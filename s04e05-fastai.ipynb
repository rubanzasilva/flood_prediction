{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":73278,"databundleVersionId":8121328,"sourceType":"competition"},{"sourceId":7277740,"sourceType":"datasetVersion","datasetId":4219453}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/rubanzasilva/s04e05-fastai?scriptVersionId=179561859\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Regression with a Flood Prediction Dataset\n\nPlayground Series - Season 4, Episode 5 where we are tasked with predicting the likelihood of floods in certain areas based off various factors.","metadata":{}},{"cell_type":"markdown","source":"## Imports\n\nBelow, i import all the libraries and datasets needed for this competition.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-24T14:17:15.851064Z","iopub.execute_input":"2024-05-24T14:17:15.851441Z","iopub.status.idle":"2024-05-24T14:17:15.862771Z","shell.execute_reply.started":"2024-05-24T14:17:15.85141Z","shell.execute_reply":"2024-05-24T14:17:15.861853Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/flood-prediction-factors/flood.csv\n/kaggle/input/playground-series-s4e5/sample_submission.csv\n/kaggle/input/playground-series-s4e5/train.csv\n/kaggle/input/playground-series-s4e5/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install openfe","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-05-24T14:17:15.873322Z","iopub.execute_input":"2024-05-24T14:17:15.873594Z","iopub.status.idle":"2024-05-24T14:17:29.860269Z","shell.execute_reply.started":"2024-05-24T14:17:15.873572Z","shell.execute_reply":"2024-05-24T14:17:29.859163Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting openfe\n  Downloading openfe-0.0.12-py3-none-any.whl.metadata (667 bytes)\nRequirement already satisfied: numpy>=1.19.3 in /opt/conda/lib/python3.10/site-packages (from openfe) (1.26.4)\nRequirement already satisfied: pandas>=1.1.5 in /opt/conda/lib/python3.10/site-packages (from openfe) (2.1.4)\nRequirement already satisfied: scikit-learn>=0.24.2 in /opt/conda/lib/python3.10/site-packages (from openfe) (1.2.2)\nRequirement already satisfied: lightgbm>=3.3.2 in /opt/conda/lib/python3.10/site-packages (from openfe) (4.2.0)\nRequirement already satisfied: scipy>=1.5.4 in /opt/conda/lib/python3.10/site-packages (from openfe) (1.11.4)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openfe) (4.66.1)\nRequirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (from openfe) (15.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.5->openfe) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.5->openfe) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.5->openfe) (2023.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->openfe) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->openfe) (3.2.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->openfe) (1.16.0)\nDownloading openfe-0.0.12-py3-none-any.whl (21 kB)\nInstalling collected packages: openfe\nSuccessfully installed openfe-0.0.12\n","output_type":"stream"}]},{"cell_type":"code","source":"#hide\n#! [ -e /content ]\n\n#hide\n#This imports and sets up everything you will need for this notebook\n#\n#!pip install -Uqq fastbook\n#import fastbook\n#fastbook.setup_book()\n\n#from fastbook import *\n#!pip install ucimlrepo\n#from ucimlrepo import fetch_ucirepo\n\nfrom fastai.tabular.all import *\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom numpy import random\n\nfrom fastai.imports import *\nnp.set_printoptions(linewidth=130)\n\n\nfrom pathlib import Path\nimport os\n\n\nfrom sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error,r2_score\n#from sklearn.metrics import root_mean_squared_error\n\nimport xgboost as xgb\nfrom xgboost import plot_importance\n\nimport lightgbm as lgb\n\nfrom catboost import CatBoostClassifier,CatBoostRegressor,Pool, metrics, cv\n\nfrom ipywidgets import interact\n\n\nmatplotlib.rc('image', cmap='Greys')\n\n#from fastkaggle import setup_comp\n\nimport optuna\nfrom openfe import OpenFE, transform\n\n","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-24T14:17:29.862107Z","iopub.execute_input":"2024-05-24T14:17:29.862444Z","iopub.status.idle":"2024-05-24T14:17:33.087327Z","shell.execute_reply.started":"2024-05-24T14:17:29.862415Z","shell.execute_reply":"2024-05-24T14:17:33.086252Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!ls /kaggle/input/playground-series-s4e5","metadata":{"execution":{"iopub.status.busy":"2024-05-24T14:17:33.088674Z","iopub.execute_input":"2024-05-24T14:17:33.089101Z","iopub.status.idle":"2024-05-24T14:17:34.096037Z","shell.execute_reply.started":"2024-05-24T14:17:33.089068Z","shell.execute_reply":"2024-05-24T14:17:34.095035Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"sample_submission.csv  test.csv  train.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"#set_seed(42)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T14:17:34.098749Z","iopub.execute_input":"2024-05-24T14:17:34.099061Z","iopub.status.idle":"2024-05-24T14:17:34.103473Z","shell.execute_reply.started":"2024-05-24T14:17:34.099033Z","shell.execute_reply":"2024-05-24T14:17:34.102543Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"path = Path('/kaggle/input/playground-series-s4e5/')\npath","metadata":{"execution":{"iopub.status.busy":"2024-05-24T14:17:34.104571Z","iopub.execute_input":"2024-05-24T14:17:34.104897Z","iopub.status.idle":"2024-05-24T14:17:34.118261Z","shell.execute_reply.started":"2024-05-24T14:17:34.104857Z","shell.execute_reply":"2024-05-24T14:17:34.1173Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Path('/kaggle/input/playground-series-s4e5')"},"metadata":{}}]},{"cell_type":"markdown","source":"After some experimentation, i noticed adding the original dataset helps the model generalize better and produces better results.","metadata":{}},{"cell_type":"code","source":"!ls /kaggle/input/flood-prediction-factors","metadata":{"execution":{"iopub.status.busy":"2024-05-24T14:17:34.119447Z","iopub.execute_input":"2024-05-24T14:17:34.119721Z","iopub.status.idle":"2024-05-24T14:17:35.117344Z","shell.execute_reply.started":"2024-05-24T14:17:34.119691Z","shell.execute_reply":"2024-05-24T14:17:35.116051Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"flood.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df = pd.read_csv(path/'train.csv',index_col='id')\ntest_df = pd.read_csv(path/'test.csv',index_col='id')\nsub_df = pd.read_csv(path/'sample_submission.csv',index_col='id')\n#original_df = pd.read_csv('/kaggle/input/flood-prediction-factors/flood.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-24T14:17:35.11925Z","iopub.execute_input":"2024-05-24T14:17:35.119681Z","iopub.status.idle":"2024-05-24T14:17:39.048253Z","shell.execute_reply.started":"2024-05-24T14:17:35.119642Z","shell.execute_reply":"2024-05-24T14:17:39.047476Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#train_df.shape,original_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-24T14:17:39.049446Z","iopub.execute_input":"2024-05-24T14:17:39.049741Z","iopub.status.idle":"2024-05-24T14:17:39.053691Z","shell.execute_reply.started":"2024-05-24T14:17:39.049717Z","shell.execute_reply":"2024-05-24T14:17:39.052795Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#train_df = pd.concat([train_df,original_df], axis=0)\n#train_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-24T14:17:39.054994Z","iopub.execute_input":"2024-05-24T14:17:39.055655Z","iopub.status.idle":"2024-05-24T14:17:39.062551Z","shell.execute_reply.started":"2024-05-24T14:17:39.055622Z","shell.execute_reply":"2024-05-24T14:17:39.061722Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#subset\n\ntrain_subset = train_df.sample(n=200000,replace=False)\ntest_subset = test_df.sample(n=150000,replace=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T14:17:39.065175Z","iopub.execute_input":"2024-05-24T14:17:39.065448Z","iopub.status.idle":"2024-05-24T14:17:39.197632Z","shell.execute_reply.started":"2024-05-24T14:17:39.065425Z","shell.execute_reply":"2024-05-24T14:17:39.196802Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_subset.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-24T14:17:39.198718Z","iopub.execute_input":"2024-05-24T14:17:39.199002Z","iopub.status.idle":"2024-05-24T14:17:39.204821Z","shell.execute_reply.started":"2024-05-24T14:17:39.198978Z","shell.execute_reply":"2024-05-24T14:17:39.204003Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(200000, 21)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Baseline\n\nThis is a simple models with just the datasets provided excluding the original datasets and no extra feature engineering or feature transformatione except the defaults.\n\nI will use random forests and neural networks as a baseline, usually i would use just the random forest since a neural network is more sensitive to parameter changes but for this case it seems to run faster, so i use i create 2 baselines.","metadata":{}},{"cell_type":"markdown","source":"Below i use the fastai cont_cat_split function to divide my columsn into categorical and continous variables.","metadata":{}},{"cell_type":"code","source":"cont_names,cat_names = cont_cat_split(train_subset, dep_var='FloodProbability')","metadata":{"execution":{"iopub.status.busy":"2024-05-24T07:33:19.311791Z","iopub.execute_input":"2024-05-24T07:33:19.312514Z","iopub.status.idle":"2024-05-24T07:33:19.341298Z","shell.execute_reply.started":"2024-05-24T07:33:19.312485Z","shell.execute_reply":"2024-05-24T07:33:19.340411Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"cont_names,cat_names = cont_cat_split(train_subset, dep_var='FloodProbability')\nsplits = RandomSplitter(valid_pct=0.2)(range_of(train_subset))\nto = TabularPandas(train_subset, procs=[Categorify, FillMissing,Normalize],\n                   cat_names = cat_names,\n                   cont_names = cont_names,\n                   y_names='FloodProbability',\n                   y_block=RegressionBlock(),\n                   splits=splits)\nX_train, y_train = to.train.xs, to.train.ys.values.ravel()\nX_test, y_test = to.valid.xs, to.valid.ys.values.ravel()\ndls = to.dataloaders(bs=64)\ntest_dl = dls.test_dl(test_subset)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"splits = RandomSplitter(valid_pct=0.2)(range_of(train_subset))","metadata":{"execution":{"iopub.status.busy":"2024-05-24T07:33:26.415848Z","iopub.execute_input":"2024-05-24T07:33:26.416178Z","iopub.status.idle":"2024-05-24T07:33:26.499736Z","shell.execute_reply.started":"2024-05-24T07:33:26.416154Z","shell.execute_reply":"2024-05-24T07:33:26.498673Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"to = TabularPandas(train_subset, procs=[Categorify, FillMissing,Normalize],\n                   cat_names = cat_names,\n                   cont_names = cont_names,\n                   y_names='FloodProbability',\n                   y_block=RegressionBlock(),\n                   splits=splits)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T07:33:32.77008Z","iopub.execute_input":"2024-05-24T07:33:32.770947Z","iopub.status.idle":"2024-05-24T07:33:32.951025Z","shell.execute_reply.started":"2024-05-24T07:33:32.770914Z","shell.execute_reply":"2024-05-24T07:33:32.950011Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"X_train, y_train = to.train.xs, to.train.ys.values.ravel()\nX_test, y_test = to.valid.xs, to.valid.ys.values.ravel()","metadata":{"execution":{"iopub.status.busy":"2024-05-24T07:33:33.341967Z","iopub.execute_input":"2024-05-24T07:33:33.342633Z","iopub.status.idle":"2024-05-24T07:33:33.364505Z","shell.execute_reply.started":"2024-05-24T07:33:33.342602Z","shell.execute_reply":"2024-05-24T07:33:33.363571Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"dls = to.dataloaders(bs=64)\ntest_dl = dls.test_dl(test_subset)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T07:33:41.581843Z","iopub.execute_input":"2024-05-24T07:33:41.582523Z","iopub.status.idle":"2024-05-24T07:33:41.805913Z","shell.execute_reply.started":"2024-05-24T07:33:41.582486Z","shell.execute_reply":"2024-05-24T07:33:41.804936Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"### Random Forest Baseline","metadata":{}},{"cell_type":"code","source":"%%time\nrf = RandomForestRegressor(50, min_samples_leaf=3)\nrf_model = rf.fit(X_train, y_train);\n\nrf_preds = tensor(rf_model.predict(test_dl.xs))\n\nrf_preds_x = tensor(rf_model.predict(X_test))\n\nmse = mean_absolute_error(y_test, rf_preds_x)\nrmse = np.sqrt(mse)\n\nr2_score(y_test,rf_preds_x)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T07:34:03.577052Z","iopub.execute_input":"2024-05-24T07:34:03.577444Z","iopub.status.idle":"2024-05-24T07:34:54.04528Z","shell.execute_reply.started":"2024-05-24T07:34:03.577414Z","shell.execute_reply":"2024-05-24T07:34:54.04428Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"CPU times: user 50.4 s, sys: 76.3 ms, total: 50.4 s\nWall time: 50.5 s\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"0.6120240869172946"},"metadata":{}}]},{"cell_type":"markdown","source":"### Neural Network","metadata":{}},{"cell_type":"code","source":"learn = tabular_learner(dls, metrics=R2Score())\nlearn.lr_find(suggest_funcs=(slide,valley))","metadata":{"execution":{"iopub.status.busy":"2024-05-24T07:45:59.727319Z","iopub.execute_input":"2024-05-24T07:45:59.72773Z","iopub.status.idle":"2024-05-24T07:46:04.440698Z","shell.execute_reply.started":"2024-05-24T07:45:59.727695Z","shell.execute_reply":"2024-05-24T07:46:04.439305Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"SuggestedLRs(slide=0.013182567432522774, valley=0.0012022644514217973)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"%%time\nlearn.fit_one_cycle(12,0.02)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T07:46:04.442376Z","iopub.execute_input":"2024-05-24T07:46:04.442654Z","iopub.status.idle":"2024-05-24T07:53:19.697953Z","shell.execute_reply.started":"2024-05-24T07:46:04.442631Z","shell.execute_reply":"2024-05-24T07:53:19.696455Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>r2_score</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.001085</td>\n      <td>0.001349</td>\n      <td>0.477405</td>\n      <td>00:37</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.000605</td>\n      <td>0.000452</td>\n      <td>0.824875</td>\n      <td>00:37</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.000664</td>\n      <td>0.000518</td>\n      <td>0.799408</td>\n      <td>00:37</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.000616</td>\n      <td>0.000475</td>\n      <td>0.816128</td>\n      <td>00:37</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.000593</td>\n      <td>0.000463</td>\n      <td>0.820623</td>\n      <td>00:36</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.000583</td>\n      <td>0.001180</td>\n      <td>0.542687</td>\n      <td>00:35</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.000569</td>\n      <td>0.150154</td>\n      <td>-57.185172</td>\n      <td>00:35</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.000527</td>\n      <td>0.006659</td>\n      <td>-1.580511</td>\n      <td>00:34</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.000494</td>\n      <td>0.001746</td>\n      <td>0.323591</td>\n      <td>00:35</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.000465</td>\n      <td>0.000414</td>\n      <td>0.839719</td>\n      <td>00:35</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.000436</td>\n      <td>0.000386</td>\n      <td>0.850287</td>\n      <td>00:36</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.000434</td>\n      <td>0.000380</td>\n      <td>0.852572</td>\n      <td>00:36</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"name":"stdout","text":"CPU times: user 7min 11s, sys: 2.81 s, total: 7min 14s\nWall time: 7min 15s\n","output_type":"stream"}]},{"cell_type":"code","source":"dl = learn.dls.test_dl(test_subset)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T07:57:44.410859Z","iopub.execute_input":"2024-05-24T07:57:44.411634Z","iopub.status.idle":"2024-05-24T07:57:44.478479Z","shell.execute_reply.started":"2024-05-24T07:57:44.411603Z","shell.execute_reply":"2024-05-24T07:57:44.477616Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"%%time\nnn_preds = learn.get_preds(dl=dl)\nnn_preds_x = learn.get_preds()[0]\na_preds, _ = learn.get_preds(dl=dl)\nnn_preds_y = a_preds.squeeze(1)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T08:00:33.691573Z","iopub.execute_input":"2024-05-24T08:00:33.692394Z","iopub.status.idle":"2024-05-24T08:01:00.49238Z","shell.execute_reply.started":"2024-05-24T08:00:33.692361Z","shell.execute_reply":"2024-05-24T08:01:00.490558Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"CPU times: user 26.8 s, sys: 141 ms, total: 26.9 s\nWall time: 26.8 s\n","output_type":"stream"}]},{"cell_type":"code","source":"#dataset no original training subset with new openFE features\nr2_score(y_test,nn_preds_x)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T08:01:24.485513Z","iopub.execute_input":"2024-05-24T08:01:24.48635Z","iopub.status.idle":"2024-05-24T08:01:24.49499Z","shell.execute_reply.started":"2024-05-24T08:01:24.486309Z","shell.execute_reply":"2024-05-24T08:01:24.493914Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"0.8525719134742764"},"metadata":{}}]},{"cell_type":"markdown","source":"So our random forest returns an r2score of **0.6120240869172946** while our neural network returns a score of **0.8525719134742764**.\n\nSo from now on, our goal will be to try to improve this score.","metadata":{}},{"cell_type":"markdown","source":"# Adding Original Dataset","metadata":{}},{"cell_type":"code","source":"original_df = pd.read_csv('/kaggle/input/flood-prediction-factors/flood.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-24T08:11:32.869804Z","iopub.execute_input":"2024-05-24T08:11:32.870221Z","iopub.status.idle":"2024-05-24T08:11:32.994004Z","shell.execute_reply.started":"2024-05-24T08:11:32.870189Z","shell.execute_reply":"2024-05-24T08:11:32.993204Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"original_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-24T08:13:40.862747Z","iopub.execute_input":"2024-05-24T08:13:40.863137Z","iopub.status.idle":"2024-05-24T08:13:40.869362Z","shell.execute_reply.started":"2024-05-24T08:13:40.863106Z","shell.execute_reply":"2024-05-24T08:13:40.86845Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"(50000, 21)"},"metadata":{}}]},{"cell_type":"code","source":"train_final = pd.concat([train_df,original_df], axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T08:27:56.229436Z","iopub.execute_input":"2024-05-24T08:27:56.230159Z","iopub.status.idle":"2024-05-24T08:27:56.30491Z","shell.execute_reply.started":"2024-05-24T08:27:56.230126Z","shell.execute_reply":"2024-05-24T08:27:56.30408Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"train_final.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-24T08:28:02.454772Z","iopub.execute_input":"2024-05-24T08:28:02.455568Z","iopub.status.idle":"2024-05-24T08:28:02.468343Z","shell.execute_reply.started":"2024-05-24T08:28:02.45552Z","shell.execute_reply":"2024-05-24T08:28:02.467146Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"(1167957, 21)"},"metadata":{}}]},{"cell_type":"code","source":"#### Random Forest Baseline","metadata":{"execution":{"iopub.status.busy":"2024-05-24T08:28:35.202646Z","iopub.execute_input":"2024-05-24T08:28:35.203402Z","iopub.status.idle":"2024-05-24T08:28:35.207167Z","shell.execute_reply.started":"2024-05-24T08:28:35.203372Z","shell.execute_reply":"2024-05-24T08:28:35.206235Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"cont_names,cat_names = cont_cat_split(train_final, dep_var='FloodProbability')\nsplits = RandomSplitter(valid_pct=0.2)(range_of(train_final))\nto = TabularPandas(train_final, procs=[Categorify, FillMissing,Normalize],\n                   cat_names = cat_names,\n                   cont_names = cont_names,\n                   y_names='FloodProbability',\n                   y_block=RegressionBlock(),\n                   splits=splits)\nX_train, y_train = to.train.xs, to.train.ys.values.ravel()\nX_test, y_test = to.valid.xs, to.valid.ys.values.ravel()\ndls = to.dataloaders(bs=64)\ntest_dl = dls.test_dl(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T08:51:32.983579Z","iopub.execute_input":"2024-05-24T08:51:32.983939Z","iopub.status.idle":"2024-05-24T08:51:34.362211Z","shell.execute_reply.started":"2024-05-24T08:51:32.98391Z","shell.execute_reply":"2024-05-24T08:51:34.361307Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"%%time\nrf = RandomForestRegressor(50, min_samples_leaf=3)\nrf_model = rf.fit(X_train, y_train);\n\nrf_preds = tensor(rf_model.predict(test_dl.xs))\n\nrf_preds_x = tensor(rf_model.predict(X_test))\n\nmse = mean_absolute_error(y_test, rf_preds_x)\nrmse = np.sqrt(mse)\n\nr2_score(y_test,rf_preds_x)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T08:51:36.497985Z","iopub.execute_input":"2024-05-24T08:51:36.498562Z","iopub.status.idle":"2024-05-24T08:57:38.383597Z","shell.execute_reply.started":"2024-05-24T08:51:36.498522Z","shell.execute_reply":"2024-05-24T08:57:38.38241Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"CPU times: user 6min, sys: 763 ms, total: 6min 1s\nWall time: 6min 1s\n","output_type":"stream"},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"0.6504381557189793"},"metadata":{}}]},{"cell_type":"code","source":"learn1 = tabular_learner(dls, metrics=R2Score())\nlearn1.lr_find(suggest_funcs=(slide,valley))","metadata":{"execution":{"iopub.status.busy":"2024-05-24T09:10:32.268568Z","iopub.execute_input":"2024-05-24T09:10:32.269488Z","iopub.status.idle":"2024-05-24T09:10:35.343983Z","shell.execute_reply.started":"2024-05-24T09:10:32.269454Z","shell.execute_reply":"2024-05-24T09:10:35.343031Z"},"trusted":true},"execution_count":47,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"SuggestedLRs(slide=0.005248074419796467, valley=0.0004786300996784121)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"%%time\nlearn1.fit_one_cycle(12,0.02)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T09:10:44.592916Z","iopub.execute_input":"2024-05-24T09:10:44.593565Z","iopub.status.idle":"2024-05-24T09:54:38.363448Z","shell.execute_reply.started":"2024-05-24T09:10:44.593531Z","shell.execute_reply":"2024-05-24T09:54:38.362551Z"},"trusted":true},"execution_count":48,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>r2_score</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.000786</td>\n      <td>0.000778</td>\n      <td>0.700291</td>\n      <td>03:34</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.000537</td>\n      <td>0.000422</td>\n      <td>0.837273</td>\n      <td>03:48</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.000606</td>\n      <td>0.000437</td>\n      <td>0.831830</td>\n      <td>03:45</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.000575</td>\n      <td>0.000423</td>\n      <td>0.837155</td>\n      <td>03:37</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.000571</td>\n      <td>0.000502</td>\n      <td>0.806579</td>\n      <td>03:37</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.000555</td>\n      <td>0.001011</td>\n      <td>0.610671</td>\n      <td>03:46</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.000493</td>\n      <td>0.000538</td>\n      <td>0.792843</td>\n      <td>03:43</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.000480</td>\n      <td>0.000444</td>\n      <td>0.829046</td>\n      <td>03:36</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.000495</td>\n      <td>0.000438</td>\n      <td>0.831190</td>\n      <td>03:37</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.000454</td>\n      <td>0.000382</td>\n      <td>0.852975</td>\n      <td>03:35</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.000463</td>\n      <td>0.000370</td>\n      <td>0.857513</td>\n      <td>03:36</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.000413</td>\n      <td>0.000369</td>\n      <td>0.857864</td>\n      <td>03:32</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"name":"stdout","text":"CPU times: user 43min 28s, sys: 17.9 s, total: 43min 46s\nWall time: 43min 53s\n","output_type":"stream"}]},{"cell_type":"code","source":"dl = learn1.dls.test_dl(test_subset)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T10:27:58.312328Z","iopub.execute_input":"2024-05-24T10:27:58.313195Z","iopub.status.idle":"2024-05-24T10:27:58.372152Z","shell.execute_reply.started":"2024-05-24T10:27:58.313155Z","shell.execute_reply":"2024-05-24T10:27:58.371287Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"%%time\nnn_preds = learn1.get_preds(dl=dl)\nnn_preds_x = learn1.get_preds()[0]\na_preds, _ = learn1.get_preds(dl=dl)\nnn_preds_y = a_preds.squeeze(1)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T10:28:09.967428Z","iopub.execute_input":"2024-05-24T10:28:09.967805Z","iopub.status.idle":"2024-05-24T10:29:00.186362Z","shell.execute_reply.started":"2024-05-24T10:28:09.967775Z","shell.execute_reply":"2024-05-24T10:29:00.184278Z"},"trusted":true},"execution_count":58,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"CPU times: user 50.2 s, sys: 209 ms, total: 50.4 s\nWall time: 50.2 s\n","output_type":"stream"}]},{"cell_type":"code","source":"nn_preds_x.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-24T10:29:00.188237Z","iopub.execute_input":"2024-05-24T10:29:00.188571Z","iopub.status.idle":"2024-05-24T10:29:00.195693Z","shell.execute_reply.started":"2024-05-24T10:29:00.188544Z","shell.execute_reply":"2024-05-24T10:29:00.194691Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"torch.Size([233591, 1])"},"metadata":{}}]},{"cell_type":"code","source":"#dataset with original training subset with new openFE features\nr2_score(y_test,nn_preds_x)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T10:29:00.196967Z","iopub.execute_input":"2024-05-24T10:29:00.197471Z","iopub.status.idle":"2024-05-24T10:29:00.220734Z","shell.execute_reply.started":"2024-05-24T10:29:00.197447Z","shell.execute_reply":"2024-05-24T10:29:00.219735Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"0.8578640002891056"},"metadata":{}}]},{"cell_type":"markdown","source":"Random forest now scores **0.6504381557189793** while the neural network scores **0.8578640002891056** which is an improvement from our previous scores.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can conclude that adding the original dataset improves the model's results.","metadata":{}},{"cell_type":"markdown","source":"# Introducing Open FE \n\nSo i","metadata":{}},{"cell_type":"markdown","source":"### Excluding original dataset","metadata":{}},{"cell_type":"code","source":"ofe = OpenFE()","metadata":{"execution":{"iopub.status.busy":"2024-05-24T14:17:40.339792Z","iopub.execute_input":"2024-05-24T14:17:40.340152Z","iopub.status.idle":"2024-05-24T14:17:40.344444Z","shell.execute_reply.started":"2024-05-24T14:17:40.340126Z","shell.execute_reply":"2024-05-24T14:17:40.343534Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#set n_jobs to be the actual cpu core count\nCPU_COUNT = os.cpu_count()\nn_jobs = CPU_COUNT\nn_jobs","metadata":{"execution":{"iopub.status.busy":"2024-05-24T14:17:40.680419Z","iopub.execute_input":"2024-05-24T14:17:40.680759Z","iopub.status.idle":"2024-05-24T14:17:40.687196Z","shell.execute_reply.started":"2024-05-24T14:17:40.680732Z","shell.execute_reply":"2024-05-24T14:17:40.686168Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"4"},"metadata":{}}]},{"cell_type":"code","source":"y_names='FloodProbability'","metadata":{"execution":{"iopub.status.busy":"2024-05-24T14:17:48.784639Z","iopub.execute_input":"2024-05-24T14:17:48.785527Z","iopub.status.idle":"2024-05-24T14:17:48.79056Z","shell.execute_reply.started":"2024-05-24T14:17:48.785484Z","shell.execute_reply":"2024-05-24T14:17:48.789555Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#features = ofe.fit(data=train_subset.drop('FloodProbability',axis=1), label=train_subset['FloodProbability'], n_jobs=n_jobs)  # generate new features\n#train_x, test_x = transform(train_z, test_subset, features, n_jobs=n_jobs) # transform the train and test data according to generated features.","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-24T11:16:34.165652Z","iopub.execute_input":"2024-05-24T11:16:34.166367Z","iopub.status.idle":"2024-05-24T11:16:34.170347Z","shell.execute_reply.started":"2024-05-24T11:16:34.166331Z","shell.execute_reply":"2024-05-24T11:16:34.169456Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"markdown","source":"Concating the original dataframe before running the OpenFE feature generation tool seems to result in a NameError.\nThis needs further investigation.","metadata":{}},{"cell_type":"code","source":"params = {\"n_estimators\": 1000, \"importance_type\": \"gain\", \"num_leaves\": 64,\"seed\": 1, \"n_jobs\": n_jobs}","metadata":{"execution":{"iopub.status.busy":"2024-05-24T14:18:12.714073Z","iopub.execute_input":"2024-05-24T14:18:12.714472Z","iopub.status.idle":"2024-05-24T14:18:12.719224Z","shell.execute_reply.started":"2024-05-24T14:18:12.714442Z","shell.execute_reply":"2024-05-24T14:18:12.718156Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"%%time\nfrom openfe import OpenFE, get_candidate_features, transform, tree_to_formula\n\nofe1 = OpenFE()\ncandidate_features_list = get_candidate_features(numerical_features=list(test_subset.columns))\nfeatures1 = ofe1.fit(data=train_subset.drop(y_names,axis=1), label=train_subset[y_names],\n                     candidate_features_list=candidate_features_list, metric='rmse', task='regression', stage2_params=params,\n                     min_candidate_features=5000,\n                     n_jobs=n_jobs, n_data_blocks=2, feature_boosting=True)\n  ","metadata":{"_kg_hide-output":true,"_kg_hide-input":false,"scrolled":true,"execution":{"iopub.status.busy":"2024-05-24T14:34:17.336807Z","iopub.execute_input":"2024-05-24T14:34:17.337498Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023634 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 345\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 20\n[LightGBM] [Info] Start training from score 0.504612\nTraining until validation scores don't improve for 200 rounds\nEarly stopping, best iteration is:\n[1275]\tvalid_0's rmse: 0.0208361\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020545 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 347\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 20\n[LightGBM] [Info] Start training from score 0.504500\nTraining until validation scores don't improve for 200 rounds\nEarly stopping, best iteration is:\n[1844]\tvalid_0's rmse: 0.0208636\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.108187 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 345\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 20\n[LightGBM] [Info] Start training from score 0.504727\nTraining until validation scores don't improve for 200 rounds\nEarly stopping, best iteration is:\n[1641]\tvalid_0's rmse: 0.0210227\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082868 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 345\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 20\n[LightGBM] [Info] Start training from score 0.504624\nTraining until validation scores don't improve for 200 rounds\nEarly stopping, best iteration is:\n[1643]\tvalid_0's rmse: 0.0210696\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.094853 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 346\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 20\n[LightGBM] [Info] Start training from score 0.504627\nTraining until validation scores don't improve for 200 rounds\nEarly stopping, best iteration is:\n[1473]\tvalid_0's rmse: 0.0210086\nThe number of candidate features is 1300\nStart stage I selection.\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/16 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002984 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 16\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002433 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002209 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002137 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002057 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 71[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003419 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002100 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Total Bins 69[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002472 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004520 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 70[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004690 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 28\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002059 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 12[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001439 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002084 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 105[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002287 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 111\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002202 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001989 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 113\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001347 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 27[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002119 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002165 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 71[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002101 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006014 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002010 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002008 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 25\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002210 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001998 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002022 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 70[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002243 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002140 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002406 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003382 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001353 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 27\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002035 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 72[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002050 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003333 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000930 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 70\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002312 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002011 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 71\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002071 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002170 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 25[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002371 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 25\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002241 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 27\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002533 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003281 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 112\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 27\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002086 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003266 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002146 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 73[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001621 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005346 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002330 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002093 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 71[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001944 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003886 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 25[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002804 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Total Bins 27[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002441 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 73[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002790 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 27\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002220 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001801 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002844 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 107\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Total Bins 72\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002445 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002413 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 28\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002268 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17[LightGBM] [Info] Total Bins 12[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002328 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010301 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002327 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002526 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002339 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002151 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007128 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 107\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002148 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Total Bins 70[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002292 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002183 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002235 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002053 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 70\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002823 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003317 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002353 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002460 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002344 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002307 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 27[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002200 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 108\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002377 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 109[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002009 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002100 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 71\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002274 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 28\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002833 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002012 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n\n[LightGBM] [Info] Total Bins 70\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003482 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 107\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Total Bins 109\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Total Bins 0\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 0\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003300 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008761 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 27[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Total Bins 25\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002057 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010130 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Total Bins 71\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002377 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002060 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 109\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002074 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002180 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 109[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002576 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002056 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002187 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 12[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001011 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002323 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 27\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001964 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 25\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001459 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002197 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 28[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002040 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 72\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002087 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 67\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002127 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 109\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002298 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002115 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 12[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001600 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002486 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 25\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002014 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002719 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002168 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002109 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 107[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002386 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Total Bins 72\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002362 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002445 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002361 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002384 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002852 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003535 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001190 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002236 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Total Bins 107\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002051 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002101 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002111 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 12[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002396 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12[LightGBM] [Info] Total Bins 71[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Total Bins 111[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002405 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002642 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 12[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Info] Total Bins 27[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002091 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002063 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 25[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002303 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 27[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002003 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 25[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002317 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Total Bins 70[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002827 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 109\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002378 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002146 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002082 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002232 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 109\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002223 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 108[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002377 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 71\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002072 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002141 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002174 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 12[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002095 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 12[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002230 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 108[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001983 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003240 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002361 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002012 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002335 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Total Bins 69\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002175 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002084 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 25\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002057 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002011 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Total Bins 13\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002115 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002747 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002977 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002825 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 109[LightGBM] [Info] Total Bins 72\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002544 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001955 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 107\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002198 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 27[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002042 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 110\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002010 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002276 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002071 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 69\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002140 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 73\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002026 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 26[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002027 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Total Bins 0\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 0[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002319 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 70\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002323 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 111\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002084 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002018 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 25\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004292 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002514 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002099 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 110\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002346 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002368 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18[LightGBM] [Info] Total Bins 108\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002423 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Total Bins 69[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002203 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002235 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002120 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Total Bins 12[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002174 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002132 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002131 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 110\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002196 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002181 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002308 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 110\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002027 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 111[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002037 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002028 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002056 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002046 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014044 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 25[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002840 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 25\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008772 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002036 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002207 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 0\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 0[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002027 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Total Bins 110\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002019 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002697 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 109\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002200 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001979 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002245 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002099 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 70\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Total Bins 73\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002097 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002124 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002136 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Total Bins 25[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003785 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 74\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002200 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002661 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001809 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Total Bins 112\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002121 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002105 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 13\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 25\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002216 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007138 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002068 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 72\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 70\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002114 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 72\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002054 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006727 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002643 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002232 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002324 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002368 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002267 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 27[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002519 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002375 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002298 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002203 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Total Bins 71[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002834 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 0[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 0\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002024 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002377 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Total Bins 18[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004182 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002212 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 26\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001474 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 18[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001986 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002055 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 68\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002405 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002041 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002188 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003133 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002328 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 71\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003250 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002806 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 25[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002045 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 113\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002242 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002797 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002493 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 28\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001972 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 71\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002971 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002237 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 111\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002189 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002057 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 71[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002119 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002030 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001741 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Total Bins 107[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001958 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 107\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002089 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 110\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007435 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002033 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002129 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003106 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 18\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004614 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002134 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002084 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 111\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 13\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002232 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 108\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001987 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.[LightGBM] [Info] Total Bins 73\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002198 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 0\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 0\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001979 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 18[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001317 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002672 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002545 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 70\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002401 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002595 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Total Bins 25[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003380 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003326 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 70[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002836 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003878 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 106\n\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Total Bins 70[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002099 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 12[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002043 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002311 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"},{"name":"stderr","text":"  6%|         | 1/16 [00:22<05:37, 22.53s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002157 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000982 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\n\n[LightGBM] [Info] Total Bins 26[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002331 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002332 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 106\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002096 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002072 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 110\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002409 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Total Bins 110\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002354 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 111\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007040 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 25[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014218 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 113\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002263 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 18\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002099 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002376 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 111[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002048 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010173 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002035 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 108[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002312 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 27[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002088 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n[LightGBM] [Info] Total Bins 12[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 0[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 0\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002419 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002320 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002652 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 109\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002373 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002009 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002346 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 72\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002737 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 109\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002537 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002031 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 110\n","output_type":"stream"},{"name":"stderr","text":" 12%|        | 2/16 [00:25<02:33, 10.95s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012614 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001928 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 68\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002042 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 110\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002010 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 109\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002019 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002027 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n","output_type":"stream"},{"name":"stderr","text":" 19%|        | 3/16 [00:26<01:22,  6.37s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012310 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 111[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n\n[LightGBM] [Info] Total Bins 0[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 0\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002004 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004839 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 27[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002018 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002131 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 70[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002424 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001911 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 27[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002702 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005399 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Total Bins 28[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002223 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 28[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002123 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002271 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002204 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002076 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 25[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001971 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002120 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 13\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002108 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002440 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 25[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003201 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002536 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002229 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 12\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002109 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 12\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002098 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002287 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 27[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002430 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002297 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 68[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002892 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002290 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002892 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002659 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 12\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002080 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 111[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002341 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002638 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 25\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002087 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002580 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Total Bins 71[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002211 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 108\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002025 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002045 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Total Bins 72[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002008 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005855 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 109[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002020 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002238 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002004 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002130 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 71[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001347 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002093 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 25\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002351 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 108\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011632 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002029 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 73[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002269 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002104 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002388 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 71\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003539 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002265 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 112\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002212 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003211 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002170 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001927 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002128 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002237 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 71\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002289 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004727 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 18\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002056 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n","output_type":"stream"},{"name":"stderr","text":" 25%|       | 4/16 [00:31<01:09,  5.79s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003197 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002140 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002462 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 109\n\n[LightGBM] [Info] Total Bins 28[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002017 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 112\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002017 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002444 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003201 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002278 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 109[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008319 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 25[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002211 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002133 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002081 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002577 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 68[LightGBM] [Info] Total Bins 68\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002859 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001947 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002801 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002230 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 12\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001783 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003969 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 25[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002380 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002074 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002136 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002638 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 12\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002120 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002222 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 16\n\n\n[LightGBM] [Info] Total Bins 12[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002038 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002119 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003114 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 71\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002073 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002321 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002508 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 12\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002960 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002068 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 111\n\n[LightGBM] [Info] Total Bins 112\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004401 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 113\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002057 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002309 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Total Bins 28[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002232 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 25\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002368 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002642 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Total Bins 69[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 111\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002049 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 25[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002197 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001982 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002124 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002089 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002318 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 24[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002078 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002167 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002016 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002203 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002123 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 107\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 0\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004149 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 0[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002045 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002017 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003557 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002095 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 70[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002061 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 113\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002271 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 108\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002185 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002029 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001567 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Total Bins 112\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003702 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002358 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 71\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002654 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010904 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002581 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 72\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002575 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003758 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002345 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 109[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002254 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 18[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003154 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Total Bins 70[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002309 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 110\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002235 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002410 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002852 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 72\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002323 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 72\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002778 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 111[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001574 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008501 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002819 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 109[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001997 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 73\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002165 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 110\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001403 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 18[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002201 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002108 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002103 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002365 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002323 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 72\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002471 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 27[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002063 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 108\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002039 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 70\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002291 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 25[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002982 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001910 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 72\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002035 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 68[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002188 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002023 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010407 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 25[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Total Bins 73\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002075 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 25[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002254 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002606 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Total Bins 25[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002040 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 25[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002293 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001625 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\n\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002169 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002091 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010074 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 0[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 0\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002049 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002408 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 70\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003437 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 106\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002273 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002165 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Total Bins 27[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005182 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 12[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002248 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002104 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 107\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002135 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002333 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 27[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002046 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002976 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002293 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002150 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 109\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002258 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002051 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002072 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Total Bins 24[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002571 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002188 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002065 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002038 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 25\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002339 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002144 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002250 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002075 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Total Bins 72\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002088 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 108\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002335 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002007 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006686 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 73[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002113 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 71\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002056 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 70\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006686 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 27\n\n[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 0\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 0\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002158 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002555 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002129 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002095 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002069 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002071 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 69[LightGBM] [Info] Total Bins 17\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002262 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 71\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004052 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004371 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002157 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 18[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003595 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002081 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 70\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002439 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 12[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002286 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006559 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 27[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004931 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002103 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001929 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002411 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 12\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003041 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002160 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Info] Total Bins 24[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002426 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 28[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002480 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002099 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002055 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 105[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003056 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002703 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002267 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 70\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002367 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002204 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Total Bins 105\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002029 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002355 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 110\n\n[LightGBM] [Info] Total Bins 26[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002054 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002041 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 109\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001966 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 108[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002306 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 12\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002177 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 13\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002087 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002162 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 108\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002312 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 73[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001943 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002173 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 108[LightGBM] [Info] Total Bins 25\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002050 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002147 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002296 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003807 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 110\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002026 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001330 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 69\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002140 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003292 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002293 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 109[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002034 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 108\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002090 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003330 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002017 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 25[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002167 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001989 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 24\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002049 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002163 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002204 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 25[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003544 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002239 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 27\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002093 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 0\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 0\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002012 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002382 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002863 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002012 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002406 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002160 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Total Bins 71\n\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002087 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008318 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002289 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 27\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001986 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 109[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002304 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002299 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 109\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002309 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001269 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Info] Total Bins 108\n\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002499 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf","output_type":"stream"},{"name":"stderr","text":" 31%|      | 5/16 [00:47<01:46,  9.71s/it]","output_type":"stream"},{"name":"stdout","text":"\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002446 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002042 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002028 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002016 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002553 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 110[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002198 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004104 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 25[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000998 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 69\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002045 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 71\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001120 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001618 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001759 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002234 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 12[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002030 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 70[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002122 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 110\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002092 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002015 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 109[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002115 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 18[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002012 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002180 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 107[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002086 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002095 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 25[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002375 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 115\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002409 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002080 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 13[LightGBM] [Info] Total Bins 18\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001457 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002171 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Total Bins 109\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002171 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002338 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 0[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 0\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002004 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 25[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"},{"name":"stderr","text":" 38%|      | 6/16 [00:50<01:12,  7.22s/it]","output_type":"stream"},{"name":"stdout","text":"\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002771 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 18\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002202 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002089 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 69[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002244 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Total Bins 27[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002132 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Total Bins 112\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002059 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002277 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002800 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 111\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002088 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002081 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002004 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 18\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003629 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 72\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002190 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 109[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002484 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003708 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002008 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 71[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002154 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 108\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002415 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 70\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002198 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002067 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 107\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Total Bins 70\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002093 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 72\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002988 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001981 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001607 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 107\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002298 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 108\n\n[LightGBM] [Info] Total Bins 27[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1","output_type":"stream"},{"name":"stderr","text":" 44%|     | 7/16 [00:51<00:47,  5.25s/it]","output_type":"stream"},{"name":"stdout","text":"\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002705 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002148 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002212 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002136 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 70\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002152 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002002 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002126 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001560 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 72\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003275 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 71\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002093 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002608 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002505 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 73\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002229 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002306 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002277 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001588 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 13[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002184 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001872 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004095 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 12[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002198 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 25[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002117 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 108[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002577 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 18[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002518 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 72\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002240 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 109\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001973 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002046 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 71\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002220 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002056 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 71\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002615 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002053 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 17\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002406 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002295 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002261 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002197 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002037 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 68\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002017 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002122 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002101 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002325 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 24[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002341 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 108[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001962 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001947 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002101 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Total Bins 18[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002104 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004576 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 73\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001934 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 72\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002744 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002090 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 18\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002208 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 70[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002103 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 68[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002309 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Total Bins 27[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002261 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002381 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002082 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Total Bins 107[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002287 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002337 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002728 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002337 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Total Bins 12\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011562 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002340 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 73[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002372 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Total Bins 71\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002057 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002171 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003157 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"},{"name":"stderr","text":" 50%|     | 8/16 [00:55<00:39,  4.99s/it]","output_type":"stream"},{"name":"stdout","text":"\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002088 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 68\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003006 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002035 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002925 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 71[LightGBM] [Info] Total Bins 108[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002212 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 110\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002148 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 71[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002215 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 27\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002128 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 71\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002335 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002344 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 27[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 18[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002187 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 72\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002102 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 111\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002306 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 111\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002304 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 109\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002162 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 13[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001793 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Total Bins 12\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002344 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 111\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001973 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002358 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002299 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 73\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002130 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 18[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003860 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003944 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 71\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002315 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001991 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 110\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002858 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001964 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002038 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002166 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Total Bins 74[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002241 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002015 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002509 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011831 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 71\n\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002100 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 71\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005080 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002112 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002159 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Total Bins 70[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002378 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003049 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002222 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 12[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002017 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002193 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 72\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002015 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002016 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 71\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 115[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002378 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002243 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002035 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 109\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002203 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002219 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 71[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002054 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002177 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 73\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002296 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002677 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 69[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002065 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 109\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002043 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 70[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002205 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002187 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002153 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 110\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002063 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002526 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 71[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002193 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 111[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002103 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002099 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003348 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Total Bins 71[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002154 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 12[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002592 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 71\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004169 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002193 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002037 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002170 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002157 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002216 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 107\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002089 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001986 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002180 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002034 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 109\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002016 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002359 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 26[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002033 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001893 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002363 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002032 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 25\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Total Bins 70[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002142 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002089 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 112\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002174 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002089 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 108[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002202 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002024 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 67\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002168 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 12\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002770 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002579 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002126 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002167 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002089 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002039 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 72\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002048 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002580 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002145 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 28\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Total Bins 111\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002147 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 111\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002224 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002652 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002117 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 72\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002278 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002070 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002412 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n\n[LightGBM] [Info] Total Bins 27[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002076 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 12\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002061 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002301 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 70[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002089 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002336 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002064 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 71\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002293 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002262 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002345 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 27\n\n[LightGBM] [Info] Total Bins 112[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001944 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 111\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002492 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002126 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 12[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002096 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 109[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002143 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001564 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001975 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 114\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002432 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002055 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 73\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002214 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001951 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001737 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002113 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002030 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002352 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002181 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 111\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002260 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 107\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002374 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 0\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 0\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Info] Total Bins 27\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002101 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002146 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002021 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 18[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001995 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003221 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002321 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 71\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002044 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 25[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002028 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 111\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002094 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 16\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002225 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002240 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001957 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002087 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 70\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002049 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 71\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002137 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003687 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 113[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004046 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002932 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 112\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002203 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n","output_type":"stream"},{"name":"stderr","text":" 56%|    | 9/16 [01:04<00:42,  6.06s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Total Bins 25[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002066 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002055 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 109\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002092 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 112\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002022 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 18\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002756 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 71\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002407 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002275 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002351 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002152 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002091 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 112\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002113 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002399 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002056 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002199 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001917 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 70\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002214 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 70\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002359 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002523 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002036 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 25\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002327 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002067 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 70\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002555 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 28[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002292 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002228 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002143 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 25\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002343 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 28[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002441 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004415 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006524 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 114\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015356 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005162 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 118[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004076 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014123 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 26[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004748 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004033 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005291 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Total Bins 76[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004698 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004494 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003912 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005312 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003397 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004711 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004064 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004195 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004156 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004908 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 18\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005348 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 30[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004342 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004591 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 115\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004235 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004716 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004692 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004179 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004923 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 75[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004730 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004384 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Total Bins 115\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004408 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 27\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004209 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 115[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004744 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 28\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002855 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 28[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004177 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 75\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n","output_type":"stream"},{"name":"stderr","text":"  6%|         | 1/16 [00:32<08:02, 32.17s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004904 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003330 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 115\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"},{"name":"stderr","text":" 12%|        | 2/16 [00:32<03:07, 13.40s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004150 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004357 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004392 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004235 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001848 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Info] Total Bins 28\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004102 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004325 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004528 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004623 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004148 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 13[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004009 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004414 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 13[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004313 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 117[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005003 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004078 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004116 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003933 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 75\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004793 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 118[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002107 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004181 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 75[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004369 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004053 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 115\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002231 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 28[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004666 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004052 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004236 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004465 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008825 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003350 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 115[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004537 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004130 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004252 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Info] Total Bins 75\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004511 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004355 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004031 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004428 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n","output_type":"stream"},{"name":"stderr","text":" 19%|        | 3/16 [00:36<01:56,  9.00s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006952 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004890 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004196 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 118\n","output_type":"stream"},{"name":"stderr","text":" 25%|       | 4/16 [00:36<01:06,  5.57s/it]","output_type":"stream"},{"name":"stdout","text":"\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004030 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003982 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005346 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004190 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005194 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 74\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004229 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Info] Total Bins 75[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004109 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 18\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010130 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004813 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 27\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005287 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 74\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003905 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003934 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004098 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004774 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004556 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 29[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004188 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 76[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008543 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 119[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004203 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 27[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004538 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 74\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004332 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004535 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005058 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 28\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004095 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004244 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004915 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 29[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004050 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005443 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004551 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004780 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 74\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004908 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 13\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005499 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004441 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 113\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"},{"text":"IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\n","name":"stderr","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003948 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004121 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 115\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004092 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004230 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004275 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 116\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004237 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 117\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008206 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003997 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004252 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 117\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004524 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 118\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003910 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 75\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004132 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004266 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004122 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006772 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 18\n\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003138 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004893 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 29\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002416 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 115[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003307 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 14[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004842 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004028 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"},{"name":"stderr","text":" 50%|     | 8/16 [01:10<00:48,  6.06s/it]","output_type":"stream"},{"name":"stdout","text":"\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004234 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003956 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006107 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 114\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005516 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 75\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003933 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 18\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005195 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 18[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004652 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004530 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004334 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004375 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004613 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 75[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004150 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 28\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004606 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 114\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004106 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004693 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 117\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004470 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005346 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004079 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 114\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003331 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 28[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004228 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003817 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005154 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006467 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 27[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004201 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 73[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004193 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002084 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 25[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003401 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004697 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004067 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004459 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Total Bins 26[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004282 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004242 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 27\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004363 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003879 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005022 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004725 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 28[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004097 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 115\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004027 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004207 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 27[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004280 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004563 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003092 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004096 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 25[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004494 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 115\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004409 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003932 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004442 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004493 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005114 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004357 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003905 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004708 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002982 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 74[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004881 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004517 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004199 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003802 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004555 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 12\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003872 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004207 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004299 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004368 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004769 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003281 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004162 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 116\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004128 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004741 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004302 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004392 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004394 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004069 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004083 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003999 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004420 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004755 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004081 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004129 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006458 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 12\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004577 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 13[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004445 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf","output_type":"stream"}]},{"cell_type":"code","source":"train_new, test_new = transform(train_subset.drop(y_names,axis=1), test_subset, features1[:300], n_jobs=n_jobs)  ","metadata":{"execution":{"iopub.status.busy":"2024-05-24T15:14:17.996445Z","iopub.execute_input":"2024-05-24T15:14:17.997429Z","iopub.status.idle":"2024-05-24T15:14:24.538351Z","shell.execute_reply.started":"2024-05-24T15:14:17.997388Z","shell.execute_reply":"2024-05-24T15:14:24.53704Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Merge train_new with train_df to add the 'FloodProbability' column\nmerged_train_new = pd.merge(train_new, train_subset[['FloodProbability']], left_index=True, right_index=True)\nmerged_train_new","metadata":{"execution":{"iopub.status.busy":"2024-05-24T14:59:13.679768Z","iopub.execute_input":"2024-05-24T14:59:13.680529Z","iopub.status.idle":"2024-05-24T14:59:13.941579Z","shell.execute_reply.started":"2024-05-24T14:59:13.680495Z","shell.execute_reply":"2024-05-24T14:59:13.94052Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"              MonsoonIntensity  TopographyDrainage  RiverManagement  \\\nopenfe_index                                                          \n25031                        4                  12                3   \n324828                       8                   2                8   \n698052                       2                   1                4   \n661165                       4                   8                2   \n922824                       8                   5                3   \n...                        ...                 ...              ...   \n199446                       5                   8                3   \n824195                       6                   2                6   \n737977                       4                   4                4   \n556349                       2                   4                2   \n272243                       4                   7                3   \n\n              Deforestation  Urbanization  ClimateChange  DamsQuality  \\\nopenfe_index                                                            \n25031                     7             5              5            5   \n324828                   10             2              5            3   \n698052                    3             4              7            6   \n661165                    4             4              2            9   \n922824                    8             6              8            1   \n...                     ...           ...            ...          ...   \n199446                    4             4              5            6   \n824195                    5             7              6            5   \n737977                    3             4              6            6   \n556349                    6             6              8            4   \n272243                    4             4              6            8   \n\n              Siltation  AgriculturalPractices  Encroachments  ...  \\\nopenfe_index                                                   ...   \n25031                 5                      5              1  ...   \n324828                6                      7              4  ...   \n698052                5                      8             10  ...   \n661165                5                     11              6  ...   \n922824                6                     12             10  ...   \n...                 ...                    ...            ...  ...   \n199446                5                      3              7  ...   \n824195                7                      4              5  ...   \n737977                8                      4              3  ...   \n556349                8                      4              6  ...   \n272243                2                      2              9  ...   \n\n              autoFE_f_291  autoFE_f_292  autoFE_f_293  autoFE_f_294  \\\nopenfe_index                                                           \n25031                 20.0      1.000000           4.0          20.0   \n324828                18.0      0.375000           3.0           9.0   \n698052                35.0      1.750000           4.0          24.0   \n661165                10.0      1.285714           2.0          27.0   \n922824                18.0      5.500000           2.0           6.0   \n...                    ...           ...           ...           ...   \n199446                20.0      0.666667           4.0          24.0   \n824195                35.0      1.666667           3.0          25.0   \n737977                64.0      1.000000           6.0          30.0   \n556349                48.0      2.000000           2.0          12.0   \n272243                10.0      2.500000           2.0          24.0   \n\n              autoFE_f_295  autoFE_f_296  autoFE_f_297  autoFE_f_298  \\\nopenfe_index                                                           \n25031                  0.0           7.0          -2.0           5.0   \n324828                 3.0           2.0           3.0           8.0   \n698052                -2.0           1.0          -3.0           7.0   \n661165                -4.0           2.0           0.0           2.0   \n922824                -5.0           5.0          -5.0           8.0   \n...                    ...           ...           ...           ...   \n199446                 1.0           5.0          -2.0           5.0   \n824195                 2.0           2.0           0.0           6.0   \n737977                 2.0           4.0          -2.0           6.0   \n556349                 4.0           3.0          -6.0           8.0   \n272243                -3.0           4.0          -3.0           6.0   \n\n              autoFE_f_299  FloodProbability  \nopenfe_index                                  \n25031                  4.0             0.495  \n324828                 3.0             0.535  \n698052                 4.0             0.530  \n661165                 2.0             0.435  \n922824                 5.0             0.655  \n...                    ...               ...  \n199446                 4.0             0.460  \n824195                 3.0             0.530  \n737977                 5.0             0.485  \n556349                 3.0             0.490  \n272243                 3.0             0.480  \n\n[200000 rows x 321 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MonsoonIntensity</th>\n      <th>TopographyDrainage</th>\n      <th>RiverManagement</th>\n      <th>Deforestation</th>\n      <th>Urbanization</th>\n      <th>ClimateChange</th>\n      <th>DamsQuality</th>\n      <th>Siltation</th>\n      <th>AgriculturalPractices</th>\n      <th>Encroachments</th>\n      <th>...</th>\n      <th>autoFE_f_291</th>\n      <th>autoFE_f_292</th>\n      <th>autoFE_f_293</th>\n      <th>autoFE_f_294</th>\n      <th>autoFE_f_295</th>\n      <th>autoFE_f_296</th>\n      <th>autoFE_f_297</th>\n      <th>autoFE_f_298</th>\n      <th>autoFE_f_299</th>\n      <th>FloodProbability</th>\n    </tr>\n    <tr>\n      <th>openfe_index</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>25031</th>\n      <td>4</td>\n      <td>12</td>\n      <td>3</td>\n      <td>7</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1</td>\n      <td>...</td>\n      <td>20.0</td>\n      <td>1.000000</td>\n      <td>4.0</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>-2.0</td>\n      <td>5.0</td>\n      <td>4.0</td>\n      <td>0.495</td>\n    </tr>\n    <tr>\n      <th>324828</th>\n      <td>8</td>\n      <td>2</td>\n      <td>8</td>\n      <td>10</td>\n      <td>2</td>\n      <td>5</td>\n      <td>3</td>\n      <td>6</td>\n      <td>7</td>\n      <td>4</td>\n      <td>...</td>\n      <td>18.0</td>\n      <td>0.375000</td>\n      <td>3.0</td>\n      <td>9.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>8.0</td>\n      <td>3.0</td>\n      <td>0.535</td>\n    </tr>\n    <tr>\n      <th>698052</th>\n      <td>2</td>\n      <td>1</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n      <td>7</td>\n      <td>6</td>\n      <td>5</td>\n      <td>8</td>\n      <td>10</td>\n      <td>...</td>\n      <td>35.0</td>\n      <td>1.750000</td>\n      <td>4.0</td>\n      <td>24.0</td>\n      <td>-2.0</td>\n      <td>1.0</td>\n      <td>-3.0</td>\n      <td>7.0</td>\n      <td>4.0</td>\n      <td>0.530</td>\n    </tr>\n    <tr>\n      <th>661165</th>\n      <td>4</td>\n      <td>8</td>\n      <td>2</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>9</td>\n      <td>5</td>\n      <td>11</td>\n      <td>6</td>\n      <td>...</td>\n      <td>10.0</td>\n      <td>1.285714</td>\n      <td>2.0</td>\n      <td>27.0</td>\n      <td>-4.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.435</td>\n    </tr>\n    <tr>\n      <th>922824</th>\n      <td>8</td>\n      <td>5</td>\n      <td>3</td>\n      <td>8</td>\n      <td>6</td>\n      <td>8</td>\n      <td>1</td>\n      <td>6</td>\n      <td>12</td>\n      <td>10</td>\n      <td>...</td>\n      <td>18.0</td>\n      <td>5.500000</td>\n      <td>2.0</td>\n      <td>6.0</td>\n      <td>-5.0</td>\n      <td>5.0</td>\n      <td>-5.0</td>\n      <td>8.0</td>\n      <td>5.0</td>\n      <td>0.655</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>199446</th>\n      <td>5</td>\n      <td>8</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>5</td>\n      <td>6</td>\n      <td>5</td>\n      <td>3</td>\n      <td>7</td>\n      <td>...</td>\n      <td>20.0</td>\n      <td>0.666667</td>\n      <td>4.0</td>\n      <td>24.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>-2.0</td>\n      <td>5.0</td>\n      <td>4.0</td>\n      <td>0.460</td>\n    </tr>\n    <tr>\n      <th>824195</th>\n      <td>6</td>\n      <td>2</td>\n      <td>6</td>\n      <td>5</td>\n      <td>7</td>\n      <td>6</td>\n      <td>5</td>\n      <td>7</td>\n      <td>4</td>\n      <td>5</td>\n      <td>...</td>\n      <td>35.0</td>\n      <td>1.666667</td>\n      <td>3.0</td>\n      <td>25.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>3.0</td>\n      <td>0.530</td>\n    </tr>\n    <tr>\n      <th>737977</th>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n      <td>6</td>\n      <td>6</td>\n      <td>8</td>\n      <td>4</td>\n      <td>3</td>\n      <td>...</td>\n      <td>64.0</td>\n      <td>1.000000</td>\n      <td>6.0</td>\n      <td>30.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>-2.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>0.485</td>\n    </tr>\n    <tr>\n      <th>556349</th>\n      <td>2</td>\n      <td>4</td>\n      <td>2</td>\n      <td>6</td>\n      <td>6</td>\n      <td>8</td>\n      <td>4</td>\n      <td>8</td>\n      <td>4</td>\n      <td>6</td>\n      <td>...</td>\n      <td>48.0</td>\n      <td>2.000000</td>\n      <td>2.0</td>\n      <td>12.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>-6.0</td>\n      <td>8.0</td>\n      <td>3.0</td>\n      <td>0.490</td>\n    </tr>\n    <tr>\n      <th>272243</th>\n      <td>4</td>\n      <td>7</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>6</td>\n      <td>8</td>\n      <td>2</td>\n      <td>2</td>\n      <td>9</td>\n      <td>...</td>\n      <td>10.0</td>\n      <td>2.500000</td>\n      <td>2.0</td>\n      <td>24.0</td>\n      <td>-3.0</td>\n      <td>4.0</td>\n      <td>-3.0</td>\n      <td>6.0</td>\n      <td>3.0</td>\n      <td>0.480</td>\n    </tr>\n  </tbody>\n</table>\n<p>200000 rows  321 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"cont_names,cat_names = cont_cat_split(merged_train_new, dep_var='FloodProbability')\nsplits = RandomSplitter(valid_pct=0.2)(range_of(merged_train_new))\nto = TabularPandas(merged_train_new, procs=[Categorify, FillMissing,Normalize],\n                   cat_names = cat_names,\n                   cont_names = cont_names,\n                   y_names='FloodProbability',\n                   y_block=RegressionBlock(),\n                   splits=splits)\nX_train, y_train = to.train.xs, to.train.ys.values.ravel()\nX_test, y_test = to.valid.xs, to.valid.ys.values.ravel()\ndls = to.dataloaders(bs=64)\n#test_dl = dls.test_dl(test_subset)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T15:00:23.558478Z","iopub.execute_input":"2024-05-24T15:00:23.559471Z","iopub.status.idle":"2024-05-24T15:00:28.592868Z","shell.execute_reply.started":"2024-05-24T15:00:23.559439Z","shell.execute_reply":"2024-05-24T15:00:28.591825Z"},"scrolled":true,"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n","output_type":"stream"}]},{"cell_type":"code","source":"learn1 = tabular_learner(dls, metrics=R2Score())\nlearn1.lr_find(suggest_funcs=(slide,valley))","metadata":{"execution":{"iopub.status.busy":"2024-05-24T15:00:40.766247Z","iopub.execute_input":"2024-05-24T15:00:40.76721Z","iopub.status.idle":"2024-05-24T15:00:44.752549Z","shell.execute_reply.started":"2024-05-24T15:00:40.767169Z","shell.execute_reply":"2024-05-24T15:00:44.751442Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"SuggestedLRs(slide=0.015848932787775993, valley=0.0008317637839354575)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"%%time\nlearn1.fit_one_cycle(12,0.02)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T15:00:44.75448Z","iopub.execute_input":"2024-05-24T15:00:44.755121Z","iopub.status.idle":"2024-05-24T15:12:20.660018Z","shell.execute_reply.started":"2024-05-24T15:00:44.755087Z","shell.execute_reply":"2024-05-24T15:12:20.659081Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>r2_score</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.000916</td>\n      <td>0.000868</td>\n      <td>0.669280</td>\n      <td>00:58</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.000552</td>\n      <td>0.000416</td>\n      <td>0.841683</td>\n      <td>01:00</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.000581</td>\n      <td>0.000484</td>\n      <td>0.815589</td>\n      <td>00:58</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.000585</td>\n      <td>0.000705</td>\n      <td>0.731460</td>\n      <td>00:59</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.000531</td>\n      <td>0.000405</td>\n      <td>0.845771</td>\n      <td>00:57</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.000521</td>\n      <td>0.000429</td>\n      <td>0.836653</td>\n      <td>00:57</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.000508</td>\n      <td>0.000397</td>\n      <td>0.848591</td>\n      <td>00:57</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.000464</td>\n      <td>0.000398</td>\n      <td>0.848526</td>\n      <td>00:57</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.000495</td>\n      <td>0.000382</td>\n      <td>0.854620</td>\n      <td>00:57</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.000461</td>\n      <td>0.000386</td>\n      <td>0.853070</td>\n      <td>00:57</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.000441</td>\n      <td>0.000388</td>\n      <td>0.852324</td>\n      <td>00:57</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.000436</td>\n      <td>0.000379</td>\n      <td>0.855586</td>\n      <td>00:57</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"name":"stdout","text":"CPU times: user 11min 32s, sys: 3.04 s, total: 11min 35s\nWall time: 11min 35s\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df.shape,train_new.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-24T15:12:20.661481Z","iopub.execute_input":"2024-05-24T15:12:20.661768Z","iopub.status.idle":"2024-05-24T15:12:20.667719Z","shell.execute_reply.started":"2024-05-24T15:12:20.661743Z","shell.execute_reply":"2024-05-24T15:12:20.66675Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"((1117957, 21), (200000, 320))"},"metadata":{}}]},{"cell_type":"code","source":"dl = learn1.dls.test_dl(test_new)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T15:14:32.414406Z","iopub.execute_input":"2024-05-24T15:14:32.41481Z","iopub.status.idle":"2024-05-24T15:14:33.387144Z","shell.execute_reply.started":"2024-05-24T15:14:32.414776Z","shell.execute_reply":"2024-05-24T15:14:33.3863Z"},"scrolled":true,"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nnn_preds = learn1.get_preds(dl=dl)\nnn_preds_x = learn1.get_preds()[0]\na_preds, _ = learn1.get_preds(dl=dl)\nnn_preds_y = a_preds.squeeze(1)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T15:14:40.135368Z","iopub.execute_input":"2024-05-24T15:14:40.136073Z","iopub.status.idle":"2024-05-24T15:16:15.898441Z","shell.execute_reply.started":"2024-05-24T15:14:40.13604Z","shell.execute_reply":"2024-05-24T15:16:15.896467Z"},"trusted":true},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"CPU times: user 1min 35s, sys: 1.42 s, total: 1min 36s\nWall time: 1min 35s\n","output_type":"stream"}]},{"cell_type":"code","source":"#dataset without original dataset,and using training subset with new openFE features\nr2_score(y_test,nn_preds_x)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T15:16:15.900004Z","iopub.execute_input":"2024-05-24T15:16:15.901924Z","iopub.status.idle":"2024-05-24T15:16:15.912907Z","shell.execute_reply.started":"2024-05-24T15:16:15.901895Z","shell.execute_reply":"2024-05-24T15:16:15.911596Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"0.8555863540227375"},"metadata":{}}]},{"cell_type":"markdown","source":"I believe the features add a slight improvement, next would be to add the original dataset and reduce the features","metadata":{}},{"cell_type":"markdown","source":"its better Uconcat probablyly throws an erro, so ","metadata":{}},{"cell_type":"code","source":"#train_final = pd.concat([train_x, train_new], axis=1) \n#test_final = pd.concat([test_x, test_new], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset Subset\n\nSince the dataset is large and takes a while to train, we can use a subset of the data for quick experimentation\n\n### Using random subset\n\nUsing a random subset results in better and faster training","metadata":{}},{"cell_type":"code","source":"#train_subset = train_df.sample(n=50000,replace=False)\n#test_subset = test_df.sample(n=30000,replace=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using Full Dataset","metadata":{}},{"cell_type":"code","source":"train_df.shape,train_final.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 'FloodProbability' in train_new.columns:\n    print(\"Column exists\")\nelse:\n    print(\"Column does not exist\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_new\ntrain_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merge train_new with train_df to add the 'FloodProbability' column\nmerged_train_new = pd.merge(train_new, train_df[['FloodProbability']], left_index=True, right_index=True)\nmerged_train_new","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merge train_new with train_df to add the 'FloodProbability' column\nmerged_train_new = pd.merge(train_new, train_subset[['FloodProbability']], left_index=True, right_index=True)\nmerged_train_new","metadata":{"execution":{"iopub.status.busy":"2024-05-24T04:23:18.811277Z","iopub.execute_input":"2024-05-24T04:23:18.811664Z","iopub.status.idle":"2024-05-24T04:23:19.078831Z","shell.execute_reply.started":"2024-05-24T04:23:18.811635Z","shell.execute_reply":"2024-05-24T04:23:19.07771Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"              MonsoonIntensity  TopographyDrainage  RiverManagement  \\\nopenfe_index                                                          \n503258                       7                   5                7   \n888180                       5                   5                8   \n1096427                      7                   3                5   \n357587                       7                   4                2   \n239801                       4                   7                7   \n...                        ...                 ...              ...   \n327058                       5                   4                1   \n819692                       2                   4                3   \n1111768                      4                   9                7   \n174703                       6                   8                6   \n875021                       4                   6                3   \n\n              Deforestation  Urbanization  ClimateChange  DamsQuality  \\\nopenfe_index                                                            \n503258                    8             3              6            5   \n888180                    5             5              5            7   \n1096427                   2             4              4            3   \n357587                   11             2              6            8   \n239801                   10             4              6            7   \n...                     ...           ...            ...          ...   \n327058                    8             3              4            4   \n819692                    4             7              7            7   \n1111768                   1             4              2            6   \n174703                    5             3              2            6   \n875021                    4             6              5            2   \n\n              Siltation  AgriculturalPractices  Encroachments  ...  \\\nopenfe_index                                                   ...   \n503258                4                      4              5  ...   \n888180                5                      3             11  ...   \n1096427               7                      7              4  ...   \n357587                6                      9              5  ...   \n239801                8                      4              1  ...   \n...                 ...                    ...            ...  ...   \n327058                4                      6              4  ...   \n819692                5                      5              6  ...   \n1111768               2                      4              6  ...   \n174703                6                      4              5  ...   \n875021                4                      2              8  ...   \n\n              autoFE_f_291  autoFE_f_292  autoFE_f_293  autoFE_f_294  \\\nopenfe_index                                                           \n503258                 0.0           9.0          12.0           7.0   \n888180                -1.0          10.0          10.0          14.0   \n1096427                5.0          10.0          12.0           9.0   \n357587                 4.0          17.0          12.0          14.0   \n239801                 3.0          11.0           8.0           9.0   \n...                    ...           ...           ...           ...   \n327058                 2.0          10.0           6.0           8.0   \n819692                -1.0          12.0          49.0          14.0   \n1111768               -1.0          10.0          16.0           9.0   \n174703                 2.0          10.0          15.0          10.0   \n875021                 0.0           4.0          30.0           9.0   \n\n              autoFE_f_295  autoFE_f_296  autoFE_f_297  autoFE_f_298  \\\nopenfe_index                                                           \n503258                 9.0           5.0           1.0          13.0   \n888180                14.0           7.0           1.0          10.0   \n1096427               11.0          10.0           3.0           5.0   \n357587                14.0           8.0           2.0          15.0   \n239801                 5.0           5.0           0.0          17.0   \n...                    ...           ...           ...           ...   \n327058                10.0           7.0           2.0          12.0   \n819692                11.0           6.0           1.0           8.0   \n1111768               10.0           3.0           2.0          10.0   \n174703                 9.0           6.0           1.0          13.0   \n875021                10.0           6.0           1.0          10.0   \n\n              autoFE_f_299  FloodProbability  \nopenfe_index                                  \n503258                 5.0             0.505  \n888180                11.0             0.590  \n1096427                7.0             0.515  \n357587                 6.0             0.540  \n239801                 8.0             0.560  \n...                    ...               ...  \n327058                 4.0             0.410  \n819692                 6.0             0.535  \n1111768                6.0             0.440  \n174703                 6.0             0.525  \n875021                 8.0             0.515  \n\n[200000 rows x 321 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MonsoonIntensity</th>\n      <th>TopographyDrainage</th>\n      <th>RiverManagement</th>\n      <th>Deforestation</th>\n      <th>Urbanization</th>\n      <th>ClimateChange</th>\n      <th>DamsQuality</th>\n      <th>Siltation</th>\n      <th>AgriculturalPractices</th>\n      <th>Encroachments</th>\n      <th>...</th>\n      <th>autoFE_f_291</th>\n      <th>autoFE_f_292</th>\n      <th>autoFE_f_293</th>\n      <th>autoFE_f_294</th>\n      <th>autoFE_f_295</th>\n      <th>autoFE_f_296</th>\n      <th>autoFE_f_297</th>\n      <th>autoFE_f_298</th>\n      <th>autoFE_f_299</th>\n      <th>FloodProbability</th>\n    </tr>\n    <tr>\n      <th>openfe_index</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>503258</th>\n      <td>7</td>\n      <td>5</td>\n      <td>7</td>\n      <td>8</td>\n      <td>3</td>\n      <td>6</td>\n      <td>5</td>\n      <td>4</td>\n      <td>4</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>9.0</td>\n      <td>12.0</td>\n      <td>7.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>13.0</td>\n      <td>5.0</td>\n      <td>0.505</td>\n    </tr>\n    <tr>\n      <th>888180</th>\n      <td>5</td>\n      <td>5</td>\n      <td>8</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>7</td>\n      <td>5</td>\n      <td>3</td>\n      <td>11</td>\n      <td>...</td>\n      <td>-1.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>14.0</td>\n      <td>14.0</td>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>11.0</td>\n      <td>0.590</td>\n    </tr>\n    <tr>\n      <th>1096427</th>\n      <td>7</td>\n      <td>3</td>\n      <td>5</td>\n      <td>2</td>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>7</td>\n      <td>7</td>\n      <td>4</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>10.0</td>\n      <td>12.0</td>\n      <td>9.0</td>\n      <td>11.0</td>\n      <td>10.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>0.515</td>\n    </tr>\n    <tr>\n      <th>357587</th>\n      <td>7</td>\n      <td>4</td>\n      <td>2</td>\n      <td>11</td>\n      <td>2</td>\n      <td>6</td>\n      <td>8</td>\n      <td>6</td>\n      <td>9</td>\n      <td>5</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>17.0</td>\n      <td>12.0</td>\n      <td>14.0</td>\n      <td>14.0</td>\n      <td>8.0</td>\n      <td>2.0</td>\n      <td>15.0</td>\n      <td>6.0</td>\n      <td>0.540</td>\n    </tr>\n    <tr>\n      <th>239801</th>\n      <td>4</td>\n      <td>7</td>\n      <td>7</td>\n      <td>10</td>\n      <td>4</td>\n      <td>6</td>\n      <td>7</td>\n      <td>8</td>\n      <td>4</td>\n      <td>1</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>11.0</td>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>17.0</td>\n      <td>8.0</td>\n      <td>0.560</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>327058</th>\n      <td>5</td>\n      <td>4</td>\n      <td>1</td>\n      <td>8</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>6</td>\n      <td>4</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>10.0</td>\n      <td>6.0</td>\n      <td>8.0</td>\n      <td>10.0</td>\n      <td>7.0</td>\n      <td>2.0</td>\n      <td>12.0</td>\n      <td>4.0</td>\n      <td>0.410</td>\n    </tr>\n    <tr>\n      <th>819692</th>\n      <td>2</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n      <td>7</td>\n      <td>7</td>\n      <td>7</td>\n      <td>5</td>\n      <td>5</td>\n      <td>6</td>\n      <td>...</td>\n      <td>-1.0</td>\n      <td>12.0</td>\n      <td>49.0</td>\n      <td>14.0</td>\n      <td>11.0</td>\n      <td>6.0</td>\n      <td>1.0</td>\n      <td>8.0</td>\n      <td>6.0</td>\n      <td>0.535</td>\n    </tr>\n    <tr>\n      <th>1111768</th>\n      <td>4</td>\n      <td>9</td>\n      <td>7</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2</td>\n      <td>6</td>\n      <td>2</td>\n      <td>4</td>\n      <td>6</td>\n      <td>...</td>\n      <td>-1.0</td>\n      <td>10.0</td>\n      <td>16.0</td>\n      <td>9.0</td>\n      <td>10.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>10.0</td>\n      <td>6.0</td>\n      <td>0.440</td>\n    </tr>\n    <tr>\n      <th>174703</th>\n      <td>6</td>\n      <td>8</td>\n      <td>6</td>\n      <td>5</td>\n      <td>3</td>\n      <td>2</td>\n      <td>6</td>\n      <td>6</td>\n      <td>4</td>\n      <td>5</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>10.0</td>\n      <td>15.0</td>\n      <td>10.0</td>\n      <td>9.0</td>\n      <td>6.0</td>\n      <td>1.0</td>\n      <td>13.0</td>\n      <td>6.0</td>\n      <td>0.525</td>\n    </tr>\n    <tr>\n      <th>875021</th>\n      <td>4</td>\n      <td>6</td>\n      <td>3</td>\n      <td>4</td>\n      <td>6</td>\n      <td>5</td>\n      <td>2</td>\n      <td>4</td>\n      <td>2</td>\n      <td>8</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>30.0</td>\n      <td>9.0</td>\n      <td>10.0</td>\n      <td>6.0</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>8.0</td>\n      <td>0.515</td>\n    </tr>\n  </tbody>\n</table>\n<p>200000 rows  321 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"cont_names,cat_names = cont_cat_split(merged_train_new, dep_var='FloodProbability')","metadata":{"execution":{"iopub.status.busy":"2024-05-24T04:23:24.791659Z","iopub.execute_input":"2024-05-24T04:23:24.792478Z","iopub.status.idle":"2024-05-24T04:23:24.837036Z","shell.execute_reply.started":"2024-05-24T04:23:24.792443Z","shell.execute_reply":"2024-05-24T04:23:24.836262Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"splits = RandomSplitter(valid_pct=0.2)(range_of(merged_train_new))","metadata":{"execution":{"iopub.status.busy":"2024-05-24T04:23:25.934179Z","iopub.execute_input":"2024-05-24T04:23:25.934554Z","iopub.status.idle":"2024-05-24T04:23:25.981335Z","shell.execute_reply.started":"2024-05-24T04:23:25.934515Z","shell.execute_reply":"2024-05-24T04:23:25.980558Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"to = TabularPandas(merged_train_new, procs=[Categorify, FillMissing,Normalize],\n                   cat_names = cat_names,\n                   cont_names = cont_names,\n                   y_names='FloodProbability',\n                   y_block=RegressionBlock(),\n                   splits=splits)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-24T04:23:26.583217Z","iopub.execute_input":"2024-05-24T04:23:26.584099Z","iopub.status.idle":"2024-05-24T04:23:30.646009Z","shell.execute_reply.started":"2024-05-24T04:23:26.584049Z","shell.execute_reply":"2024-05-24T04:23:30.645132Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train, y_train = to.train.xs, to.train.ys.values.ravel()\nX_test, y_test = to.valid.xs, to.valid.ys.values.ravel()","metadata":{"execution":{"iopub.status.busy":"2024-05-24T04:23:30.647809Z","iopub.execute_input":"2024-05-24T04:23:30.648096Z","iopub.status.idle":"2024-05-24T04:23:31.106853Z","shell.execute_reply.started":"2024-05-24T04:23:30.648071Z","shell.execute_reply":"2024-05-24T04:23:31.105957Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"dls = to.dataloaders(bs=64)\ntest_dl = dls.test_dl(test_new)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-24T04:23:31.108011Z","iopub.execute_input":"2024-05-24T04:23:31.108322Z","iopub.status.idle":"2024-05-24T04:23:32.294039Z","shell.execute_reply.started":"2024-05-24T04:23:31.108296Z","shell.execute_reply":"2024-05-24T04:23:32.2931Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Assuming 'df' is your DataFrame\nmerged_train_new.to_csv('merged_train_new.csv', index=False, encoding='utf-8')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_train_new.to_pickle('merged_train_new.pkl')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FileLink('merged_train_new.csv')\nFileLink('merged_train_new.pkl')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest Baseline\n\nWe initially use a random forest as a baseline since it is a really simple model that doesnt break easily with small changes in the hyperparameters etc. \n\nWe can also easily use this for explanability with features such as feature importance.","metadata":{}},{"cell_type":"code","source":"%%time\nrf = RandomForestRegressor(50, min_samples_leaf=3)\nrf_model = rf.fit(X_train, y_train);\n\nrf_preds = tensor(rf_model.predict(test_dl.xs))\n\nrf_preds_x = tensor(rf_model.predict(X_test))\n\nmse = mean_absolute_error(y_test, rf_preds_x)\nrmse = np.sqrt(mse)\n\nr2_score(y_test,rf_preds_x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Neural Network Baseline","metadata":{}},{"cell_type":"code","source":"learn = tabular_learner(dls, metrics=R2Score())\nlearn.lr_find(suggest_funcs=(slide,valley))","metadata":{"execution":{"iopub.status.busy":"2024-05-24T04:23:43.513479Z","iopub.execute_input":"2024-05-24T04:23:43.514159Z","iopub.status.idle":"2024-05-24T04:23:46.363049Z","shell.execute_reply.started":"2024-05-24T04:23:43.514126Z","shell.execute_reply":"2024-05-24T04:23:46.362124Z"},"trusted":true},"execution_count":63,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"SuggestedLRs(slide=0.013182567432522774, valley=0.0006918309954926372)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"#%%time\n#learn.fit_one_cycle(12,lr_max=slice(learn.valley))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nlearn.fit_one_cycle(12,0.02)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T04:23:52.144083Z","iopub.execute_input":"2024-05-24T04:23:52.144947Z","iopub.status.idle":"2024-05-24T04:35:52.249073Z","shell.execute_reply.started":"2024-05-24T04:23:52.144912Z","shell.execute_reply":"2024-05-24T04:35:52.248183Z"},"trusted":true},"execution_count":64,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>r2_score</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.000801</td>\n      <td>0.000551</td>\n      <td>0.790989</td>\n      <td>00:59</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.000516</td>\n      <td>0.000424</td>\n      <td>0.839318</td>\n      <td>00:59</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.000527</td>\n      <td>0.000408</td>\n      <td>0.845371</td>\n      <td>00:59</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.000550</td>\n      <td>0.000400</td>\n      <td>0.848317</td>\n      <td>00:59</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.000527</td>\n      <td>0.000433</td>\n      <td>0.835932</td>\n      <td>00:59</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.000542</td>\n      <td>0.000515</td>\n      <td>0.804943</td>\n      <td>00:59</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.000499</td>\n      <td>0.000429</td>\n      <td>0.837430</td>\n      <td>00:59</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.000481</td>\n      <td>0.000383</td>\n      <td>0.854681</td>\n      <td>01:00</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.000478</td>\n      <td>0.000392</td>\n      <td>0.851478</td>\n      <td>01:00</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.000464</td>\n      <td>0.000381</td>\n      <td>0.855584</td>\n      <td>01:01</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.000444</td>\n      <td>0.000371</td>\n      <td>0.859205</td>\n      <td>01:00</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.000445</td>\n      <td>0.000368</td>\n      <td>0.860320</td>\n      <td>01:00</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"name":"stdout","text":"CPU times: user 11min 56s, sys: 2.9 s, total: 11min 59s\nWall time: 12min\n","output_type":"stream"}]},{"cell_type":"code","source":"dl = learn.dls.test_dl(test_new)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-24T04:35:52.250902Z","iopub.execute_input":"2024-05-24T04:35:52.25119Z","iopub.status.idle":"2024-05-24T04:35:53.494886Z","shell.execute_reply.started":"2024-05-24T04:35:52.251165Z","shell.execute_reply":"2024-05-24T04:35:53.493941Z"},"scrolled":true,"trusted":true},"execution_count":65,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nnn_preds = learn.get_preds(dl=dl)\nnn_preds_x = learn.get_preds()[0]\na_preds, _ = learn.get_preds(dl=dl)\nnn_preds_y = a_preds.squeeze(1)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T04:35:53.49593Z","iopub.execute_input":"2024-05-24T04:35:53.496267Z","iopub.status.idle":"2024-05-24T04:37:33.916664Z","shell.execute_reply.started":"2024-05-24T04:35:53.49624Z","shell.execute_reply":"2024-05-24T04:37:33.915682Z"},"trusted":true},"execution_count":66,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"CPU times: user 1min 39s, sys: 1.47 s, total: 1min 41s\nWall time: 1min 40s\n","output_type":"stream"}]},{"cell_type":"code","source":"learn.export('models/fp_model.pkl')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#learn.load('fp_model.pkl')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dataset no original training subset with new openFE features\nr2_score(y_test,nn_preds_x)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T15:18:05.853863Z","iopub.execute_input":"2024-05-24T15:18:05.85426Z","iopub.status.idle":"2024-05-24T15:18:05.863498Z","shell.execute_reply.started":"2024-05-24T15:18:05.854232Z","shell.execute_reply":"2024-05-24T15:18:05.862383Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"0.8555863540227375"},"metadata":{}}]},{"cell_type":"code","source":"#dataset no original training subset with new openFE features\nr2_score(y_test,nn_preds_x)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T07:19:49.928315Z","iopub.execute_input":"2024-05-24T07:19:49.929232Z","iopub.status.idle":"2024-05-24T07:19:49.96458Z","shell.execute_reply.started":"2024-05-24T07:19:49.929193Z","shell.execute_reply":"2024-05-24T07:19:49.963268Z"},"trusted":true},"execution_count":4,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#dataset no original training subset with new openFE features\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m r2_score(\u001b[43my_test\u001b[49m,nn_preds_x)\n","\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"],"ename":"NameError","evalue":"name 'y_test' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"# Neural Network Ensemble","metadata":{}},{"cell_type":"code","source":"def ensemble():\n    learn = tabular_learner(dls, metrics=RocAucMulti())\n    with learn.no_bar(),learn.no_logging(): learn.fit(6, 0.02)\n    return learn.get_preds(dl=dl)[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learns = [ensemble() for _ in range(5)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ens_preds = torch.stack(learns).mean(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nn_preds_x.shape,ens_preds.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r2_score(y_test,nn_preds_x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_preds = nn_preds[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['FloodProbability'] = target_preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.to_csv('submission.csv', columns=['FloodProbability'], index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('submission.csv')\nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm submission.csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['FloodProbability'] = target_preds\ntest_df.to_csv('submission.csv', columns=['FloodProbability'], index=True)\n\nsubmission = pd.read_csv('submission.csv')\nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest Baseline","metadata":{}},{"cell_type":"code","source":"rf = RandomForestRegressor(100, min_samples_leaf=3)\nrf_model = rf.fit(X_train, y_train);\n\nrf_preds = tensor(rf_model.predict(test_dl.xs))\n\nrf_preds_x = tensor(rf_model.predict(X_test))\n\nmse = mean_absolute_error(y_test, rf_preds_x)\nrmse = np.sqrt(mse)\n\nr2_score(y_test,rf_preds_x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Optimize Params with Optuna","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CatBoost - Optuna","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom catboost import CatBoostRegressor\nfrom sklearn.metrics import r2_score\n\nimport optuna\nfrom catboost import CatBoostRegressor\nfrom sklearn.metrics import mean_squared_error\n\ndef objective_catboost(trial):\n    params = {\n        \"iterations\": 200,\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n        \"depth\": trial.suggest_int(\"depth\", 1, 10),\n        \"random_strength\": trial.suggest_int(\"random_strength\", 1, 10),\n    }\n    model = CatBoostRegressor(**params, silent=True)\n    model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False)\n    cat_predictions = model.predict(X_test)\n    r2score = r2_score(y_test, cat_predictions)\n    return r2score\n\n\nstudy_catboost = optuna.create_study(direction='minimize')\nstudy_catboost.optimize(objective_catboost, n_trials=200)\nprint(study_catboost.best_params)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LightGBM - Optuna","metadata":{}},{"cell_type":"code","source":"%%time\n\ndef objective_lgbm(trial):\n    params = {\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 50),\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 200),\n    }\n    model = lgb.LGBMRegressor(**params)\n    model.fit(X_train, y_train)\n    lgb_predictions = model.predict(X_test)\n    r2score = r2_score(y_test, lgb_predictions)\n    return r2score\n\n\nstudy_lgbm = optuna.create_study(direction='minimize')\nstudy_lgbm.optimize(objective_lgbm, n_trials=50)\nprint(study_lgbm.best_params)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ndef objective_lgbm(trial):\n    params = {\n            'num_leaves': trial.suggest_int('num_leaves', 100, 500),\n            'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0, log=True),\n            'n_estimators': trial.suggest_int('n_estimators', 300, 1200),\n            'subsample_for_bin': trial.suggest_int('subsample_for_bin', 20000, 300000),\n            'min_child_samples': trial.suggest_int('min_child_samples', 20, 500),\n            'reg_alpha': trial.suggest_float('reg_alpha', 1e-9, 10.0, log=True),\n            'reg_lambda': trial.suggest_float('reg_lambda', 1e-9, 10.0, log=True),\n            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n            'subsample': trial.suggest_float('subsample', 0.25, 1.0),\n            'max_depth': trial.suggest_int('max_depth', 1, 15)\n            }\n    \n    model = lgb.LGBMRegressor(**params,verbose=False)\n    model.fit(X_train, y_train)\n    lgb_predictions = model.predict(X_test)\n    r2score = r2_score(y_test, lgb_predictions)\n    return r2score\n\n\nstudy_lgbm = optuna.create_study(direction='minimize')\nstudy_lgbm.optimize(objective_lgbm, n_trials=100)\nprint(study_lgbm.best_params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function Optuna\ndef objective(trial):\n    # Define parameters to be optimized\n    params = {\n            'num_leaves': trial.suggest_int('num_leaves', 100, 500),\n            'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0, log=True),\n            'n_estimators': trial.suggest_int('n_estimators', 300, 1200),\n            'subsample_for_bin': trial.suggest_int('subsample_for_bin', 20000, 300000),\n            'min_child_samples': trial.suggest_int('min_child_samples', 20, 500),\n            'reg_alpha': trial.suggest_float('reg_alpha', 1e-9, 10.0, log=True),\n            'reg_lambda': trial.suggest_float('reg_lambda', 1e-9, 10.0, log=True),\n            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n            'subsample': trial.suggest_float('subsample', 0.25, 1.0),\n            'max_depth': trial.suggest_int('max_depth', 1, 15)\n            }\n    \n    # Train the model\n    model = LGBMRegressor(**params, objective='regression', random_state=0, device='gpu', verbosity=-1)\n    model.fit(X_train, y_train)\n    \n    lgb_predictions = model.predict(X_test)\n    r2score = r2_score(y_test, lgb_predictions)\n    return r2score\n    \n   \n\n# Create a study object and optimize the objective function\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=100)\n\n# Get the best parameters and best R^2 score\nbest_params = study.best_params\nbest_r2 = study.best_value\n\nprint(\"Best R^2 score:\", best_r2)\nprint(\"Best parameters:\", best_params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"XGBoost - Optuna","metadata":{}},{"cell_type":"code","source":"def objective_xgboost(trial):\n    params = {\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 200),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 10),\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n        \"subsample\": trial.suggest_float(\"subsample\", 0.1, 1.0),\n    }\n    model = xgb.XGBRegressor(**params)\n    model.fit(X_train, y_train)\n    xgb_predictions = model.predict(X_test)\n    rmse = mean_squared_error(y_test, xgb_predictions, squared=False)\n    return rmse\n\nstudy_xgboost = optuna.create_study(direction='minimize')\nstudy_xgboost.optimize(objective_xgboost, n_trials=150)\nprint(study_xgboost.best_params)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CatBoost Baseline","metadata":{}},{"cell_type":"code","source":"#with optuna params\ncat_model = CatBoostRegressor(iterations=2000, depth=9, learning_rate= 0.29776650862748444, random_strength=3)\ncat_model = cat_model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False)\n\n#test set preds\ncat_preds = tensor(cat_model.predict(test_dl.xs))\n\n#validation set preds\ncat_preds_x = tensor(cat_model.predict(X_test))\n\nr2_score(y_test,cat_preds_x)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T04:37:33.928539Z","iopub.execute_input":"2024-05-24T04:37:33.928882Z","iopub.status.idle":"2024-05-24T04:45:25.01957Z","shell.execute_reply.started":"2024-05-24T04:37:33.92885Z","shell.execute_reply":"2024-05-24T04:45:25.018528Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"0.8414981959259584"},"metadata":{}}]},{"cell_type":"code","source":"print(study_catboost.best_params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#with optuna params\ncat_model = CatBoostRegressor(iterations=1441, depth=1, learning_rate= 0.01000456241465664, random_strength=10)\ncat_model = cat_model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False)\n\n#test set preds\ncat_preds = tensor(cat_model.predict(test_dl.xs))\n\n#validation set preds\ncat_preds_x = tensor(cat_model.predict(X_test))\n\nr2_score(y_test,cat_preds_x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#with optuna params\ncat_model = CatBoostRegressor(iterations=50=00, depth=1, learning_rate= 0.01000456241465664, random_strength=10)\ncat_model = cat_model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False)\n\n#test set preds\ncat_preds = tensor(cat_model.predict(test_dl.xs))\n\n#validation set preds\ncat_preds_x = tensor(cat_model.predict(X_test))\n\nr2_score(y_test,cat_preds_x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#with optuna params\ncat_model = CatBoostRegressor(depth=1, learning_rate= 0.01000456241465664, random_strength=10)\ncat_model = cat_model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False)\n\n#test set preds\ncat_preds = tensor(cat_model.predict(test_dl.xs))\n\n#validation set preds\ncat_preds_x = tensor(cat_model.predict(X_test))\n\nr2_score(y_test,cat_preds_x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Light GBM","metadata":{}},{"cell_type":"markdown","source":"optuna params","metadata":{}},{"cell_type":"code","source":"%%time\n\ndef objective_lgbm(trial):\n    params = {\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 50),\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 200),\n    }\n    model = lgb.LGBMRegressor(**params)\n    model.fit(X_train, y_train)\n    lgb_predictions = model.predict(X_test)\n    r2score = r2_score(y_test, lgb_predictions)\n    return r2score\n\n\nstudy_lgbm = optuna.create_study(direction='minimize')\nstudy_lgbm.optimize(objective_lgbm, n_trials=50)\nprint(study_lgbm.best_params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(study_lgbm.best_params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\n\ndef objective_lgbm(trial):\n    params = {\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 50),\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 200),\n    }\n    model = lgb.LGBMRegressor(**params)\n    model.fit(X_train, y_train)\n    lgb_predictions = model.predict(X_test)\n    r2score = r2_score(y_test, lgb_predictions)\n    return r2score\n\n\nstudy_lgbm = optuna.create_study(direction='minimize')\nstudy_lgbm.optimize(objective_lgbm, n_trials=100)\nprint(study_lgbm.best_params)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\n\ndef objective_lgbm(trial):\n    params = {\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 50),\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 200),\n    }\n    model = lgb.LGBMRegressor(**params)\n    model.fit(X_train, y_train)\n    lgb_predictions = model.predict(X_test)\n    r2score = r2_score(y_test, lgb_predictions)\n    return r2score\n\n\nstudy_lgbm = optuna.create_study(direction='minimize')\nstudy_lgbm.optimize(objective_lgbm, n_trials=150)\nprint(study_lgbm.best_params)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"{'num_leaves': 26, 'learning_rate': 0.01001653579832905, 'n_estimators': 110}\n{'num_leaves': 25, 'learning_rate': 0.010094365133109197, 'n_estimators': 100}\n{'num_leaves': 20, 'learning_rate': 0.010218030489864638, 'n_estimators': 100} - 150 trials","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_model = lgb.LGBMRegressor(num_leaves=26, learning_rate=0.01001653579832905, n_estimators=110)\nlgb_model = lgb_model.fit(X_train, y_train)\n\n#test set preds\nlgb_preds = tensor(lgb_model.predict(test_dl.xs))\n\n#validation set preds\nlgb_preds_x = tensor(lgb_model.predict(X_test))\n\nlgb_score = r2_score(y_test,lgb_preds_x)\nlgb_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#100 trials\nlgb_model = lgb.LGBMRegressor(num_leaves=25, learning_rate=0.010094365133109197, n_estimators=100)\nlgb_model = lgb_model.fit(X_train, y_train)\n\n#test set preds\nlgb_preds = tensor(lgb_model.predict(test_dl.xs))\n\n#validation set preds\nlgb_preds_x = tensor(lgb_model.predict(X_test))\n\nlgb_score = r2_score(y_test,lgb_preds_x)\nlgb_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#150 trials\nlgb_model = lgb.LGBMRegressor(num_leaves=20, learning_rate=0.010218030489864638, n_estimators=100)\nlgb_model = lgb_model.fit(X_train, y_train)\n\n#test set preds\nlgb_preds = tensor(lgb_model.predict(test_dl.xs))\n\n#validation set preds\nlgb_preds_x = tensor(lgb_model.predict(X_test))\n\nlgb_score = r2_score(y_test,lgb_preds_x)\nlgb_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_model = lgb.LGBMRegressor(num_leaves=435, learning_rate=0.0137267854143469, n_estimators=380, max_depth=1,min_child_samples=171, subsample_for_bin=161411, reg_alpha=4.885489650124004, reg_lambda=0.3204538963056391, colsample_bytree =  0.8025591720341736, subsample= 0.8291001995890841)\nlgb_model = lgb_model.fit(X_train, y_train)\n\n#test set preds\nlgb_preds = tensor(lgb_model.predict(test_dl.xs))\n\n#validation set preds\nlgb_preds_x = tensor(lgb_model.predict(X_test))\n\nlgb_score = r2_score(y_test,lgb_preds_x)\nlgb_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_model = lgb.LGBMRegressor(num_leaves=435, learning_rate=0.0137267854143469, n_estimators=380, max_depth=1, boosting_type='gbdt',min_child_samples=171, random_state=27,subsample_for_bin=161411, reg_alpha=4.885489650124004, reg_lambda=0.3204538963056391, colsample_bytree =  0.8025591720341736, subsample= 0.8291001995890841)\nlgb_model = lgb_model.fit(X_train, y_train)\n\n#test set preds\nlgb_preds = tensor(lgb_model.predict(test_dl.xs))\n\n#validation set preds\nlgb_preds_x = tensor(lgb_model.predict(X_test))\n\nlgb_score = r2_score(y_test,lgb_preds_x)\nlgb_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Initial baseline","metadata":{}},{"cell_type":"code","source":"lgb_model = lgb.LGBMRegressor(num_leaves=500, learning_rate=0.02956613668999794, n_estimators=483, max_depth=82, boosting_type='gbdt',min_child_samples=90, random_state=27,subsample_for_bin=20698, reg_alpha=1.12032585776774e-09, reg_lambda=3.2869705488456358, colsample_bytree =  0.5441783735468184, subsample= 0.9370755150709044)\nlgb_model = lgb_model.fit(X_train, y_train)\n\n#test set preds\nlgb_preds = tensor(lgb_model.predict(test_dl.xs))\n\n#validation set preds\nlgb_preds_x = tensor(lgb_model.predict(X_test))\n\nlgb_score = r2_score(y_test,lgb_preds_x)\nlgb_score","metadata":{"execution":{"iopub.status.busy":"2024-05-24T04:45:25.02144Z","iopub.execute_input":"2024-05-24T04:45:25.02177Z","iopub.status.idle":"2024-05-24T04:48:21.892802Z","shell.execute_reply.started":"2024-05-24T04:45:25.021744Z","shell.execute_reply":"2024-05-24T04:48:21.891675Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.483800 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14139\n[LightGBM] [Info] Number of data points in the train set: 160000, number of used features: 360\n[LightGBM] [Info] Start training from score 0.504670\n","output_type":"stream"},{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"0.8407008170872311"},"metadata":{}}]},{"cell_type":"code","source":"submit = pd.read_csv(path/'sample_submission.csv')\nsubmit['FloodProbability'] = lgb_preds\nsubmit.to_csv('submission.csv', index=False)\nsub = pd.read_csv('submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBoost","metadata":{}},{"cell_type":"code","source":"xgb_model = xgb.XGBRegressor(n_estimators = 196, max_depth=5, learning_rate=0.1461774202844157, subsample= 0.6649609199174655)\nxgb_model = xgb_model.fit(X_train, y_train)\n\nxgb_preds = tensor(xgb_model.predict(test_dl.xs))\n\nxgb_preds_x = tensor(xgb_model.predict(X_test))\n\nr2_score(y_test,xgb_preds_x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# General Ensemble","metadata":{}},{"cell_type":"code","source":"nn_preds_m = nn_preds_x.squeeze()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for r2_Score testing\ngeneral_preds = (lgb_preds_x + xgb_preds_x + cat_preds_x + nn_preds_m)/4\ngeneral_preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for r2_Score testing\ngeneral_preds = ( cat_preds_x + nn_preds_m)/2\ngeneral_preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r2_score(y_test,general_preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r2_score(y_test,general_preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"general_preds.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#use for submission\ngeneral_preds = (cat_preds + nn_preds_y)/2             \ngeneral_preds","metadata":{"execution":{"iopub.status.busy":"2024-05-24T04:48:21.894393Z","iopub.execute_input":"2024-05-24T04:48:21.894709Z","iopub.status.idle":"2024-05-24T04:48:21.91105Z","shell.execute_reply.started":"2024-05-24T04:48:21.894684Z","shell.execute_reply":"2024-05-24T04:48:21.910189Z"},"trusted":true},"execution_count":70,"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"tensor([0.4167, 0.4979, 0.5194,  ..., 0.4967, 0.4833, 0.4927])"},"metadata":{}}]},{"cell_type":"markdown","source":"# Scoring","metadata":{}},{"cell_type":"code","source":"submit = pd.read_csv(path/'sample_submission.csv')\nsubmit['FloodProbability'] = general_preds\nsubmit.to_csv('submission.csv', index=False)\nsub = pd.read_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-24T04:48:21.912269Z","iopub.execute_input":"2024-05-24T04:48:21.912537Z","iopub.status.idle":"2024-05-24T04:48:22.866697Z","shell.execute_reply.started":"2024-05-24T04:48:21.912514Z","shell.execute_reply":"2024-05-24T04:48:22.865327Z"},"trusted":true},"execution_count":71,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[71], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m submit \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(path\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_submission.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43msubmit\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFloodProbability\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m general_preds\n\u001b[1;32m      3\u001b[0m submit\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubmission.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m sub \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubmission.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:4311\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   4309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4310\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 4311\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:4524\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4515\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4516\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4517\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4522\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4523\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4524\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4527\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4528\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4529\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m   4530\u001b[0m     ):\n\u001b[1;32m   4531\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4532\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:5266\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   5265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 5266\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5267\u001b[0m arr \u001b[38;5;241m=\u001b[39m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   5268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5269\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[1;32m   5270\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5273\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[1;32m   5274\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/common.py:573\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m     )\n","\u001b[0;31mValueError\u001b[0m: Length of values (150000) does not match length of index (745305)"],"ename":"ValueError","evalue":"Length of values (150000) does not match length of index (745305)","output_type":"error"}]},{"cell_type":"code","source":"!ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm submission.csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective_lgbm(trial):\n    params = {\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 50),\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 200),\n    }\n    model = lgb.LGBMRegressor(**params)\n    model.fit(X_train, y_train)\n    lgb_predictions = model.predict(X_test)\n    r2score = r2_score(y_test, lgb_predictions)\n    return r2score\n\n# Create a study\nstudy_lgbm = optuna.create_study(direction='minimize')\n\n# Convert the study to a distributed study\nstudy_lgbm = optuna_distributed.from_study(study_lgbm)\n\n# Run the optimization with parallel processing\nnum_parallel_jobs = 4 # Adjust this based on your system's capabilities\nstudy_lgbm.optimize(objective_lgbm, n_trials=100, n_jobs=num_parallel_jobs)\n\nprint(study_lgbm.best_params)\n","metadata":{},"execution_count":null,"outputs":[]}]}