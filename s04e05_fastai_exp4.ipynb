{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 73278,
          "databundleVersionId": 8121328,
          "sourceType": "competition"
        },
        {
          "sourceId": 7277740,
          "sourceType": "datasetVersion",
          "datasetId": 4219453
        }
      ],
      "dockerImageVersionId": 30698,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rubanzasilva/flood_probability/blob/main/s04e05_fastai_exp4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'playground-series-s4e5:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F73278%2F8121328%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240531%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240531T093348Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D0cfc7cbdaaff5c2328e1a59166ee657772a88b843c007aa91e3996cd17c0b3152d5e2106c2a385d806a5a41d6b9bd9456feeb28e6a3237a83032c45b15da90e7fd4866b70140d2fadc229ccd481434cbadb2c52312c7b3fc7b8ca5105e17e89586549cab20ce84ee2f18fd0d2e49fc7f3d7d83876eaf4c1936ef3ddccf2117b8ba8b0e1b2a0dd89449f6b705fcc50c93ff4209ea047e090895292ab1a1262e3d9e3fc5623698b27174ca63b4e5790fde65f15941899f4641130b7ddc987110cf42abe798898aad9387215ed9fc4811e09e3decc11dd5bda298c2a80b3ffb9ddd3748faf691b24f0a25542f4f09deec53b8c75b03afefd970ecbf0668a757953b,flood-prediction-factors:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4219453%2F7277740%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240531%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240531T093348Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D19a3cb146aa763cdc5d2d6d2ab82c48486a8726f63adb41a9d43da824c5359bfcdb74ea224a32eb0e704010c5de50ff11cc4dc108f6867a57673453ed8447a9594023600d4e6d806fe3c50d2ce8afadc779da07d86eae8accc4ca76a7a9de628c7e159a5b5d750fd6b7c6b8cf85d632a55aef00d5e7d2618eb31ad7492f931955091f6f72b77e516f93adf790ae9cbb0a01179bfcbf7c87b746352ad7338aa5474feb33677477cfacec814584ded86c5522bb119f185e1837de3a34a72ebac45d5daf398d546dda159985da5b287bdd56aed99277c6931d2d329b30d8a19892e17388678c2ea554a74ee4c85a53f8f8a4c90b0aa566f6db41393dc6076ae1388'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "LCXA4_R9_8IB"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression with a Flood Prediction Dataset\n",
        "\n",
        "Playground Series - Season 4, Episode 5 where we are tasked with predicting the likelihood of floods in certain areas based off various factors."
      ],
      "metadata": {
        "id": "E4JL4SYG_8IV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports\n",
        "\n",
        "Below, i import all the libraries and datasets needed for this competition."
      ],
      "metadata": {
        "id": "YRiKSLsk_8Ia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_kg_hide-output": true,
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-05-31T09:32:02.524722Z",
          "iopub.execute_input": "2024-05-31T09:32:02.525121Z",
          "iopub.status.idle": "2024-05-31T09:32:02.536982Z",
          "shell.execute_reply.started": "2024-05-31T09:32:02.525091Z",
          "shell.execute_reply": "2024-05-31T09:32:02.535754Z"
        },
        "trusted": true,
        "id": "VgRcjoA1_8Id",
        "outputId": "c3ec73cf-efb5-4fe1-f9f1-8abd563f1377"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/flood-prediction-factors/flood.csv\n/kaggle/input/playground-series-s4e5/sample_submission.csv\n/kaggle/input/playground-series-s4e5/train.csv\n/kaggle/input/playground-series-s4e5/test.csv\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openfe"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2024-05-31T09:32:02.884698Z",
          "iopub.execute_input": "2024-05-31T09:32:02.885063Z",
          "iopub.status.idle": "2024-05-31T09:32:16.374333Z",
          "shell.execute_reply.started": "2024-05-31T09:32:02.885037Z",
          "shell.execute_reply": "2024-05-31T09:32:16.373095Z"
        },
        "trusted": true,
        "id": "MVFLmLWg_8Ih",
        "outputId": "bf8f17ec-155b-4784-9249-1df06385ab58"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting openfe\n  Downloading openfe-0.0.12-py3-none-any.whl.metadata (667 bytes)\nRequirement already satisfied: numpy>=1.19.3 in /opt/conda/lib/python3.10/site-packages (from openfe) (1.26.4)\nRequirement already satisfied: pandas>=1.1.5 in /opt/conda/lib/python3.10/site-packages (from openfe) (2.2.2)\nRequirement already satisfied: scikit-learn>=0.24.2 in /opt/conda/lib/python3.10/site-packages (from openfe) (1.2.2)\nRequirement already satisfied: lightgbm>=3.3.2 in /opt/conda/lib/python3.10/site-packages (from openfe) (4.2.0)\nRequirement already satisfied: scipy>=1.5.4 in /opt/conda/lib/python3.10/site-packages (from openfe) (1.11.4)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openfe) (4.66.1)\nRequirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (from openfe) (15.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.5->openfe) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.5->openfe) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.5->openfe) (2023.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->openfe) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->openfe) (3.2.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->openfe) (1.16.0)\nDownloading openfe-0.0.12-py3-none-any.whl (21 kB)\nInstalling collected packages: openfe\nSuccessfully installed openfe-0.0.12\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "#! [ -e /content ]\n",
        "\n",
        "#hide\n",
        "#This imports and sets up everything you will need for this notebook\n",
        "#\n",
        "#!pip install -Uqq fastbook\n",
        "#import fastbook\n",
        "#fastbook.setup_book()\n",
        "\n",
        "#from fastbook import *\n",
        "#!pip install ucimlrepo\n",
        "#from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "from fastai.tabular.all import *\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "\n",
        "from fastai.imports import *\n",
        "np.set_printoptions(linewidth=130)\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error,r2_score\n",
        "#from sklearn.metrics import root_mean_squared_error\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import plot_importance\n",
        "\n",
        "import lightgbm as lgb\n",
        "\n",
        "from catboost import CatBoostClassifier,CatBoostRegressor,Pool, metrics, cv\n",
        "\n",
        "from ipywidgets import interact\n",
        "\n",
        "\n",
        "matplotlib.rc('image', cmap='Greys')\n",
        "\n",
        "#from fastkaggle import setup_comp\n",
        "\n",
        "import optuna\n",
        "from openfe import OpenFE, transform\n",
        "\n",
        "from IPython.display import FileLink\n",
        "\n"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2024-05-31T09:32:16.377662Z",
          "iopub.execute_input": "2024-05-31T09:32:16.378952Z",
          "iopub.status.idle": "2024-05-31T09:32:18.580772Z",
          "shell.execute_reply.started": "2024-05-31T09:32:16.378913Z",
          "shell.execute_reply": "2024-05-31T09:32:18.579664Z"
        },
        "trusted": true,
        "id": "iKvCdJ05_8Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /kaggle/input/playground-series-s4e5"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-31T09:32:18.582368Z",
          "iopub.execute_input": "2024-05-31T09:32:18.583832Z",
          "iopub.status.idle": "2024-05-31T09:32:19.612648Z",
          "shell.execute_reply.started": "2024-05-31T09:32:18.583792Z",
          "shell.execute_reply": "2024-05-31T09:32:19.611188Z"
        },
        "trusted": true,
        "id": "13G9_E4Z_8Iq",
        "outputId": "327c84b0-ee85-4d48-8ca5-09555ce285a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "sample_submission.csv  test.csv  train.csv\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#set_seed(42)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-31T09:32:19.616143Z",
          "iopub.execute_input": "2024-05-31T09:32:19.619349Z",
          "iopub.status.idle": "2024-05-31T09:32:19.624759Z",
          "shell.execute_reply.started": "2024-05-31T09:32:19.619293Z",
          "shell.execute_reply": "2024-05-31T09:32:19.623676Z"
        },
        "trusted": true,
        "id": "Q4zad-x3_8It"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = Path('/kaggle/input/playground-series-s4e5/')\n",
        "path"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-31T09:32:19.625918Z",
          "iopub.execute_input": "2024-05-31T09:32:19.626942Z",
          "iopub.status.idle": "2024-05-31T09:32:19.640257Z",
          "shell.execute_reply.started": "2024-05-31T09:32:19.626914Z",
          "shell.execute_reply": "2024-05-31T09:32:19.63855Z"
        },
        "trusted": true,
        "id": "h4tHhDlX_8Iv",
        "outputId": "2192c8f1-4650-469d-ecee-31e2409de294"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Path('/kaggle/input/playground-series-s4e5')"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After some experimentation, i noticed adding the original dataset helps the model generalize better and produces better results."
      ],
      "metadata": {
        "id": "5BDW_QeA_8Iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /kaggle/input/flood-prediction-factors"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-31T09:32:19.641799Z",
          "iopub.execute_input": "2024-05-31T09:32:19.646032Z",
          "iopub.status.idle": "2024-05-31T09:32:20.68958Z",
          "shell.execute_reply.started": "2024-05-31T09:32:19.64599Z",
          "shell.execute_reply": "2024-05-31T09:32:20.688219Z"
        },
        "trusted": true,
        "id": "g9zNuHDT_8I0",
        "outputId": "57d406c6-e2ff-44a3-8907-c62a115ce012"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "flood.csv\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(path/'train.csv',index_col='id')\n",
        "test_df = pd.read_csv(path/'test.csv',index_col='id')\n",
        "sub_df = pd.read_csv(path/'sample_submission.csv',index_col='id')\n",
        "original_df = pd.read_csv('/kaggle/input/flood-prediction-factors/flood.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-31T09:32:20.691636Z",
          "iopub.execute_input": "2024-05-31T09:32:20.692025Z",
          "iopub.status.idle": "2024-05-31T09:32:24.372984Z",
          "shell.execute_reply.started": "2024-05-31T09:32:20.69199Z",
          "shell.execute_reply": "2024-05-31T09:32:24.371749Z"
        },
        "trusted": true,
        "id": "loRN-onY_8I2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape,original_df.shape,test_df.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-31T09:32:24.37643Z",
          "iopub.execute_input": "2024-05-31T09:32:24.37681Z",
          "iopub.status.idle": "2024-05-31T09:32:24.384038Z",
          "shell.execute_reply.started": "2024-05-31T09:32:24.37678Z",
          "shell.execute_reply": "2024-05-31T09:32:24.382994Z"
        },
        "trusted": true,
        "id": "9nupXEiq_8I4",
        "outputId": "5d6d05c5-592e-43ca-93c8-bfcfa3519acf"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "((1117957, 21), (50000, 21), (745305, 20))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The original dataset contains the target value which we would have to drop if we wanted to concat the test set and the original dataset"
      ],
      "metadata": {
        "id": "WhGuwI9j_8I6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_final = pd.concat([train_df,original_df], axis=0)\n",
        "test_final = pd.concat([test_df,original_df.drop('FloodProbability',axis=1)],axis=0)\n",
        "train_final.shape,test_final.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-31T09:32:24.387519Z",
          "iopub.execute_input": "2024-05-31T09:32:24.387866Z",
          "iopub.status.idle": "2024-05-31T09:32:24.538453Z",
          "shell.execute_reply.started": "2024-05-31T09:32:24.387803Z",
          "shell.execute_reply": "2024-05-31T09:32:24.537353Z"
        },
        "trusted": true,
        "id": "yW9AtGe5_8I6",
        "outputId": "ca4bbe8e-e865-44fd-92b4-d08cbe9c6aa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "((1167957, 21), (795305, 20))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Subset"
      ],
      "metadata": {
        "id": "4e7Y_AYW_8I9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_subset = train_df.sample(n=200000,replace=False)\n",
        "test_subset = test_df.sample(n=150000,replace=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-31T09:32:24.541348Z",
          "iopub.execute_input": "2024-05-31T09:32:24.541712Z",
          "iopub.status.idle": "2024-05-31T09:32:24.712165Z",
          "shell.execute_reply.started": "2024-05-31T09:32:24.541676Z",
          "shell.execute_reply": "2024-05-31T09:32:24.710983Z"
        },
        "trusted": true,
        "id": "tZvDymQt_8I9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_subset.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-31T09:32:24.713416Z",
          "iopub.execute_input": "2024-05-31T09:32:24.713741Z",
          "iopub.status.idle": "2024-05-31T09:32:24.720347Z",
          "shell.execute_reply.started": "2024-05-31T09:32:24.713715Z",
          "shell.execute_reply": "2024-05-31T09:32:24.719263Z"
        },
        "trusted": true,
        "id": "EDF8alAn_8I-",
        "outputId": "133b54c8-b777-4ab8-c031-7a9af00d5445"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 15,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(200000, 21)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Data Exploration"
      ],
      "metadata": {
        "id": "_oJrtl-A_8I_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_final.hist(figsize=(32,8));"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-31T09:32:24.721682Z",
          "iopub.execute_input": "2024-05-31T09:32:24.723681Z",
          "iopub.status.idle": "2024-05-31T09:32:29.743858Z",
          "shell.execute_reply.started": "2024-05-31T09:32:24.723651Z",
          "shell.execute_reply": "2024-05-31T09:32:29.742764Z"
        },
        "trusted": true,
        "id": "6AIMHxud_8I_",
        "outputId": "cd927d51-df7f-4620-d0fc-b7a0dc892994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 3200x800 with 25 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline\n",
        "\n",
        "This is a simple models with just the datasets provided excluding the original datasets and no extra feature engineering or feature transformatione except the defaults.\n",
        "\n",
        "I will use random forests and neural networks as a baseline, usually i would use just the random forest since a neural network is more sensitive to parameter changes but for this case it seems to run faster, so i use i create 2 baselines."
      ],
      "metadata": {
        "id": "b8mdfPRX_8JB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below i use the fastai cont_cat_split function to divide my columsn into categorical and continous variables."
      ],
      "metadata": {
        "id": "yQ5gb05U_8JD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Without Original Dataset"
      ],
      "metadata": {
        "id": "27XH6Q___8JE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_subset = train_df.sample(n=200000,replace=False)\n",
        "test_subset = test_df.sample(n=150000,replace=False)"
      ],
      "metadata": {
        "id": "3ny1uTtA_8JE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont_names,cat_names = cont_cat_split(train_subset, dep_var='FloodProbability')"
      ],
      "metadata": {
        "trusted": true,
        "id": "CrtZHhRs_8JF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont_names,cat_names = cont_cat_split(train_subset, dep_var='FloodProbability')\n",
        "splits = RandomSplitter(valid_pct=0.2)(range_of(train_subset))\n",
        "to = TabularPandas(train_subset, procs=[Categorify, FillMissing,Normalize],\n",
        "                   cat_names = cat_names,\n",
        "                   cont_names = cont_names,\n",
        "                   y_names='FloodProbability',\n",
        "                   y_block=RegressionBlock(),\n",
        "                   splits=splits)\n",
        "X_train, y_train = to.train.xs, to.train.ys.values.ravel()\n",
        "X_test, y_test = to.valid.xs, to.valid.ys.values.ravel()\n",
        "dls = to.dataloaders(bs=64)\n",
        "test_dl = dls.test_dl(test_subset)"
      ],
      "metadata": {
        "trusted": true,
        "id": "fDs_UyS3_8JG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splits = RandomSplitter(valid_pct=0.2)(range_of(train_subset))"
      ],
      "metadata": {
        "trusted": true,
        "id": "4l4GOPeY_8JG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to = TabularPandas(train_subset, procs=[Categorify, FillMissing,Normalize],\n",
        "                   cat_names = cat_names,\n",
        "                   cont_names = cont_names,\n",
        "                   y_names='FloodProbability',\n",
        "                   y_block=RegressionBlock(),\n",
        "                   splits=splits)"
      ],
      "metadata": {
        "trusted": true,
        "id": "lN2quVL6_8JH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = to.train.xs, to.train.ys.values.ravel()\n",
        "X_test, y_test = to.valid.xs, to.valid.ys.values.ravel()"
      ],
      "metadata": {
        "trusted": true,
        "id": "CuBTQtik_8JJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_dls = to.dataloaders(bs=64)\n",
        "test_dl = baseline_dls.test_dl(test_subset)"
      ],
      "metadata": {
        "trusted": true,
        "id": "rVXIiffm_8JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "C_kCNVLJ_8JL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "rf = RandomForestRegressor(50, min_samples_leaf=3)\n",
        "rf_model = rf.fit(X_train, y_train);\n",
        "\n",
        "rf_preds = tensor(rf_model.predict(test_dl.xs))\n",
        "\n",
        "rf_preds_x = tensor(rf_model.predict(X_test))\n",
        "\n",
        "mse = mean_absolute_error(y_test, rf_preds_x)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "r2_score(y_test,rf_preds_x)"
      ],
      "metadata": {
        "trusted": true,
        "id": "dGvIVGI1_8JM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Network"
      ],
      "metadata": {
        "id": "dYNkzV6z_8JO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = tabular_learner(baseline_dls, metrics=R2Score())\n",
        "learn.lr_find(suggest_funcs=(slide,valley))"
      ],
      "metadata": {
        "trusted": true,
        "id": "X0LRKpxq_8JO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "learn.fit_one_cycle(12,0.02)"
      ],
      "metadata": {
        "trusted": true,
        "id": "igxsaxjb_8JU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dls = baseline_dls"
      ],
      "metadata": {
        "trusted": true,
        "id": "DXm1Y2ZB_8JV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dl = learn.dls.test_dl(test_subset)"
      ],
      "metadata": {
        "trusted": true,
        "id": "xpiUqiLF_8JV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "nn_preds = learn.get_preds(dl=dl)\n",
        "nn_preds_x = learn.get_preds()[0]\n",
        "a_preds, _ = learn.get_preds(dl=dl)\n",
        "nn_preds_y = a_preds.squeeze(1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ASXsRveD_8JW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset no original training subset without openFE features,trial 2\n",
        "r2_score(y_test,nn_preds_x)"
      ],
      "metadata": {
        "trusted": true,
        "id": "qVNKm0bH_8JW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset no original training subset without openFE features\n",
        "r2_score(y_test,nn_preds_x)"
      ],
      "metadata": {
        "trusted": true,
        "id": "KB9WcsyA_8Jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So our random forest returns an r2score of **0.6120240869172946** while our neural network returns a score of **0.8525719134742764** which we shall use as our baseline scores.\n",
        "\n",
        "So from now on, our goal will be to try to improve this score."
      ],
      "metadata": {
        "id": "bcX9-7Er_8Jl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CatBoost"
      ],
      "metadata": {
        "id": "__xnz8Ww_8Jm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_model = CatBoostRegressor(iterations=1500, depth=8, learning_rate= 0.012, random_strength=8)\n",
        "cat_model = cat_model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False)\n",
        "\n",
        "#test set preds\n",
        "cat_preds = tensor(cat_model.predict(test_dl.xs))\n",
        "\n",
        "#validation set preds\n",
        "cat_preds_x = tensor(cat_model.predict(X_test))\n",
        "\n",
        "r2_score(y_test,cat_preds_x)"
      ],
      "metadata": {
        "id": "TQmspYG6_8Jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v-Xbgelg_8Jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding Original Dataset"
      ],
      "metadata": {
        "id": "gxcRbZoH_8Jo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train_final = pd.concat([train_df,original_df], axis=0)\n",
        "#test_final = pd.concat([test_df,original_df],axis=0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-30T03:14:12.881009Z",
          "iopub.execute_input": "2024-05-30T03:14:12.881412Z",
          "iopub.status.idle": "2024-05-30T03:14:13.022921Z",
          "shell.execute_reply.started": "2024-05-30T03:14:12.881368Z",
          "shell.execute_reply": "2024-05-30T03:14:13.021428Z"
        },
        "trusted": true,
        "id": "BLpPebhk_8Jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_subset = train_final.sample(n=200000,replace=False)\n",
        "test_subset = test_final.sample(n=150000,replace=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-31T09:32:56.724335Z",
          "iopub.execute_input": "2024-05-31T09:32:56.724729Z",
          "iopub.status.idle": "2024-05-31T09:32:56.898947Z",
          "shell.execute_reply.started": "2024-05-31T09:32:56.7247Z",
          "shell.execute_reply": "2024-05-31T09:32:56.897437Z"
        },
        "trusted": true,
        "id": "P38pU7iF_8Jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using subset\n",
        "splits = RandomSplitter(valid_pct=0.2)(range_of(train_subset))\n",
        "to = TabularPandas(train_subset, procs=[Categorify, FillMissing,Normalize],\n",
        "                   cat_names = cat_names,\n",
        "                   cont_names = cont_names,\n",
        "                   y_names='FloodProbability',\n",
        "                   y_block=RegressionBlock(),\n",
        "                   splits=splits)\n",
        "X_train, y_train = to.train.xs, to.train.ys.values.ravel()\n",
        "X_test, y_test = to.valid.xs, to.valid.ys.values.ravel()\n",
        "dls = to.dataloaders(bs=64)\n",
        "test_dl = dls.test_dl(test_subset)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-30T15:11:12.876797Z",
          "iopub.execute_input": "2024-05-30T15:11:12.877253Z",
          "iopub.status.idle": "2024-05-30T15:11:13.232033Z",
          "shell.execute_reply.started": "2024-05-30T15:11:12.877218Z",
          "shell.execute_reply": "2024-05-30T15:11:13.231127Z"
        },
        "trusted": true,
        "id": "SFOZrN8N_8Jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont_names,cat_names = cont_cat_split(train_final, dep_var='FloodProbability')\n",
        "splits = RandomSplitter(valid_pct=0.2)(range_of(train_final))\n",
        "to = TabularPandas(train_final, procs=[Categorify, FillMissing,Normalize],\n",
        "                   cat_names = cat_names,\n",
        "                   cont_names = cont_names,\n",
        "                   y_names='FloodProbability',\n",
        "                   y_block=RegressionBlock(),\n",
        "                   splits=splits)\n",
        "X_train, y_train = to.train.xs, to.train.ys.values.ravel()\n",
        "X_test, y_test = to.valid.xs, to.valid.ys.values.ravel()\n",
        "dls = to.dataloaders(bs=64)\n",
        "#test_dl = dls.test_dl(test_df)\n",
        "#dl = learn1.dls.test_dl(test_final)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-31T03:33:48.269542Z",
          "iopub.execute_input": "2024-05-31T03:33:48.270008Z",
          "iopub.status.idle": "2024-05-31T03:33:49.740196Z",
          "shell.execute_reply.started": "2024-05-31T03:33:48.269972Z",
          "shell.execute_reply": "2024-05-31T03:33:49.738985Z"
        },
        "trusted": true,
        "id": "YeLeCb97_8Jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dl = dls.test_dl(test_final)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-31T03:33:50.379749Z",
          "iopub.execute_input": "2024-05-31T03:33:50.383276Z",
          "iopub.status.idle": "2024-05-31T03:33:50.69463Z",
          "shell.execute_reply.started": "2024-05-31T03:33:50.383224Z",
          "shell.execute_reply": "2024-05-31T03:33:50.693589Z"
        },
        "trusted": true,
        "id": "nb8zTZa4_8Js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random forest with original dataset"
      ],
      "metadata": {
        "id": "Nd1J_8Ua_8Js"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "rf = RandomForestRegressor(50, min_samples_leaf=9)\n",
        "rf_model = rf.fit(X_train, y_train);\n",
        "\n",
        "rf_preds = tensor(rf_model.predict(test_dl.xs))\n",
        "\n",
        "rf_preds_x = tensor(rf_model.predict(X_test))\n",
        "\n",
        "mse = mean_absolute_error(y_test, rf_preds_x)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "r2_score(y_test,rf_preds_x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-30T20:06:25.217281Z",
          "iopub.status.idle": "2024-05-30T20:06:25.217846Z",
          "shell.execute_reply.started": "2024-05-30T20:06:25.217543Z",
          "shell.execute_reply": "2024-05-30T20:06:25.217565Z"
        },
        "trusted": true,
        "id": "F8YvqpHp_8Jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Network with original dataset"
      ],
      "metadata": {
        "id": "QegVk0om_8Ju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn1 = tabular_learner(dls, metrics=R2Score())\n",
        "learn1.lr_find(suggest_funcs=(slide,valley))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-30T20:06:25.219837Z",
          "iopub.status.idle": "2024-05-30T20:06:25.220345Z",
          "shell.execute_reply.started": "2024-05-30T20:06:25.220094Z",
          "shell.execute_reply": "2024-05-30T20:06:25.220117Z"
        },
        "trusted": true,
        "id": "-YBBqhlu_8Jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "learn1.fit_one_cycle(12,0.02)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-30T20:06:25.222115Z",
          "iopub.status.idle": "2024-05-30T20:06:25.222507Z",
          "shell.execute_reply.started": "2024-05-30T20:06:25.222319Z",
          "shell.execute_reply": "2024-05-30T20:06:25.222335Z"
        },
        "trusted": true,
        "id": "41pq-4BI_8Jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dl = learn1.dls.test_dl(test_subset)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-30T20:06:25.224236Z",
          "iopub.status.idle": "2024-05-30T20:06:25.224796Z",
          "shell.execute_reply.started": "2024-05-30T20:06:25.224512Z",
          "shell.execute_reply": "2024-05-30T20:06:25.224534Z"
        },
        "trusted": true,
        "id": "9qQS-ryk_8Jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "nn_preds = learn1.get_preds(dl=dl)\n",
        "nn_preds_x = learn1.get_preds()[0]\n",
        "#a_preds, _ = learn1.get_preds(dl=dl)\n",
        "#nn_preds_y = a_preds.squeeze(1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-30T20:06:25.226606Z",
          "iopub.status.idle": "2024-05-30T20:06:25.227173Z",
          "shell.execute_reply.started": "2024-05-30T20:06:25.226897Z",
          "shell.execute_reply": "2024-05-30T20:06:25.226921Z"
        },
        "trusted": true,
        "id": "2RV8tuda_8Jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset with original training subset with test_df\n",
        "r2_score(y_test,nn_preds_x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-30T20:06:25.228516Z",
          "iopub.status.idle": "2024-05-30T20:06:25.228895Z",
          "shell.execute_reply.started": "2024-05-30T20:06:25.2287Z",
          "shell.execute_reply": "2024-05-30T20:06:25.228715Z"
        },
        "trusted": true,
        "id": "b_ijINf3_8Jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset with original training subset with test_final\n",
        "r2_score(y_test,nn_preds_x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-30T20:06:25.230406Z",
          "iopub.status.idle": "2024-05-30T20:06:25.230779Z",
          "shell.execute_reply.started": "2024-05-30T20:06:25.230611Z",
          "shell.execute_reply": "2024-05-30T20:06:25.230627Z"
        },
        "trusted": true,
        "id": "I-zUE1r8_8Jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random forest now scores **0.6504381557189793** while the neural network scores **0.8578640002891056** which is an improvement from our previous scores."
      ],
      "metadata": {
        "id": "MDXIL_9w_8J0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CatBoost with original dataset"
      ],
      "metadata": {
        "id": "n_En4NWt_8J1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_model = CatBoostRegressor(iterations=1500, depth=8, learning_rate= 0.012, random_strength=8)\n",
        "cat_model = cat_model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False)\n",
        "\n",
        "#test set preds\n",
        "cat_preds = tensor(cat_model.predict(test_dl.xs))\n",
        "\n",
        "#validation set preds\n",
        "cat_preds_x = tensor(cat_model.predict(X_test))\n",
        "\n",
        "r2_score(y_test,cat_preds_x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-30T09:18:10.039255Z",
          "iopub.execute_input": "2024-05-30T09:18:10.039808Z",
          "iopub.status.idle": "2024-05-30T09:22:24.058938Z",
          "shell.execute_reply.started": "2024-05-30T09:18:10.039764Z",
          "shell.execute_reply": "2024-05-30T09:22:24.05766Z"
        },
        "trusted": true,
        "id": "8B0x61GA_8J1",
        "outputId": "7db0e594-7e64-49bd-b391-ec5fa05e8d8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 15,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.8399742912408491"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "cat_model = CatBoostRegressor(n_estimators=8000,random_state=0,learning_rate=0.011277016304363601, depth=8, subsample=0.8675506657380021, colsample_bylevel=0.7183884158632279, min_data_in_leaf=98)\n",
        "cat_model = cat_model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False)\n",
        "\n",
        "#test set preds\n",
        "cat_preds = tensor(cat_model.predict(test_dl.xs))\n",
        "\n",
        "#validation set preds\n",
        "cat_preds_x = tensor(cat_model.predict(X_test))\n",
        "\n",
        "r2_score(y_test,cat_preds_x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-30T09:22:24.061175Z",
          "iopub.execute_input": "2024-05-30T09:22:24.061984Z",
          "iopub.status.idle": "2024-05-30T09:43:10.715254Z",
          "shell.execute_reply.started": "2024-05-30T09:22:24.061942Z",
          "shell.execute_reply": "2024-05-30T09:43:10.714193Z"
        },
        "trusted": true,
        "id": "FRQiHhaS_8J2",
        "outputId": "106c144d-4eef-4432-b103-ee133078c68d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "CPU times: user 1h 10min 19s, sys: 1min 25s, total: 1h 11min 45s\nWall time: 20min 46s\n",
          "output_type": "stream"
        },
        {
          "execution_count": 16,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.8520149902128791"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "using subset for experimentation"
      ],
      "metadata": {
        "id": "xQB6xYbF_8J3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "cat_model = CatBoostRegressor(n_estimators=8000,random_state=0,learning_rate=0.011277016304363601, depth=8, subsample=0.8675506657380021, colsample_bylevel=0.7183884158632279, min_data_in_leaf=98)\n",
        "cat_model = cat_model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False)\n",
        "\n",
        "#test set preds\n",
        "cat_preds = tensor(cat_model.predict(test_dl.xs))\n",
        "\n",
        "#validation set preds\n",
        "cat_preds_x = tensor(cat_model.predict(X_test))\n",
        "\n",
        "r2_score(y_test,cat_preds_x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-30T15:44:56.547603Z",
          "iopub.execute_input": "2024-05-30T15:44:56.548077Z",
          "iopub.status.idle": "2024-05-30T15:49:44.585379Z",
          "shell.execute_reply.started": "2024-05-30T15:44:56.54804Z",
          "shell.execute_reply": "2024-05-30T15:49:44.58406Z"
        },
        "trusted": true,
        "id": "ZYkQWWWE_8J4",
        "outputId": "7af0aa2a-06c7-4c02-e60d-56bf9e0ad28b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "CPU times: user 13min 4s, sys: 41.4 s, total: 13min 45s\nWall time: 4min 48s\n",
          "output_type": "stream"
        },
        {
          "execution_count": 47,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.8502558115136835"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can conclude that adding the original dataset improves the model's results."
      ],
      "metadata": {
        "id": "4Dviapxf_8J6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LightGBM with original dataset"
      ],
      "metadata": {
        "id": "ctnoEHsp_8J6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_model_3 = lgb.LGBMRegressor(boosting_type='gbdt', n_estimators=2000, learning_rate=0.012,num_leaves=250, subsample_for_bin=165700, min_child_samples=114, reg_alpha=2.075e-06, reg_lambda=3.839e-07, colsample_bytree= 0.9634,subsample=0.9592, max_depth= 10,random_state=0,verbosity=-1)\n",
        "lgb_model_3 = lgb_model_3.fit(X_train, y_train)\n",
        "\n",
        "#test set preds\n",
        "lgb_preds_3 = tensor(lgb_model_3.predict(test_dl.xs))\n",
        "\n",
        "#validation set preds\n",
        "lgb_preds_x_3 = tensor(lgb_model_3.predict(X_test))\n",
        "\n",
        "lgb_score_3 = r2_score(y_test,lgb_preds_x_3)\n",
        "lgb_score_3"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-29T20:24:13.55056Z",
          "iopub.execute_input": "2024-05-29T20:24:13.551049Z",
          "iopub.status.idle": "2024-05-29T20:34:23.490812Z",
          "shell.execute_reply.started": "2024-05-29T20:24:13.551006Z",
          "shell.execute_reply": "2024-05-29T20:34:23.48976Z"
        },
        "trusted": true,
        "id": "266fj-g9_8J7",
        "outputId": "f72cbe58-b140-4655-9a3f-168b4d0b4748"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 28,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.8434422384534928"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "with subset"
      ],
      "metadata": {
        "id": "rOSstKOW_8J9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "lgb_model_3 = lgb.LGBMRegressor(boosting_type='gbdt', n_estimators=2000, learning_rate=0.012,num_leaves=250, subsample_for_bin=165700, min_child_samples=114, reg_alpha=2.075e-06, reg_lambda=3.839e-07, colsample_bytree= 0.9634,subsample=0.9592, max_depth= 10,random_state=0,verbosity=-1)\n",
        "lgb_model_3 = lgb_model_3.fit(X_train, y_train)\n",
        "\n",
        "#test set preds\n",
        "lgb_preds_3 = tensor(lgb_model_3.predict(test_dl.xs))\n",
        "\n",
        "#validation set preds\n",
        "lgb_preds_x_3 = tensor(lgb_model_3.predict(X_test))\n",
        "\n",
        "lgb_score_3 = r2_score(y_test,lgb_preds_x_3)\n",
        "lgb_score_3"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-30T15:49:44.588075Z",
          "iopub.execute_input": "2024-05-30T15:49:44.588557Z",
          "iopub.status.idle": "2024-05-30T15:51:37.12322Z",
          "shell.execute_reply.started": "2024-05-30T15:49:44.588515Z",
          "shell.execute_reply": "2024-05-30T15:51:37.122312Z"
        },
        "trusted": true,
        "id": "y_VuHDWA_8J_",
        "outputId": "8fc788a0-9602-45f4-dcdb-3f9eaac4dd80"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "CPU times: user 3min 40s, sys: 1.88 s, total: 3min 42s\nWall time: 1min 52s\n",
          "output_type": "stream"
        },
        {
          "execution_count": 48,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.8352025054299641"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost with original dataset"
      ],
      "metadata": {
        "id": "0B_hSuFs_8KB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = xgb.XGBRegressor(n_estimators = 500, max_depth=5, learning_rate=0.1461774202844157, subsample= 0.6649609199174655)\n",
        "xgb_model = xgb_model.fit(X_train, y_train)\n",
        "\n",
        "xgb_preds = tensor(xgb_model.predict(test_dl.xs))\n",
        "\n",
        "xgb_preds_x = tensor(xgb_model.predict(X_test))\n",
        "\n",
        "r2_score(y_test,xgb_preds_x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-30T09:43:10.717719Z",
          "iopub.execute_input": "2024-05-30T09:43:10.718332Z",
          "iopub.status.idle": "2024-05-30T09:43:58.872138Z",
          "shell.execute_reply.started": "2024-05-30T09:43:10.718293Z",
          "shell.execute_reply": "2024-05-30T09:43:58.870958Z"
        },
        "trusted": true,
        "id": "UuRSnrsO_8KC",
        "outputId": "e0e04085-c03b-434d-e31a-23a1b51f8064"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 17,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.8393283321384759"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "xgb_model = xgb.XGBRegressor(n_estimators=8000,max_depth=10,learning_rate=0.01,random_state=0)\n",
        "xgb_model = xgb_model.fit(X_train, y_train)\n",
        "\n",
        "xgb_preds = tensor(xgb_model.predict(test_dl.xs))\n",
        "\n",
        "xgb_preds_x = tensor(xgb_model.predict(X_test))\n",
        "\n",
        "r2_score(y_test,xgb_preds_x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-30T09:43:58.873827Z",
          "iopub.execute_input": "2024-05-30T09:43:58.874261Z",
          "iopub.status.idle": "2024-05-30T10:10:08.941422Z",
          "shell.execute_reply.started": "2024-05-30T09:43:58.874211Z",
          "shell.execute_reply": "2024-05-30T10:10:08.939797Z"
        },
        "trusted": true,
        "id": "nwwxGl9v_8KD",
        "outputId": "d8d41320-2701-40d3-abe3-16fbfb571cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.845830991514303"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "with subset"
      ],
      "metadata": {
        "id": "uFGaH8_3_8KF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "xgb_model = xgb.XGBRegressor(n_estimators=8000,max_depth=10,learning_rate=0.01,random_state=0)\n",
        "xgb_model = xgb_model.fit(X_train, y_train)\n",
        "\n",
        "xgb_preds = tensor(xgb_model.predict(test_dl.xs))\n",
        "\n",
        "xgb_preds_x = tensor(xgb_model.predict(X_test))\n",
        "\n",
        "r2_score(y_test,xgb_preds_x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-30T15:51:37.12468Z",
          "iopub.execute_input": "2024-05-30T15:51:37.125447Z",
          "iopub.status.idle": "2024-05-30T15:57:08.331937Z",
          "shell.execute_reply.started": "2024-05-30T15:51:37.125413Z",
          "shell.execute_reply": "2024-05-30T15:57:08.330725Z"
        },
        "trusted": true,
        "id": "TbKGdCGg_8KG",
        "outputId": "4e65c978-8c06-4381-9c30-486c6cf03951"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 49,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.8262393455140243"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_importance(xgb_model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-30T10:10:08.945263Z",
          "iopub.execute_input": "2024-05-30T10:10:08.945822Z",
          "iopub.status.idle": "2024-05-30T10:10:09.771464Z",
          "shell.execute_reply.started": "2024-05-30T10:10:08.94578Z",
          "shell.execute_reply": "2024-05-30T10:10:09.77036Z"
        },
        "trusted": true,
        "id": "bJDO5ygK_8KJ",
        "outputId": "a165f6dd-23e9-4bdf-c1cf-f8346d6167df"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 19,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<Axes: title={'center': 'Feature importance'}, xlabel='F score', ylabel='Features'>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAHHCAYAAAAiQ84EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdeVyO2f/48dfdvqiQpaKUVBhblox9nyJGxhLDkHVmCNn3ZM0S4oMMQ40ZWcZubJN9yzoYBtlljOwKUXd1/f7o1/V1qyyDibyfj0cPXec61znnfd257/tc51zn0iiKoiCEEEIIIYQQb0EvpxsghBBCCCGE+PhJx0IIIYQQQgjx1qRjIYQQQgghhHhr0rEQQgghhBBCvDXpWAghhBBCCCHemnQshBBCCCGEEG9NOhZCCCGEEEKItyYdCyGEEEIIIcRbk46FEEIIIYQQ4q1Jx0IIIYTIBSIiItBoNFy9ejWnmyKE+ERJx0IIIcRHKeOLdFY/Q4cOfS91HjhwgKCgIB4+fPheyv+UJSYmEhQUxK5du3K6KUKIf8kgpxsghBBCvI2xY8fi5OSkk1amTJn3UteBAwcYM2YMfn5+5M2b973U8W998803tG3bFmNj45xuyr+SmJjImDFjAKhbt27ONkYI8a9Ix0IIIcRHrXHjxlSuXDmnm/FWnjx5grm5+VuVoa+vj76+/jtq0X8nLS2N5OTknG6GEOIdkKlQQgghcrXNmzdTq1YtzM3NsbCwwNvbm7/++ksnz59//omfnx/FixfHxMQEGxsbunTpwr1799Q8QUFBDBo0CAAnJyd12tXVq1e5evUqGo2GiIiITPVrNBqCgoJ0ytFoNJw5c4avv/6afPnyUbNmTXX/L7/8QqVKlTA1NSV//vy0bduW69evvzLOrO6xcHR0pGnTpuzatYvKlStjampK2bJl1elGq1evpmzZspiYmFCpUiWOHz+uU6afnx958uTh8uXLeHp6Ym5ujp2dHWPHjkVRFJ28T548YcCAAdjb22NsbIybmxshISGZ8mk0Gvz9/VmyZAmfffYZxsbGzJs3j4IFCwIwZswY9dxmnLfXeX2eP7cXL15UR5WsrKzo3LkziYmJmc7ZL7/8goeHB2ZmZuTLl4/atWvz+++/6+R5nb8fIUQ6GbEQQgjxUYuPj+fu3bs6aQUKFADg559/plOnTnh6ejJ58mQSExMJCwujZs2aHD9+HEdHRwCioqK4fPkynTt3xsbGhr/++ov58+fz119/cfDgQTQaDV999RXnz59n6dKlzJgxQ62jYMGC3Llz543b3bp1a1xcXJg4caL65XvChAmMGjWKNm3a0K1bN+7cucP//vc/ateuzfHjx//V9KuLFy/y9ddf8+2339KhQwdCQkJo1qwZ8+bNY/jw4fTs2ROA4OBg2rRpQ0xMDHp6/3fdMTU1FS8vLz7//HOmTJnCli1bGD16NCkpKYwdOxYARVH48ssv2blzJ127dqVChQps3bqVQYMGcePGDWbMmKHTph07drBixQr8/f0pUKAA5cuXJywsjO+//54WLVrw1VdfAVCuXDng9V6f57Vp0wYnJyeCg4P5448/+PHHHylUqBCTJ09W84wZM4agoCCqV6/O2LFjMTIy4tChQ+zYsYMvvvgCeP2/HyHE/6cIIYQQH6Hw8HAFyPJHURTl0aNHSt68eZXu3bvrHBcXF6dYWVnppCcmJmYqf+nSpQqg7NmzR02bOnWqAihXrlzRyXvlyhUFUMLDwzOVAyijR49Wt0ePHq0ASrt27XTyXb16VdHX11cmTJigk37q1CnFwMAgU3p25+P5thUrVkwBlAMHDqhpW7duVQDF1NRUuXbtmpr+ww8/KICyc+dONa1Tp04KoPTu3VtNS0tLU7y9vRUjIyPlzp07iqIoytq1axVAGT9+vE6bWrVqpWg0GuXixYs650NPT0/566+/dPLeuXMn07nK8LqvT8a57dKli07eFi1aKNbW1ur2hQsXFD09PaVFixZKamqqTt60tDRFUd7s70cIkU6mQgkhhPiozZkzh6ioKJ0fSL/K/fDhQ9q1a8fdu3fVH319fapWrcrOnTvVMkxNTdXfnz17xt27d/n8888B+OOPP95Lu7/77jud7dWrV5OWlkabNm102mtjY4OLi4tOe99E6dKlqVatmrpdtWpVAOrXr4+Dg0Om9MuXL2cqw9/fX/09YypTcnIy27ZtA2DTpk3o6+vTp08fneMGDBiAoihs3rxZJ71OnTqULl36tWN409fnxXNbq1Yt7t27R0JCAgBr164lLS2NwMBAndGZjPjgzf5+hBDpZCqUEEKIj5qHh0eWN29fuHABSP8CnRVLS0v19/v37zNmzBiWLVvG7du3dfLFx8e/w9b+nxdXsrpw4QKKouDi4pJlfkNDw39Vz/OdBwArKysA7O3ts0x/8OCBTrqenh7FixfXSXN1dQVQ7+e4du0adnZ2WFhY6OQrVaqUuv95L8b+Km/6+rwYc758+YD02CwtLbl06RJ6enov7dy8yd+PECKddCyEEELkSmlpaUD6PHkbG5tM+w0M/u8jsE2bNhw4cIBBgwZRoUIF8uTJQ1paGl5eXmo5L/PiHP8Mqamp2R7z/FX4jPZqNBo2b96c5epOefLkeWU7spLdSlHZpSsv3Gz9PrwY+6u86evzLmJ7k78fIUQ6+V8hhBAiV3J2dgagUKFCNGzYMNt8Dx48YPv27YwZM4bAwEA1PeOK9fOy60BkXBF/8cF5L16pf1V7FUXByclJHRH4EKSlpXH58mWdNp0/fx5AvXm5WLFibNu2jUePHumMWpw7d07d/yrZnds3eX1el7OzM2lpaZw5c4YKFSpkmwde/fcjhPg/co+FEEKIXMnT0xNLS0smTpyIVqvNtD9jJaeMq9svXs0ODQ3NdEzGsyZe7EBYWlpSoEAB9uzZo5M+d+7c127vV199hb6+PmPGjMnUFkVRMi2t+l+aPXu2Tltmz56NoaEhDRo0AKBJkyakpqbq5AOYMWMGGo2Gxo0bv7IOMzMzIPO5fZPX53X5+Pigp6fH2LFjM414ZNTzun8/Qoj/IyMWQgghciVLS0vCwsL45ptvqFixIm3btqVgwYLExsayceNGatSowezZs7G0tKR27dpMmTIFrVZLkSJF+P3337ly5UqmMitVqgTAiBEjaNu2LYaGhjRr1gxzc3O6devGpEmT6NatG5UrV2bPnj3qlf3X4ezszPjx4xk2bBhXr17Fx8cHCwsLrly5wpo1a+jRowcDBw58Z+fndZmYmLBlyxY6depE1apV2bx5Mxs3bmT48OHqsyeaNWtGvXr1GDFiBFevXqV8+fL8/vvvrFu3joCAAPXq/8uYmppSunRpli9fjqurK/nz56dMmTKUKVPmtV+f11WiRAlGjBjBuHHjqFWrFl999RXGxsYcOXIEOzs7goODX/vvRwjxnBxajUoIIYR4KxnLqx45cuSl+Xbu3Kl4enoqVlZWiomJieLs7Kz4+fkpR48eVfP8/fffSosWLZS8efMqVlZWSuvWrZV//vkny+VPx40bpxQpUkTR09PTWd41MTFR6dq1q2JlZaVYWFgobdq0UW7fvp3tcrMZS7W+aNWqVUrNmjUVc3NzxdzcXClZsqTSq1cvJSYm5rXOx4vLzXp7e2fKCyi9evXSSctYMnfq1KlqWqdOnRRzc3Pl0qVLyhdffKGYmZkphQsXVkaPHp1pmdZHjx4p/fr1U+zs7BRDQ0PFxcVFmTp1qrp868vqznDgwAGlUqVKipGRkc55e93XJ7tzm9W5URRFWbRokeLu7q4YGxsr+fLlU+rUqaNERUXp5Hmdvx8hRDqNovwHd2kJIYQQ4qPj5+fHypUrefz4cU43RQjxEZB7LIQQQgghhBBvTToWQgghhBBCiLcmHQshhBBCCCHEW5N7LIQQQgghhBBvTUYshBBCCCGEEG9NOhZCCCGEEEKItyYPyBNCZCktLY1//vkHCwsLNBpNTjdHCCGEEK9BURQePXqEnZ0denr/7RiCdCyEEFn6559/sLe3z+lmCCGEEOJfuH79OkWLFv1P65SOhRAiSxYWFgBcuXKF/Pnz53Br3h+tVsvvv//OF198gaGhYU43572ROHOfTyVWiTN3kTjfv4SEBOzt7dXP8f+SdCyEEFnKmP5kYWGBpaVlDrfm/dFqtZiZmWFpaZnrP+QkztzlU4lV4sxdJM7/Tk5MY5abt4UQQgghhBBvTToWQgghhBBCiLcmHQshhBBCCCHEW5OOhRBCCCGEEOKtScdCCCGEEEII8dakYyGEEEIIIYR4a9KxEEIIIYQQQrw16VgIIYQQQggh3pp0LIQQQgghhBBvTToWQnxkNBoNa9euzelmCCGEEJ+MsLAwypUrh6WlJZaWllSrVo3Nmzer++Pi4vjmm2+wsbHB3NwcDw8PDhw4oO7ftWsXGo0my58jR46o+bZu3crnn3+OhYUFBQsWpGXLlly9elXdv3r1aho1akTBggXVdmzdujXLNnfv3h1ra2tMTU0pW7YsR48efWmMu3btomLFihgbG1OiRAkiIiLe+DxJx0Jk4ufnh0aj4bvvvsu0r1evXmg0Gvz8/P77hr1HQUFBVKhQ4Y2OcXR0JDQ09L2052Vu3rxJ48aNAbh69SoajYYTJ0785+0QQgghPhVFixZl0qRJHDt2jKNHj1K/fn2aN2/OX3/9BUDHjh2JiYlh/fr1nDp1Ch8fH0JCQjh+/DgA1atX5+bNmzo/3bp1w8nJicqVKwNw5coVmjdvTv369Tlx4gRbt27l7t27fPXVV2o79uzZQ6NGjdi0aRPHjh2jXr16NGvWTK0H4MGDBwAYGhqyefNmzpw5w7Rp08iXL1+28V25cgVvb2/q1avHiRMnCAgIoFu3btl2WrJj8Ea5xSfD3t6eZcuWMWPGDExNTQF49uwZkZGRODg45HDrPm02NjY53QQhhBDik9KsWTOd7QkTJhAWFsbBgwf57LPPOHDgAGFhYXh4eAAwfPhwpk2bxvHjx/Hw8MDIyEjn81ur1bJu3Tp69+6NRqMB4NixY6SmpjJ+/Hj09NKv/Q8cOJDmzZuj1WoxNDTMdEFz4sSJrFu3jg0bNuDu7g6g5pk7dy6WlpYAODk5vTS+efPm4eTkxLRp0wAoVaoU+/btY8aMGXh6er72eZIRC5GlihUrYm9vz+rVq9W01atX4+DgoP7hAiQlJdGnTx8KFSqEiYkJNWvW1BnSyxj62759O5UrV8bMzIzq1asTExOj5jl58iT16tXDwsICS0tLKlWqpDNct2rVKj777DOMjY1xdHRU/+gzPHjwgI4dO5IvXz7MzMxo3LgxFy5cUPdHRESQN29etm7dSqlSpciTJw9eXl7cvHkz2/j9/PzUqw22trZYW1vTq1cvtFotAHXr1uXatWv069dPHcrMsG/fPmrVqoWpqSn29vb06dOHJ0+eqPsdHR2ZOHEiXbp0wcLCAgcHB+bPn6/uT05Oxt/fH1tbW0xMTChWrBjBwcHq/uenQmW8Ubi7u6PRaKhbty579uzB0NCQuLg4nZgCAgKoVatWtjELIYQQ4tVSU1NZtmwZT548oVq1akD6iMTy5cu5f/8+aWlpLF++nOTkZGrXrp1lGevXr+fevXt07txZTatUqRJ6enqEh4eTmppKfHw8P//8Mw0bNsTQ0DDLctLS0nj06BH58+dX0zKmaHXs2JFChQrh7u7OggULXhpTdHQ0DRs21Enz9PQkOjr61SfkOTJiIbLVpUsXwsPDad++PQCLFi2ic+fO7Nq1S80zePBgVq1axU8//USxYsWYMmUKnp6eXLx4UeePfMSIEUybNo2CBQvy3Xff0aVLF/bv3w9A+/btcXd3JywsDH19fU6cOKH+Bzp27Bht2rQhKCgIX19fDhw4QM+ePbG2tlanY/n5+XHhwgXWr1+PpaUlQ4YMoUmTJpw5c0YtJzExkZCQEH7++Wf09PTo0KEDAwcOZMmSJdnGv3PnTmxtbdm5cycXL17E19eXChUq0L17d1avXk358uXp0aMH3bt3V4+5dOkSXl5ejB8/nkWLFnHnzh38/f3x9/cnPDxczTdt2jTGjRvH8OHDWblyJd9//z116tTBzc2NWbNmsX79elasWIGDgwPXr1/n+vXrWbbx8OHDeHh4sG3bNj777DOMjIzInz8/xYsX5+eff2bQoEFA+pWRJUuWMGXKlNd9+VVVg7eTYmD+xsd9LIz1FaZ4QJmgrSSlal59wEdK4sx9PpVYJc7c5WOM8+okbwBOnTpFtWrVePbsGXny5GHNmjWULl0agBUrVuDr64u1tTUGBgaYmZkxdOhQSpQokWWZCxcuxNPTk6JFi6ppTk5O/P7777Rp04Zvv/2W1NRUqlWrxqZNm7JtW0hICI8fP6ZNmzb/197/f0+Gs7Mzo0eP5siRI/Tp0wcjIyM6deqUZTlxcXEULlxYJ61w4cIkJCTw9OlTdfbKq0jHQmSrQ4cODBs2jGvXrgGwf/9+li1bpnYsnjx5QlhYGBEREeqc/wULFhAVFcXChQvVL7WQPmRYp04dAIYOHYq3tzfPnj3DxMSE2NhYBg0aRMmSJQFwcXFRj5s+fToNGjRg1KhRALi6unLmzBmmTp2q06HYv38/1atXB2DJkiXY29uzdu1aWrduDaR/sZ43bx7Ozs4A+Pv7M3bs2JfGny9fPmbPno2+vj4lS5bE29ub7du30717d/Lnz4++vj4WFhY6Q5vBwcG0b9+egIAANZZZs2ZRp04dwsLCMDExAaBJkyb07NkTgCFDhjBjxgx27tyJm5sbsbGxuLi4ULNmTTQaDcWKFcu2jQULFgTA2tpapx1du3YlPDxcfQ02bNjAs2fPdN54XpSUlERSUpK6nZCQAICxnoK+vvLSc/UxM9ZTdP7NrSTO3OdTiVXizF0+xjgzZisUL16cI0eOkJCQwKpVq+jUqRPbtm2jdOnSjBgxggcPHrBlyxasra1Zu3YtU6dOpUmTJjozPQD+/vtvtm7dSmRkpFo2pH+579atGx06dMDX15fHjx8zZswYWrZsyebNm3VmRwAsXbqUMWPGsGrVKvLly6eWlZaWBsDo0aOxtLTE3d2d06dPM2/evGw7Fu+KdCxEtgoWLIi3tzcREREoioK3tzcFChRQ91+6dAmtVkuNGjXUNENDQzw8PDh79qxOWeXKlVN/t7W1BeD27ds4ODjQv39/unXrpg73tW7dWu0AnD17lubNm+uUVaNGDUJDQ0lNTeXs2bMYGBhQtWpVdb+1tTVubm46bTAzM1PLzGjD7du3Xxr/Z599hr6+vs4xp06deukxJ0+e5M8//9QZCVEUhbS0NK5cuUKpUqUynQ+NRoONjY3aHj8/Pxo1aoSbmxteXl40bdqUL7744qX1vsjPz4+RI0dy8OBBPv/8cyIiImjTpg3m5tmPPAQHBzNmzJhM6SPd0zAzS32j+j9G4yqn5XQT/hMSZ+7zqcQqceYuH1OcWY0Y1KhRg61btzJ48GBatGjB3LlzmTVrFs+ePePGjRtUqVKFEiVKEBgYyPfff69z7PLly7GwsMDAwECn7IzvDrVr11ana3fs2JFu3boRGhqKm5ubmnfv3r3873//Y/DgwSQlJemUY2Vlxd27d3XqLFWqFKtWrco2RhsbG27duqWTduvWLSwtLV97tAKkYyFeoUuXLvj7+wMwZ86cf13O83MDM3rcGT3qoKAgvv76azZu3MjmzZsZPXo0y5Yto0WLFm/R8uzrz2iDorz8aklWx2S0OTuPHz/m22+/pU+fPpn2PX/T+8vKrlixIleuXGHz5s1s27aNNm3a0LBhQ1auXPnSup9XqFAhmjVrRnh4OE5OTmzevFlnCltWhg0bRv/+/dXthIQE7O3tqVevHtbW1q9d98dGq9USFRVFo0aNsp3DmhtInLnPpxKrxJm75KY4Q0NDKVy4sHrDdp06ddQLiFqtlqCgIOzs7GjSpIl6jKIo9OvXjy5duvDll1/qlLdr1y6uXr2qkz+jg/H555+r93MsW7aMOXPmEBkZmakMSO+YPH+PLMD58+dfOgMiqylXUVFRap2vSzoW4qW8vLxITk5Go9FkWhXA2dkZIyMj9u/fr/6xarVajhw5ok4Fel2urq64urrSr18/2rVrR3h4OC1atKBUqVLqvRgZ9u/fj6urK/r6+pQqVYqUlBQOHTqkToW6d+8eMTEx6rzH98XIyIjUVN0r+RUrVuTMmTPZzql8XZaWlvj6+uLr60urVq3w8vLi/v37OvetZLQByNQOgG7dutGuXTuKFi2Ks7OzzshSVoyNjTE2Ns6Ubmho+NG/+b8OiTN3+VTihE8nVokzd/nY4hw2bBiNGzfGwcGBR48eERkZye7du9m6dStly5alRIkS+Pv7ExISgrW1NatWreLkyZOMGTNGJ87t27dz5coVevTokSn+Zs2aMXPmTIKDg2nXrh2PHj1i+PDhFCtWjCpVqmBoaEhkZCRdunRh5syZ1KhRg3v37gFgamqKlZUVkD7de/Xq1YSEhNCxY0cOHz7M/PnzdRaKGTZsGDdu3GDx4sUAfPfdd8yePZvBgwfTpUsXduzYwYoVK9i4ceMbnSdZFUq8lL6+PmfPnuXMmTM604IAzM3N+f777xk0aBBbtmzhzJkzdO/encTERLp27fpa5T99+hR/f3927drFtWvX2L9/P0eOHFF7/AMGDGD79u2MGzeO8+fP89NPPzF79mwGDhwIpN/D0Lx5c7p3786+ffs4efIkHTp0oEiRIpmmUL1rjo6O7Nmzhxs3bqhDjkOGDOHAgQP4+/tz4sQJLly4wLp169RRn9cxffp0li5dyrlz5zh//jy//vorNjY25M2bN1PeQoUKYWpqypYtW7h16xbx8fHqPk9PTywtLRk/frzOqhNCCCGEeDO3b9+mY8eOuLm50aBBA44cOcLWrVvVkZdNmzZRsGBBmjVrRrly5fjll1/o06ePeg9qhoULF1K9enX1vtLn1a9fn8jISNauXYu7uzteXl4YGxuzZcsWdTrS/PnzSUlJoVevXtja2qo/ffv2VcupVKkSkL6qZpkyZRg3bhyhoaHqYjyQPhISGxurbjs5ObFx40aioqIoX74806ZN48cff3yjpWZBRizEa8hYAzkrkyZNIi0tjW+++YZHjx5RuXJltm7d+tKHsDxPX1+fe/fu0bFjR27dukWBAgX46quv1Ln+FStWZMWKFQQGBjJu3DhsbW0ZO3aszgP6wsPD6du3L02bNlWXdtu0adN7vxIyduxYvv32W5ydnUlKSkJRFMqVK8fu3bsZMWIEtWrVQlEUnJ2d8fX1fe1yLSwsmDJlChcuXEBfX58qVaqwadMmdU3r5xkYGDBr1izGjh1LYGAgtWrVUqc86enp4efnx8SJE+nYseO7ClsIIYT45CxcuPCl+11cXHTuYdBqtVnemxEZGfnSctq2bUvbtm2z3f+qac3Pi46OzvY7XFZP1a5bt67Og/b+DY3yqonmQoiPVteuXblz5w7r169/42MTEhLUG8By+z0WmzZtokmTJh/VsPybkjhzn08lVokzd5E437+Mz+/4+PiXXhx+H2TEQohcKD4+nlOnThEZGfmvOhVCCCGEEG9KOhZC5ELNmzfn8OHDfPfddzRq1CinmyOEEEKIT4B0LITIhd5kDqYQQgghxLsgq0IJIYQQQggh3pp0LIQQQgghhBBvTToWQgghhBBCiLcmHQvxUfLz88PHxyenm/FKQUFBVKhQIaebIYQQ4hMWFhZGuXLlsLS0xNLSkmrVqrF582Z1//z586lbty6WlpZoNBoePnyYqYzz58/TvHlzChQogKWlJTVr1mTnzp1Z1nfv3j2KFi2aqSw/Pz+MjIzw8fHByMgIjUaDRqPhs88+y7KcSZMmodFoCAgIeGWMv/76KyVLlsTExISyZctm+QwJ8f5Jx+IjlPEfMbufoKCgnG7iRyEoKEg9ZwYGBhQoUIDatWsTGhpKUlLSO6lj4MCBbN++/Z2UJYQQQvwbRYsWZdKkSRw7doyjR49Sv359mjdvzl9//QVAYmIiXl5eDB8+PNsymjZtSkpKCjt27ODYsWOUL1+epk2bEhcXlylv165dKVeuXKb0mTNnEhsbS3h4OLGxsVy/fp38+fPTunXrTHmPHDnCDz/8kGU5Lzpw4ADt2rWja9euHD9+HB8fH3x8fDh9+vQrjxXvlnQsPkI3b95Uf0JDQ7G0tNRJGzhwYE43MUvJyck53YRMPvvsM/Wx9jt37qR169YEBwdTvXp1Hj16lO1xrxtLnjx5cvXD5YQQQnz4mjVrRpMmTXBxccHV1ZUJEyaQJ08eDh48CEBAQABDhw7l888/z/L4u3fvcuHCBYYOHUq5cuVwcXFh0qRJJCYmZvryHhYWxsOHD7P8LmJlZYWNjQ358uXDxsaGo0eP8uDBAzp37qyT7/Hjx7Rv354FCxaQL1++V8Y3c+ZMvLy8GDRoEKVKlWLcuHFUrFiR2bNnv+4pEu+IdCw+QjY2NuqPlZUVGo1G3S5UqBDTp0+naNGiGBsbU6FCBbZs2aIee/XqVTQaDcuWLaN69eqYmJhQpkwZdu/erVPH7t278fDwwNjYGFtbW4YOHUpKSoq6/9GjR7Rv3x5zc3NsbW2ZMWMGdevW1RmudHR0ZNy4cXTs2BFLS0t69OgBwJAhQ3B1dcXMzIzixYszatQotFqtelzG9KEffvgBe3t7zMzMaNOmDfHx8ZnORUhICLa2tlhbW9OrVy+1nLFjx1KmTJlM+StUqMCoUaPUbQMDA2xsbLCzs6Ns2bL07t2b3bt3c/r0aSZPnvzOYsmQMYUru3YD/Pzzz1SuXBkLCwtsbGz4+uuvuX37tk4c69evx8XFBRMTE+rVq8dPP/2Uach537591KpVC1NTU+zt7enTpw9PnjzJdE6EEEJ8OlJTU1m2bBlPnjyhWrVqr3WMtbU1bm5uLF68mCdPnpCSksIPP/xAoUKFqFSpkprvzJkzjB07lsWLF6On9+qvmAsXLqRhw4YUK1ZMJ71Xr154e3vTsGHD12pfdHR0pryenp5ER0e/1vHi3ZHnWOQyM2fOZNq0afzwww+4u7uzaNEivvzyS/766y9cXFzUfIMGDSI0NJTSpUszffp0mjVrxpUrV7C2tubGjRs0adIEPz8/Fi9ezLlz5+jevTsmJibqNKv+/fuzf/9+1q9fT+HChQkMDOSPP/7IdD9BSEgIgYGBjB49Wk2zsLAgIiICOzs7Tp06Rffu3bGwsGDw4MFqnosXL7JixQo2bNhAQkICXbt2pWfPnixZskTNs3PnTmxtbdm5cycXL17E19eXChUq0L17d7p06cKYMWM4cuQIVapUAeD48eP8+eefrF69+qXnsGTJkjRu3JjVq1czfvz4t47lRS9rN4BWq2XcuHG4ublx+/Zt+vfvj5+fnzpf9MqVK7Rq1Yq+ffvSrVs3jh8/nunK0KVLl/Dy8mL8+PEsWrSIO3fu4O/vj7+/P+Hh4Vm2KykpSWcKWEJCAgC1J28jxdD8pefsY2aspzCuMlQau4WkNE1ON+e9kThzn08lVonz7ZwO8gTg1KlT1K5dm2fPnpEnTx5+/fVXXFxcdC5sZVxA1Gq1OukAmzdvplWrVlhYWKCnp0ehQoXYsGEDefLkQavVkpSURNu2bQkODsbW1pbz589nWVbG77GxsWzevJnFixfr7F++fDnHjh0jOjoarVaLoiikpaVlas/z4uLisLa21slToEAB4uLiXnrc+5RRb07Un1MxA2gURVFyrHbx1iIiIggICFCvVBcpUoRevXrpzJP08PCgSpUqzJkzh6tXr+Lk5MSkSZMYMmQIkP5G4uTkRO/evRk8eDAjRoxg1apVnD17Fo0m/c1t7ty5DBkyhPj4eJ48eYK1tTWRkZG0atUKgPj4eOzs7OjevTuhoaFA+lV+d3d31qxZ89IYQkJCWLZsGUePHgXSr/KPHz+ea9euUaRIEQC2bNmCt7c3N27cwMbGBj8/P3bt2sWlS5fQ19cHoE2bNujp6bFs2TIAmjRpgqOjI3PnzgWgT58+nDp1Sr3ZLCgoiLVr13LixIlMbRo6dCizZs0iMTHxrWN5vo7XafeLjh49SpUqVXj06BF58uRh6NChbNy4kVOnTql5Ro4cyYQJE3jw4AF58+alW7du6Ovr88MPP6h59u3bR506dXjy5AkmJiaZ6gkKCmLMmDGZ0iMjIzEzM3tp3EIIIT5sWq2Wu3fv8uTJE6Kjo4mKimLChAnY29ureU6dOsWoUaP45ZdfyJMnj5quKArBwcGkpKTQunVrjIyMiIqK4siRI0ydOpX8+fOzaNEi7t+/r17oyq6sDCtXrmTdunUsWrQIQ0NDAO7cucPAgQMZM2YMjo6OAIwYMQInJye6deuWbWytWrWiT58+1K5dW03btGkTy5cv56effnqr8/YxSkxM5OuvvyY+Ph5LS8v/tG4ZschFEhIS+Oeff6hRo4ZOeo0aNTh58qRO2vPDnwYGBlSuXJmzZ88CcPbsWapVq6Z2KjLKePz4MX///TcPHjxAq9Xi4eGh7reyssLNzS1TmypXrpwpbfny5cyaNYtLly7x+PFjUlJSMv3hOzg4qJ2KjPampaURExODjY0NkH5/RMaXcwBbW1udL9sZIxfTp09HT0+PyMhIZsyYkcWZy0xRFJ343yaWF72q3ceOHSMoKIiTJ0/y4MED0tLSgPSrO6VLlyYmJkYdhcnw/GsBcPLkSf7880+dEZ6Mqz5XrlyhVKlSmdo1bNgw+vfvr24nJCRgb2/P+ON6pBjqZ8qfW6RfJUxj1FG9T+BqqMSZm3wqsUqcbydjxOJ5ffr0wcvLi5MnT/Ltt9+q6ebm6aPTX3zxBXnz5lXTd+zYwdGjR7l9+7b6Gde7d29Kly7NP//8Q4cOHQgMDOT06dO0bNkSSP/MAejUqRNDhw5VR/u1Wi2///470dHRdO7cmebNm6v1rFu3jvj4eAYMGKCmpaamcubMGTZv3szjx491Pj8z2NraYmdnR5MmTdS0I0eO4ODgoJP2X9JqtURFRdGoUSO14/RfyZhxkBOkYyHeq4w3qQzR0dG0b9+eMWPG4OnpiZWVFcuWLWPatGlvXPaL/1E1Go36JRzSb1YzNjZmzZo1GBkZodVq1RGWVzl79ixOTk7vJZaXtfvJkyd4enri6enJkiVLKFiwILGxsXh6er7Rze+PHz/m22+/pU+fPpn2OTg4ZHmMsbExxsbGmdL3DGmYq29A12q1bNq0iWOBXv/5m/9/SeLMfT6VWCXO90NRFLRarU5dBgbpXwsNDQ110jM+f4yNjXXS9fT00Gg0GBoasnr1ap4+faruO3LkCF26dGHv3r04OzvrHHf69GkuXbpE9+7dddI9PT11LrQBdO7cmZIlSzJkyJAsR9sh/eLjrl27dDokO3bsoHr16jn+N/Piufyv6swp0rHIRSwtLbGzs2P//v3UqVNHTd+/f3+mK9oHDx5UhwxTUlI4duwY/v7+AJQqVYpVq1bpXLXfv38/FhYWFC1alHz58mFoaKheDYD0qVDnz5/XGYbMyoEDByhWrBgjRoxQ065du5YpX2xsLP/88w92dnZqe/X09LIcFcmOgYEBnTp1Ijw8HCMjI9q2bYupqekrjzt37hxbtmxh2LBh7ySWN3Hu3Dnu3bvHpEmT1OHpjGlVGdzc3DKtz33kyBGd7YoVK3LmzBlKlCjxVu0RQgjx8Rs2bBiNGzfGwcGBR48eERkZya5du9i6dSuQfo9CXFwcFy9eBNKnMVlYWODg4ED+/PmpVq0a+fLlo1OnTgQGBmJqasqCBQu4cuUK3t7eADg7O+vUeffuXSD9O8Xzox8A27Ztw8PDI9MiKxYWFpnSzM3Nsba21knv2LEjRYoUITg4GIC+fftSp04dpk2bhre3tzolef78+W955sSbklWhcplBgwYxefJkli9fTkxMDEOHDuXEiRP07dtXJ9+cOXNYs2YN586do1evXjx48IAuXboA0LNnT65fv07v3r05d+4c69atY/To0fTv3x89PT0sLCzo1KkTgwYNYufOnfz111907dpVvXLxMi4uLsTGxrJs2TIuXbrErFmzsrxvwcTEhE6dOnHy5En27t1Lnz59aNOmjToN6nV169aNHTt2sGXLFjW+56WkpBAXF8c///zDqVOn+N///kedOnWoUKECgwYNeiexvAkHBweMjIz43//+x+XLl1m/fj3jxo3TyfPtt99y7tw5hgwZwvnz51mxYgUREREA6vkfMmQIBw4cwN/fnxMnTnDhwgXWrVundh6FEEJ8Om7fvk3Hjh1xc3OjQYMGHDlyhK1bt9KoUSMA5s2bh7u7u7qISO3atXF3d2f9+vVA+o3QW7Zs4fHjx9SvX5/KlSuzb98+1q1bR/ny5d+oLfHx8eo0qH8rNjaWmzdvqtvVq1cnMjKS+fPnU758eVauXMnatWuzXB1SvF8yYpHL9OnTR52fePv2bUqXLq0uTfq8SZMmMWnSJE6cOEGJEiVYv349BQoUANJvAN+0aRODBg2ifPny5M+fn65duzJy5Ej1+OnTp/Pdd9/RtGlTLC0tGTx4MNevX892mDLDl19+Sb9+/fD39ycpKQlvb29GjRqV6aF+JUqU4KuvvqJJkybcv3+fpk2bqjdhvwkXFxeqV6/O/fv3qVq1aqb9f/31F7a2tujr62NlZUXp0qUZNmwY33//fZbTgv5NLG+iYMGCREREMHz4cGbNmkXFihUJCQnhyy+/VPM4OTmxcuVKBgwYwMyZM6lWrRojRozQaXO5cuXYvXs3I0aMoFatWiiKgrOzM76+vv+6bUIIIT5OCxcufOn+oKCgV352Va5cWR3heB1169Ylq/WBrKysWLFixWvf+7Br167XSmvdunWWD9oT/zFFfFKuXLmiAMrx48ffabmPHz9WrKyslB9//PGtyxo9erRSvnz5t2+UoihpaWmKs7OzMm3atHdS3odq/PjxStGiRd9pmfHx8Qqg3L17952W+6FJTk5W1q5dqyQnJ+d0U94riTP3+VRilThzF4nz/cv4/I6Pj//P65YRC/GvHD9+nHPnzuHh4UF8fDxjx44F0FndIafduXOHZcuWERcX91ZDrh+iuXPnUqVKFaytrdm/fz9Tp06VaU5CCCGEyFHSsRD/WkhICDExMRgZGVGpUiX27t2rTqf6EBQqVIgCBQowf/588uXLl9PNeacuXLjA+PHjuX//Pg4ODgwYMOCVN5sLIYQQQrxP0rH4xDg6OmY55/FNubu7c+zYsXfQosxeZ67n63gXcX6oZsyY8drP5BBCCCGE+C/IqlBCCCGEEEKItyYdCyGEEEIIIcRbk46FEEIIIcQ7FBwcTJUqVbCwsKBQoUL4+PgQExOjkycuLo5vvvkGGxsbzM3N8fDw4MCBA+r+Xbt2odFosvzJeCjqrl27aN68Oba2tpibm1OhQgWWLFmiU8/q1aupXLkyefPmVfP8/PPPmfJ88cUXWFtbo9FoOHHixGvF+euvv1KyZElMTEwoW7Zspoe3ik+PdCzES129evWN3mSEEEKIT93u3bvp1asXBw8eJCoqCq1WyxdffMGTJ0/UPB07diQmJob169dz6tQpfHx8CAkJ4fjx40D6Q99u3ryp89OtWzecnJyoXLkyAAcOHKBcuXKsWrWKP//8k86dO9OxY0d+++03tZ78+fMzYsQIoqOj1TydO3fWeSbFkydPqFmzJpMnT37tGA8cOEC7du3o2rUrx48fx8fHBx8fH06fPv22p098zP7zBW7FB6VTp04KoACKgYGB4ujoqAwaNEh5+vSpoiiKkpKSoty8eVPRarX/WVu+/fbbTPt69uypAEqnTp3eeztym06dOinNmzd/4+PkORa5i8SZ+3wqseaGOG/fvq0Ayu7du9U0c3NzZfHixep2cnKyYmFhocybNy/LMpKTk5WCBQsqY8eOfWldTZo0UTp37vzSPO7u7srIkSMzpb/Js67atGmjeHt766RVrVo1y8/w5+WG1/N1fKrPsZARC4GXlxc3b97k8uXLzJgxgx9++IHRo0cDoK+vj42NDQYG728BseTkZPV3e3t7li1bxtOnT9W0Z8+eERkZiYODw3trgxBCCPG+xMfHA+mjBxmqV6/O8uXLuX//PmlpaSxfvpzk5GRq166dZRnr16/n3r17r3wuU3x8vE49z1MUhe3btxMTE5NtPa8rOjqahg0b6qR5enoSHR39VuWKj5ssNyswNjbGxsYGSP9i37BhQ6Kiopg8eTJXr17FycmJ48ePU65cORwcHBgxYgTff/+9evzx48epVKkSV65coVixYjx8+JCBAweybt06kpKSqFy5MjNmzKB8+fJA+nKya9euxd/fnwkTJnDt2jXS0tIAqFixIpcuXWL16tW0b98eSJ/76eDggJOTk067t2zZwvjx4zl9+jT6+vpUq1aNmTNn4uzsDKC2fdWqVfzvf//j0KFDuLi4MG/ePKpVqwbAvXv38Pf3Z8+ePTx48ABnZ2eGDx9Ou3bt1HoePXrEd999x9q1a7G0tGTw4MGsW7eOChUqEBoaCkBSUhIjRoxg6dKlPHz4kDJlyjB58mTq1q0LQEREBAEBAfzyyy8MGDCA69ev06RJExYvXsyvv/7K6NGjiY+P55tvvmHGjBno6+u/UbnLly8nICCA69evU7NmTcLDw7G1tSUoKIiffvoJAI1GA8DOnTvV419H1eDtpBiYv3b+j42xvsIUDygTtJWkVE1ON+e9kThzn08l1o8tzquTvHW209LSCAgIoEaNGpQpU0ZNX7FiBb6+vlhbW2NgYICZmRlDhw6lRIkSWZa7cOFCPD09KVq0aLZ1r1ixgiNHjvDDDz/opMfHx1OkSBGSkpLQ19dn7ty5NGrU6C2iTL9HpHDhwjpphQsXJi4u7q3KFR836VgIHadPn+bAgQMUK1Ys0z49PT3atWtHZGSkTsdiyZIl1KhRQz2mdevWmJqasnnzZqysrPjhhx9o0KAB58+fV6+iXLx4kVWrVrF69Wr1S3SGLl26EB4ernYsFi1aROfOndm1a5dOvidPntC/f3/KlSvH48ePCQwMpEWLFpw4cQI9vf8bjBsxYgQhISG4uLgwYsQI2rVrx8WLFzEwMODZs2dUqlSJIUOGYGlpycaNG/nmm29wdnbGw8MDgP79+7N//37Wr19P4cKFCQwM5I8//qBChQpqHf7+/pw5c4Zly5ZhZ2fHmjVr8PLy4tSpU7i4uACQmJjIrFmzWLZsGY8ePeKrr76iRYsW5M2bl02bNnH58mVatmxJjRo18PX1faNyQ0JC+Pnnn9HT06NDhw4MHDiQJUuWMHDgQM6ePUtCQgLh4eEA2V7JSkpKIikpSd1OSEgAwFhPQV8/9z4TxFhP0fk3t5I4c59PJdaPLU6tVquz7e/vz+nTp9m5c6fOvhEjRvDgwQO2bNmCtbU1a9euZerUqTRp0gR3d3edMv7++2+2bt1KZGRkpvIz7Nq1i86dOxMWFoarq6tOPhMTE44cOcLjx4/ZuXMn/fv3x8HBgTp16mTZdq1Wm209z0tJSdHJl5qamuU5yK6O3Cwn48zJc6tRlFz8FDHxSn5+fvzyyy+YmJiQkpJCUlISenp6rFixgpYtW+qMWFSoUIETJ05QsWJFrl69ioODA2lpaTg4ODBy5Ei+++479u3bh7e3N7dv38bY2Fitp0SJEgwePJgePXoQFBTExIkTuXHjBgULFtRpy8OHD1mwYAH29vbqCholS5bk+vXrdOvWjbx58xIREZFlLHfv3qVgwYKcOnWKMmXKqG3/8ccf6dq1KwBnzpzhs88+4+zZs5QsWTLLcpo2bUrJkiUJCQnh0aNHWFtbExkZSatWrYD0Kz92dnZ0796d0NBQYmNjKV68OLGxsdjZ2anlNGzYEA8PDyZOnEhERASdO3fm4sWL6ojKd999x88//8ytW7fIkycPkD4tzdHRkXnz5v3rcufOncvYsWPVq0YZ53Xt2rUv/VsICgpizJgxmdIjIyMxMzN76bFCCCEymz9/PocOHWLixIk6V/dv3rzJ999/z6xZs3Sm+QYGBmJra6tz8Q5g+fLlbNq0iYULF2Y5Nfn06dOMHz+ezp074+np+cp2zZ49m7t372Z6GO2tW7f49ttvmT59OsWLF39pGd26dePLL7/kyy+/VNOWLl3KoUOH1NF8kTMSExP5+uuviY+Px9LS8j+tW0YsBPXq1SMsLIwnT54wY8YMDAwMaNmyZZZ5K1SoQKlSpYiMjGTo0KHs3r2b27dv07p1awBOnjzJ48ePsba21jnu6dOnXLp0Sd0uVqyYTqfieQULFsTb25uIiAgURcHb25sCBQpkynfhwgUCAwM5dOgQd+/eVadTxcbG6gw3lytXTv3d1tYWgNu3b1OyZElSU1OZOHEiK1as4MaNGyQnJ5OUlKR+kb58+TJarVYdvQCwsrLCzc1N3T516hSpqam4urrqtC8pKUnnPJiZmalf/iF9yNjR0VHtVGSk3b59+63KtbW1Vct4E8OGDaN///7qdkJCAvb29ow/rkeKof5Ljvy4GespjKucxqijeiSlffjTLP4tiTP3+VRi/djiPB3kiaIoBAQEcOLECfbs2aOOMGc4deoUAHXq1KFUqVJA+lXmoKAg7OzsaNKkiZpXURT69etHly5ddL7EZ9i9ezfBwcFMnjw5U4ckO2vWrCE5OVmnHkifQgxQs2ZNnVH5rNStW5e4uDidMiZNmkSjRo0ylfs8rVZLVFQUjRo1wtDQ8LXa+zHKyTgzZhzkBOlYCMzNzdU5nYsWLaJ8+fIsXLhQvcr/ovbt26sdi8jISLy8vNQvuo8fP8bW1jbTtCWAvHnz6tT5Ml26dMHf3x+AOXPmZJmnWbNmFCtWjAULFmBnZ0daWhplypTRuRkc0PkPnXGfQUYnZOrUqcycOZPQ0FDKli2Lubk5AQEBmcp4mcePH6Ovr8+xY8cyTet6vtPw4huLRqPJMi2jbW9T7r8ZiDQ2NtYZZcqwZ0jDTB3F3ESr1bJp0yaOBXrl+g85iTN3+VRi/Rjj7NmzJ5GRkaxbt478+fNz7949IP3ClKmpKWXLlqVEiRL4+/sTEhKCtbU1q1at4uTJk4wZM0Ynzu3bt3PlyhV69OiRKf6dO3fSvHlz+vbtS5s2bdR6jIyM1GmvwcHBVK5cGWdnZ5KSkti0aRNLliwhLCxMLe/+/fvExsbyzz//AOkX1QwNDbGxsVHvwezYsSNFihQhODgYgH79+lGnTh1mzZqFt7c3y5Yt49ixYyxYsOC1XidDQ8OP5vV8GzkRZ06eV+lYCB16enoMHz6c/v378/XXX2eZ5+uvv2bkyJEcO3aMlStXMm/ePHVfxYoViYuLw8DAAEdHx3/dDi8vL5KTk9FoNFkO6967d4+YmBgWLFhArVq1ANi3b98b17N//36aN29Ohw4dgPQOx/nz5yldujQAxYsXx9DQkCNHjqjD1fHx8Zw/f15dUcPd3Z3U1FRu376ttuVdeFflGhkZqfNehRBCvH9hYWEAmRbKCA8Px8/PD0NDQzZt2sTQoUNp1qwZjx8/xtnZmT59+tC4cWOdYxYuXEj16tWznL77008/kZiYSHBwsPqFH9JHQjIu8D158oSePXvy999/Y2pqSsmSJfnll1/Ue/kgfcWp51ebatu2LQCjR49Wp0vFxsbq3L9YvXp1IiMjGTlyJMOHD8fFxYW1a9fqzBgQnx7pWIhMWrduzaBBg5gzZ456X8HzHB0dqV69Ol27diU1NVVnaLZhw4ZUq1YNHx8fpkyZgqurK//88w8bN26kRYsW6kN9XkVfX5+zZ8+qv78oX758WFtbM3/+fGxtbYmNjWXo0KFvHKuLiwsrV67kwIED5MuXj+nTp3Pr1i21Y2FhYUGnTp0YNGgQ+fPnp1ChQowePRo9PT119MPV1ZX27dvTsWNHpk2bhru7O3fu3GH79u2UK1cOb2/vlzUhW++qXEdHR7Zu3UpMTAzW1tZYWVl9EleJhBAip7zOqLGLiwurVq1StzNGZl4UGRmZbRkRERHZ3neYYfz48YwfP/6lefz8/PDz83tpnqxmIrRu3VqdCi0EyJO3RRYMDAzw9/dnypQpOk8JfV779u05efIkLVq0wNTUVE3XaDRs2rSJ2rVr07lzZ1xdXWnbti3Xrl3LtCzdq1haWmZ705Genp467FqmTBn69evH1KlT36h8gJEjR1KxYkU8PT2pW7cuNjY2+Pj46OSZPn061apVo2nTpjRs2JAaNWpQqlQpTExM1Dzh4eF07NiRAQMG4Obmho+Pj84ox7/1Lsrt3r07bm5uVK5cmYIFC7J///63apMQQgghRFZkVSgh3tCTJ08oUqQI06ZNy/Y+lNwgISEBKysr7t69+0ncY9GkSZNcPZIjceY+n0qsEmfuInG+fxmf37IqlBAfoOPHj3Pu3Dk8PDyIj49n7NixADRv3jyHWyaEEEII8eGQjoUQryEkJISYmBiMjIyoVKkSe/fuzXIJXCGEEEKIT5V0LIR4BXd3d44dO5bTzRBCCCGE+KDJzdtCCCGEEEKItyYdCyGEEEIIIcRbk46FyFXmz5+Pvb09enp6hIaG5nRz3oldu3ah0Wh4+PBhTjdFCCFyjeDgYKpUqYKFhQWFChXCx8eHmJiYTPmio6OpX78+5ubmWFpaUrt2bZ4+fQr83/tzVj9HjhzJVNbFixexsLAgb968OumrV6/m888/5+uvvyZv3rxUqFCBn3/+WSfPrVu38PPzw87ODjMzM7y8vLhw4cIr4/z1118pWbIkJiYmlC1bNstnZQjxrkjHQuQ4Pz8/9Y3Y0NCQwoUL06hRIxYtWkRaWtprl5OQkIC/vz9Dhgzhxo0b9OjR4z22+uUcHR3/Vcembt26BAQE6KRVr16dmzdvYmVl9W4aJ4QQgt27d9OrVy8OHjxIVFQUWq2WL774Quf5TdHR0Xh5efHFF19w+PBhjhw5gr+/v/oE6oz35+d/unXrhpOTU6YHwmq1Wtq1a0etWrUytSV//vwMHTqUyZMnc+zYMTp37kznzp3ZunUrkP7APR8fHy5fvsy6des4fvw4xYoVo2HDhtk+bwrgwIEDtGvXjq5du3L8+HF8fHzw8fHh9OnT7+IUCpGJ3LwtPgheXl6Eh4eTmprKrVu32LJlC3379mXlypWsX78eA4NX/6nGxsai1Wrx9vbG1tb2X7dFq9V+UGtrGxkZYWNjk9PNEEKIXGXLli062xERERQqVIhjx45Ru3ZtAPr160efPn0YOnSoms/NzU39/cX3Z61Wy7p16+jduzcajUan/JEjR1KyZEkaNGjAgQMHdPbVrVtXfe6Bs7Mzffv25aeffmLfvn14enpy4cIFDh48yOnTp/nss88ACAsLw8bGhqVLl9KtW7csY5w5cyZeXl4MGjQIgHHjxhEVFcXs2bOZN2/em54yIV5JRizEB8HY2BgbGxuKFClCxYoVGT58OOvWrWPz5s1EREQA8PDhQ7p160bBggWxtLSkfv36nDx5Ekj/QChbtiwAxYsXR6PRcPXqVSD9zdfZ2RkjIyPc3NwyDS9rNBrCwsL48ssvMTc3Z8KECQCsW7eOihUrYmJiQvHixRkzZgwpKSlA+tWjoKAgHBwcMDY2xs7Ojj59+gDpHxDXrl2jX79+6kgMwL1792jXrh1FihTBzMyMsmXLsnTpUrUdfn5+7N69m5kzZ6rHXb16NcupUKtWreKzzz7D2NgYR0dHpk2bphOTo6MjEydOpEuXLlhYWODg4MD8+fPfwSslhBC5U3x8PJA+egBw+/ZtDh06RKFChahevTqFCxemTp067Nu3L9sy1q9fz7179+jcubNO+o4dO/j111+ZM2fOK9uhKArbt28nJiZG7eAkJSUBYGJioubT09PD2Nj4pe2Jjo6mYcOGOmmenp5ER0e/sh1C/BsyYiE+WPXr16d8+fKsXr2abt260bp1a0xNTdm8eTNWVlb88MMPNGjQgPPnz+Pr64u9vT0NGzbk8OHD2NvbU7BgQdasWUPfvn0JDQ2lYcOG/Pbbb3Tu3JmiRYtSr149ta6goCAmTZpEaGgoBgYG7N27l44dOzJr1ixq1arFpUuX1KlVo0ePZtWqVcyYMYNly5bx2WefERcXp3ZyVq9eTfny5enRowfdu3dX63j27BmVKlViyJAhWFpasnHjRr755hucnZ3x8PBg5syZnD9/njJlyqgP4StYsKDaQcpw7Ngx2rRpQ1BQEL6+vhw4cICePXtibW2Nn5+fmm/atGmMGzeO4cOHs3LlSr7//nvq1Kmjc7XtdVQN3k6KgfkbHfMxMdZXmOIBZYK2kpSqefUBHymJM/f5VGJ9H3FeneSts52WlkZAQAA1atSgTJkyAFy+fBlI/3wICQmhQoUKLF68mAYNGnD69GlcXFwylbtw4UI8PT0pWrSomnbv3j38/Pz45ZdfXvoU5Pj4eNq2bUtKSgr6+vrMnTuXRo0aAVCyZEkcHBwYNmwYP/zwA+bm5syYMYO///6bmzdvZltmXFwchQsX1kkrXLgwcXFxrzhDQvw70rEQH7SSJUvy559/sm/fPg4fPszt27cxNjYG0h9at3btWlauXEmPHj2wtrYG0r+MZwxNh4SE4OfnR8+ePQHo378/Bw8eJCQkRKdj8fXXX+tcYerSpQtDhw6lU6dOQPooyLhx4xg8eDCjR48mNjYWGxsbGjZsiKGhIQ4ODnh4eADpV7v09fWxsLDQGSIvUqQIAwcOVLd79+7N1q1bWbFiBR4eHlhZWWFkZISZmdlLpz5Nnz6dBg0aMGrUKABcXV05c+YMU6dO1elYNGnSRI17yJAhzJgxg507d2bbsUhKSlKvikH6PSsAxnoK+vpKtu352BnrKTr/5lYSZ+7zqcT6PuLUarU62/7+/pw+fZqdO3eq+5KTkwHo1q0bHTp0AGDKlCls27aNBQsWqKPbGf7++2+2bt1KZGSkTvldu3bF19eXatWqodVqSU1NzbINJiYmzJgxg/Lly7N371769++Pg4MDderUAWDFihX06NFD/Yxp0KABXl5eKIqSqaznpaSk6OzPrv7/Ska9OVX/fyUn48zJcysdC/FBUxQFjUbDyZMnefz4sdp5yPD06VMuXbqU7fFnz57NdBN3jRo1mDlzpk7aizfZnTx5kv379+t8cKSmpvLs2TMSExNp3bo1oaGhFC9eHC8vL5o0aUKzZs1eei9IamoqEydOZMWKFdy4cYPk5GSSkpIwMzN75Xl4MabmzZtniik0NJTU1FT09fUBKFeunLpfo9FgY2PD7du3sy03ODiYMWPGZEof6Z6GmVnqG7XxYzSu8usvFPAxkzhzn08l1ncZ5/MrI82fP59Dhw4xceJE/vzzT/78808gfRUmSO9gPJ/fysqKQ4cOZVpdafny5VhYWGBgYKCzLyoqig0bNjB9+nQ1LS0tDRMTE3r27KkzVcnW1pbbt2/j5uZGlSpVGDRoEEFBQer+sWPH8uTJE1JSUrCysmLQoEGUKFEi25WerKys2LVrl85Iyf79+zEzM8vx1aGioqJytP7/Sk7EmZiY+J/XmUE6FuKDdvbsWZycnHj8+DG2trbs2rUrU54Xl+37N8zNdaf6PH78mDFjxvDVV19lymtiYoK9vT0xMTFs27aNqKgoevbsydSpU9m9e3e2N35PnTqVmTNnEhoaStmyZTE3NycgIEC9KvauvdgOjUbz0lW2hg0bRv/+/dXthIQE7O3tqVevXqYOXW6i1WqJioqiUaNGH9RN+++axJn7fCqxvq84FUUhICCAEydOsGfPnkxTmxRFYcyYMZiamtKkSRM1ffTo0Xh6euqkKYpCv3796NKlC19++aVOOdHR0eooAcCGDRsICQlh9+7dFClShHz58mUZ55o1a0hOTtap53kXLlzg0qVLhIaGqlOmXlS3bl3i4uJ0ypg0aRKNGjXKttz3Tf5u37+MGQc5QToW4oO1Y8cOTp06Rb9+/ShatChxcXEYGBjg6Oj42mWUKlWK/fv3q1OaIP1qTenSpV96XMWKFYmJiaFEiRLZ5jE1NaVZs2Y0a9aMXr16UbJkSU6dOkXFihUxMjLS+SDJqLd58+bqkHpaWhrnz5/XaUtWx2UX04tlu7q6qqMV/4axsbE6zex5hoaGufrNP4PEmbt8KnHCpxPru46zZ8+eREZGsm7dOvLnz8+9e/eA9Kv8pqamAAwaNIjRo0dTsWJFKlSowE8//URMTAyrVq3Sacv27du5cuUKPXr0yNTG50ePIX1EXE9PD3d3dzUtODiYChUqEBcXx8WLF4mKimLJkiWEhYWp5f36668ULFgQBwcHTp06Rd++ffHx8dHpIHTs2JEiRYoQHBwMpK9qVadOHWbNmoW3tzfLli3j2LFjLFiwIMf/ZuTv9v3WmVOkYyE+CElJScTFxeksNxscHEzTpk3p2LEjenp6VKtWDR8fH6ZMmYKrqyv//PMPGzdupEWLFpmmMmUYNGgQbdq0wd3dnYYNG7JhwwZWr17Ntm3bXtqewMBAmjZtioODA61atUJPT4+TJ09y+vRpxo8fT0REBKmpqVStWhUzMzN++eUXTE1NKVasGJC+KtOePXto27YtxsbGFChQABcXF1auXMmBAwfIly8f06dP59atWzodC0dHRw4dOsTVq1fJkyePujrJ8wYMGECVKlUYN24cvr6+REdHM3v2bObOnfsWr4AQQnxawsLCgPSr+s8LDw9X71cLCAjg2bNn9OvXj/v371O+fHmioqJwdnbWOWbhwoVUr16dkiVL/qu2PHnyhD59+hAbG4u5uTklS5bkl19+wdfXV81z8+ZN+vfvz61bt7C1taVjx47qvXYZYmNj1WdsQPpzNiIjIxk5ciTDhw/HxcWFtWvXqjeoC/HOKULksE6dOimAAigGBgZKwYIFlYYNGyqLFi1SUlNT1XwJCQlK7969FTs7O8XQ0FCxt7dX2rdvr8TGxiqKoijHjx9XAOXKlSs65c+dO1cpXry4YmhoqLi6uiqLFy/W2Q8oa9asydSuLVu2KNWrV1dMTU0VS0tLxcPDQ5k/f76iKIqyZs0apWrVqoqlpaVibm6ufP7558q2bdvUY6Ojo5Vy5copxsbGSsZ/s3v37inNmzdX8uTJoxQqVEgZOXKk0rFjR6V58+bqcTExMcrnn3+umJqaqrHs3LlTAZQHDx6o+VauXKmULl1aMTQ0VBwcHJSpU6fqtL1YsWLKjBkzdNLKly+vjB49+mUvhY74+HgFUO7evfvax3yMkpOTlbVr1yrJyck53ZT3SuLMfT6VWCXO3EXifP8yPr/j4+P/87o1iqLk7uUkhBD/SkJCAlZWVty9ezfX32OxadMmmjRpkquH5SXO3OdTiVXizF0kzvcv4/M7Pj7+pUscvw/ygDwhhBBCCCHEW5OOhRBCCCGEEOKtScdCCCGEEEII8dakYyGEEEIIIYR4a9KxEEIIIYQQQrw16VgIIYQQ4pMQHBxMlSpVsLCwoFChQvj4+BATE5MpX3R0NPXr18fc3BxLS0tq167N06dP1f2Ojo5oNBqdn0mTJqn7Y2JiqFevHoULF8bExITixYszcuRItFqtTj2//vorJUuWxMTEBHd3d44ePaqzX1EUAgMDsbW1xdTUlIYNG3LhwoVXxjlnzhwcHR0xMTGhatWqHD58+E1PlRD/inQsRK7k6OhIaGjoe6/Hz88PHx+f91rHrl270Gg0PHz48L3WI4QQud3u3bvp1asXBw8eJCoqCq1WyxdffMGTJ0/UPNHR0Xh5efHFF19w+PBhjhw5gr+/v86D5wDGjh3LzZs31Z/evXur+wwNDenYsSO///47MTExhIaGsmDBAkaPHq3mOXDgAO3ataNr164cP36cL7/8kkmTJnH69Gk1z5QpU5g1axbz5s3j0KFDmJub4+npybNnz7KNcfny5fTv35/Ro0fzxx9/UL58eTw9Pbl9+/a7OIVCvNx//uQMIV5TnTp1lL59+2ZKDw8PV6ysrF56bFYPiHsfHj58qPPgureVVcxJSUnKzZs3lbS0tHdWz+uQB+TlLhJn7vOpxPo+47x9+7YCKLt371bTqlatqowcOfKlx/2bz5h+/fopNWvWVLfbtGmjeHt7q9vJycmKq6ur0r17d0VRFCUtLU2xsbHReQDqw4cPFWNjY2Xp0qXZ1uPh4aH06tVL3U5NTVXs7OyU4ODgN2rv+yJ/t+9fTj4gT0YsRK6SnJz8n9ZnZWVF3rx532sdRkZG2NjYoNFo3ms9QgjxqYmPjwcgf/78ANy+fZtDhw5RqFAhqlevTuHChalTpw779u3LdOykSZOwtrbG3d2dqVOnkpKSkm09Fy9eZMuWLdSpU0dNi46OpmHDhjr53N3dOXjwIABXrlwhLi5OJ4+VlRVVq1YlOjo6y3qSk5M5duyYzjF6eno0bNgw22OEeJcMcroBQrwNPz8/Hj58SJUqVZgzZw7GxsZcuXIFgEePHtGuXTvWr19P3rx5GT58OL169VKPnT59OuHh4Vy+fJn8+fPTrFkzpkyZQp48eQCIiIggICCA5cuXExAQwPXr16lZsybh4eHY2trq1L927VquXr2Kk5NTpjbWqVOHXbt2ce/ePfz9/dmzZw8PHjzA2dmZ4cOH065dO7Ws3bt3s3v3bmbOnAmkf7BcvXqVevXq8eDBA7UTs2rVKgIDA7l48SK2trb07t2bAQMGqHU6OjrSo0cPLl68yK+//kq+fPkYOXIkPXr0eONzXDV4OykG5m983MfCWF9higeUCdpKUmru7bxJnLnPpxLru4rz6iRvne20tDQCAgKoUaMGZcqUAeDy5csABAUFERISQoUKFVi8eDENGjTg9OnTuLi4ANCnTx8qVqxI/vz5OXDgAMOGDePmzZtMnz5dp47q1avzxx9/kJSURI8ePRg7dqy6Ly4ujsKFC+vkt7Ky4tatW+p+IFOewoULq/tedPfuXVJTU7M85ty5c68+SUK8JelYiI/e9u3bsbS0JCoqSid96tSpDB8+nDFjxrB161b69u2Lq6srjRo1AtKv4syaNQsnJycuX75Mz549GTx4MHPnzlXLSExMJCQkhJ9//hk9PT06dOjAwIEDWbJkSaZ22Nvbc/PmTXU740pT7dq1AXj27BmVKlViyJAhWFpasnHjRr755hucnZ3x8PBg5syZnD9/njJlyqgfPgULFuTq1as69Rw7dow2bdoQFBSEr68vBw4coGfPnlhbW+Pn56fmmzZtGuPGjWP48OGsXLmS77//njp16uDm5pbleUxKSiIpKUndTkhIAMBYT0FfX3nVy/DRMtZTdP7NrSTO3OdTifVdxfnijdP+/v6cPn2anTt3qvsyRr27detGhw4dgPT7HLZt28aCBQuYMGECgM79FKVKlUJfX5+ePXsyduxYjI2N1X2//PILjx494s8//2TYsGFMnjyZgQMHqvtTUlLUujP+VRQFrVarjoBotVqdtqelpaHRaDLF83wZz5cLkJqaqpab016MN7fKyThz8txKx0J89MzNzfnxxx8xMjLSSa9RowZDhw4FwNXVlf379zNjxgy1YxEQEKDmdXR0ZPz48Xz33Xc6HQutVsu8efNwdnYG0j+Inr/i9Dx9fX1sbGyA9E6Ej48P1apVIygoCIAiRYrofKD07t2brVu3smLFCjw8PLCyssLIyAgzMzO1nKxMnz6dBg0aMGrUKDW2M2fOMHXqVJ2ORZMmTejZsycAQ4YMYcaMGezcuTPbjkVwcDBjxozJlD7SPQ0zs9Rs25NbjKucltNN+E9InLnPpxLr28a5adMm9ff58+dz6NAhJk6cyJ9//smff/4JoI4WJCcn6+S3srLi0KFDOmnPe/bsGSkpKSxevJgiRYpk2m9paUnr1q0JCgrCzc0NfX19rKys2LVrF5aWlmq++Ph4zM3N2bRpkzoqsWrVKooXL67mOXfuHE5OTlm2RavVoqenx6ZNm7h//76afvz4cTQaTbbtzwkvXgzMrXIizsTExP+8zgzSsRAfvbJly2bqVABUq1Yt0/bzK0Vt27aN4OBgzp07R0JCAikpKTx79ozExETMzMwAMDMzUzsVALa2tq+1skaXLl149OgRUVFR6koiqampTJw4kRUrVnDjxg2Sk5NJSkpS63pdZ8+epXnz5jppNWrUIDQ0lNTUVPT19QEoV66cul+j0WBjY/PStg8bNoz+/fur2wkJCdjb2zP+uB4phvpv1MaPibGewrjKaYw6qkdSWi6eTiJx5jqfSqzvKs7TQZ4oikJAQAAnTpxgz5496tSmDIqiMGbMGExNTWnSpImaPnr0aDw9PXXSnhcZGYmenh6tWrUiX758Wea5d+8eaWlpeHl5YWhoSN26dYmLi1PL1Gq1DBkyhAYNGtCkSRMURSEoKAitVqvmSUhI4OLFiwwdOjTbtlSqVImEhAR1f1paGr169eL777/P9pj/klarJSoqikaNGmFoaJjTzXlvcjLOjBkHOUE6FuKDZWlpqd5Y97yHDx9iZWWlbpubv/n8/6tXr9K0aVO+//57JkyYQP78+dm3bx9du3YlOTlZ/bL/4puBRqNBUV4+HD9+/Hi2bt3K4cOHsbCwUNOnTp3KzJkzCQ0NpWzZspibmxMQEPDebjjPqu1padlf8TM2NtYZws+wZ0hDrK2t33n7PhRarZZNmzZxLNAr13/ISZy5y6cS67uMs2fPnkRGRrJu3Try58/PvXv3gPQRCVNTUwAGDRrE6NGjqVixIhUqVOCnn34iJiaGVatWYWhoSHR0NIcOHaJevXpYWFgQHR3NoEGD6NChA4UKFQJgyZIlGBoaUrZsWYyNjTl69CijRo3C19dX/Xzp168fderUYdasWXh7e7NkyRIuXbrE0qVL1TgDAgIIDg6mZMmSODk5MWrUKOzs7GjVqpWap0GDBrRo0QJ/f38ABgwYQKdOnfDw8MDDw4PQ0FCePHlCt27dPqi/E0NDww+qPe9LTsSZk+dVOhbig+Xm5sbvv/+eKf2PP/7A1dX1lcdnrKzx/HapUqWA9PsU0tLSmDZtmjqisGLFirdu86pVqxg7diybN2/WGekA2L9/P82bN1fn7aalpXH+/HlKly6t5jEyMiI19eXTjkqVKsX+/fszle3q6qqOVgghhMgsLCwMgLp16+qkh4eHq1NJAwICePbsGf369eP+/fuUL1+eqKgo9T3d2NiYZcuWERQURFJSEk5OTvTr109nxNfAwIDJkydz/vx5FEWhWLFi+Pv7069fPzVP9erViYyMZOTIkQwfPpwSJUowdOhQ9UZygMGDB/PkyRN69OjBw4cPqVmzJlu2bMHExETNc+nSJe7evatu+/r6cufOHQIDA4mLi6NChQps2bIl0w3dQrwP0rEQH6zvv/+e2bNn06dPH7p164axsTEbN25k6dKlbNiw4ZXH79+/nylTpuDj40NUVBS//vorGzduBKBEiRJotVr+97//0axZM/bv38+8efPeqr2nT5+mY8eODBkyhM8++0ydH2tkZET+/PlxcXFh5cqVHDhwgHz58jF9+nRu3bql07FwdHTk0KFDXL16lTx58qhLID5vwIABVKlShXHjxuHr60t0dDSzZ8/WuTdECCFEZq8acc4wdOhQ9R69F1WsWDHThasX+fr64uvr+8p6WrduTevWrYH/G5l5nkajYezYsdne2wdkWuAD0u8HzBjBEOK/JM+xEB+s4sWLs2fPHs6dO0fDhg2pWrUqK1as4Ndff8XLy+uVxw8YMICjR4/i7u7O+PHjmT59Op6engCUL1+e6dOnM3nyZMqUKcOSJUsIDg5+q/YePXqUxMRExo8fj62trfrz1VdfATBy5EgqVqyIp6cndevWxcbGJtNTuwcOHIi+vj6lS5emYMGCxMbGZqqnYsWKrFixgmXLllGmTBkCAwMZO3aszo3bQgghhBD/NY3yut13IcQnJSEhASsrK+7evftJ3GPRpEmTXD3fV+LMfT6VWCXO3EXifP8yPr/j4+N1Vh37L8iIhRBCCCGEEOKtScdCCCGEEEII8dakYyGEEEIIIYR4a9KxEEIIIYQQQrw16VgIIYQQQggh3pp0LIT4wAUFBVGhQgV128/PL9MytUIIkVtNnjyZgQMHkj9/fgoVKoSPjw8xMTFZ5lUUhcaNG6PRaFi7dq3OviNHjtCgQQPy5s1Lvnz58PT05OTJk5mODwkJwdXVFWNjY4oUKcKECRPU/atXr6ZRo0YULFgQS0tLqlWrxtatWzO148aNG3To0AFra2tMTU0pW7YsR48efWmcu3fvpn///uTJk4cSJUoQERHxeidIiA+IdCzEB8nPzw+NRoNGo8HQ0JDChQvTqFEjFi1aRFpaWk43j+vXr9OlSxfs7OwwMjKiWLFi9O3bl3v37r33umfOnKnzgVO3bl0CAgLee71CCJET9u7dS+PGjdm7dy9RUVFotVq++OILnjx5kilvaGgoGo0mU/rjx4/x8vLCwcGBQ4cOsW/fPiwsLPD09ESr1ar5+vbty48//khISAjnzp1j/fr1eHh4qPv37NlDo0aN2LRpE8eOHaNevXo0a9aM48ePq3kePHhAjRo1MDQ0ZPPmzZw5c4Zp06aRL1++bGO8cuUKzZs3p0yZMhw5coSAgAC6deuWZadFiA+ZPHlbfLC8vLwIDw8nNTWVW7dusWXLFvr27cvKlStZv349BgY58+d7+fJlqlWrhqurK0uXLsXJyYm//vqLQYMGsXnzZg4ePJjlE7PfFSsrq/dWthBCfGh+++03Nm3axGeffYahoSEREREUKlSIY8eOUbt2bTXfiRMnmDZtGkePHsXW1lanjHPnznH//n3Gjh2Lvb09AKNHj6ZcuXJcu3aNEiVKcPbsWcLCwjh9+jRubm4AODk56ZQTGhqqsz1x4kTWrVvHhg0bcHd3B9JHWOzt7QkPD1fzvVjOi+bNm4ejoyNdunShVKlSlCtXjn379jFjxgz1wa5CfAxkxEJ8sIyNjbGxsaFIkSJUrFiR4cOHs27dOjZv3qxesZ8+fTply5bF3Nwce3t7evbsyePHj9UyIiIiyJs3L7/99htubm6YmZnRqlUrEhMT+emnn3B0dCRfvnz06dOH1NRU9bi5c+fi4uKCiYkJhQsXplWrVuq+Xr16YWRkxO+//06dOnVwcHCgcePGbNu2jRs3bjBixAg1b1bD8Xnz5tUZcRgyZAiurq6YmZlRvHhxRo0apXMF7UXPT4Xy8/Nj9+7dzJw5Ux3huXLlCiVKlCAkJETnuBMnTqDRaLh48eLrvgRCCPHBiY+PB9C5gJOYmMjXX3/NnDlzsLGxyXSMm5sb1tbWLFy4kOTkZJ4+fcrChQspVaoUjo6OAGzYsIHixYvz22+/4eTkhKOjI926deP+/fvZtiUtLY1Hjx7ptGX9+vVUrlyZ1q1bU6hQIdzd3VmwYMFLY4qOjqZBgwY6aZ6enkRHR7/yfAjxIZERC/FRqV+/PuXLl2f16tV069YNPT09Zs2ahZOTE5cvX6Znz54MHjyYuXPnqsckJiYya9Ysli1bxqNHj/jqq69o0aIFefPmZdOmTVy+fJmWLVtSo0YNfH19OXr0KH369OHnn3+mevXq3L9/n7179wJw//59tm7dyoQJEzA1NdVpm42NDe3bt2f58uXMnTs3y+H4rFhYWBAREYGdnR2nTp2ie/fuWFhYMHjw4FceO3PmTM6fP0+ZMmUYO3YsAAULFqRLly6Eh4czcOBANW94eDi1a9emRIkSr9WuDFWDt5NiYP5Gx3xMjPUVpnhAmaCtJKW+3mv2MZI4c59PIdark7x1ttPS0ggICKBGjRqUKVNGTe/Xrx/Vq1enefPmWZZjYWHBrl278PHxYdy4cQC4uLiwdetWdfT78uXLXLt2jV9//ZXFixeTmppKv379aNWqFTt27Miy3JCQEB4/fkybNm3UtMuXLxMWFkb//v0ZPnw4R44coU+fPhgZGdGpU6csy4mLi6NQoUI6aYULFyYhIYGnT59m+rwR4kMlHQvx0SlZsiR//vkngM69BY6OjowfP57vvvtOp2Oh1WoJCwvD2dkZgFatWvHzzz9z69Yt8uTJQ+nSpalXrx47d+7E19eX2NhYzM3Nadq0KRYWFhQrVkwd4r5w4QKKolCqVKks21aqVCkePHjAnTt3Mn1IZGfkyJE6MQwcOJBly5a9VsfCysoKIyMjzMzMdK7S+fn5ERgYyOHDh/Hw8ECr1RIZGZlpFON5SUlJJCUlqdsJCQkAGOsp6OsrrxXLx8hYT9H5N7eSOHOfTyFWrVarjuBqtVr8/f05ffo0O3fuVNM3bNjAjh07OHz4sM5ob0pKirr99OlTunTpQrVq1fj5559JTU1l+vTpNGnShOjoaExNTUlJSSEpKYmFCxfi6uoKwA8//EDVqlV1pkdlWLp0KWPGjGHVqlXky5dPrSstLY1KlSoxZswYAMqUKcOff/5JWFgYX3/9dZZxKoqijppnlJOSkqJu59TU3/fh+dczN8vJOHPy3Oaev1TxyVAURR0N2LZtG8HBwZw7d46EhARSUlJ49uwZiYmJmJmZAWBmZqZ2KiD9KpCjoyN58uTRSbt9+zYAjRo1olixYhQvXhwvLy+8vLxo0aKFWl5GG17GyMjoteNZvnw5s2bN4tKlSzx+/JiUlBQsLS1f+/is2NnZ4e3tzaJFi/Dw8GDDhg0kJSXRunXrbI8JDg5WPwifN9I9DTOz1CyOyF3GVc75RQH+CxJn7pObY920aZP6e+vWrTl06BATJ07kzz//VC8whYeHc+nSJQoUKKBzrK+vL6VKlWLChAlERUVx/vx5hg0bpr7Xf/3113To0IGxY8dSq1YtHj9+jL6+PhcvXlSnjGZcbFm1apXO6nx79+7lf//7H4MHDyYpKUmnnXnz5iVPnjw6aSkpKVy4cEEn7XlGRkYcPXqUChUqEBUVBcD27dsxMzNj586d//b0fdAy4sztciLOxMTE/7zODNKxEB+ds2fP4uTkxNWrV2natCnff/89EyZMIH/+/Ozbt4+uXbuSnJysdgQMDQ11js9YaerFtIzVpiwsLPjjjz/YtWsXv//+O4GBgQQFBXHkyBFKlCiBRqPh7NmztGjRIsu2FSxYkLx586rlvtgJef5KQnR0NO3bt2fMmDF4enpiZWXFsmXLmDZt2lufp27duvHNN98wY8YMwsPD8fX11ekcvWjYsGH0799f3U5ISMDe3p569ephbW391u35UGm1WqKiomjUqFGmv4vcROLMfT6VWJOTk2nTpg3Hjx9nz549uLi46OyvWLEid+/ezZQWEhKCt7c3Tk5OXLlyBVNTU7y9vdULUykpKRgYGFCuXDmaNGmCoaEhy5cvx83NTb0YlbEcbatWrdRRjGXLljFnzhwiIyP58ssvM7W3fv36/P333zRp0kRN27FjB66urjppz9u7dy+bN28GUF/PpUuXUrNmzWyP+Vh9Kn+3ORlnxoyDnCAdC/FR2bFjB6dOnaJfv34cO3aMtLQ0pk2bhp5e+joEK1aseCf1GBgY0LBhQxo2bMjo0aPJmzcvO3bs4KuvvqJRo0bMnTuXfv366cx7jYuLY8mSJfTq1UtNK1iwIDdv3lS3L1y4oHMl4cCBAxQrVkznhu9r1669UVuNjIx0bjzP0KRJE8zNzQkLC2PLli3s2bPnpeUYGxtjbGycKd3Q0DBXv/lnkDhzl08lTsj9sfbu3Ztdu3axfv168ufPry7rbWVlhampKfb29upKT89zcnJSOwNeXl4MHTqUgIAAevfuTVpaGpMmTcLAwED94ufl5UXFihX59ttvCQ0NJS0tDX9/fxo1asRnn30GQGRkJF26dGHmzJnUqFFDbYupqam6Yt+AAQOoXr06U6dOpU2bNhw+fJgff/yR+fPnq6/TsGHDuHHjBosXLwbSFwUJCwsjIiKC4sWLs3fvXlauXMnGjRtz7Wub2/9uM+REnDl5XmVVKPHBSkpKIi4ujhs3bvDHH38wceJEmjdvTtOmTenYsSMlSpRAq9Xyv//9j8uXL/Pzzz8zb968t673t99+Y9asWZw4cYJr166xePFi0tLS1Pm1s2fPJikpCU9PT/bs2cP169fZsmULjRo1wtXVlcDAQLWs+vXrM3v2bI4fP87Ro0f57rvvdP7Du7i4EBsby7Jly7h06RKzZs1izZo1b9ReR0dHDh06xNWrV7l796468qKvr4+fnx/Dhg3DxcWFatWqvfW5EUKI/9oPP/xAYmIiDRs2xNbWVv1Zvnz5a5dRsmRJNmzYwJ9//km1atWoVasW//zzD1u2bFGXptXT02PDhg0UKFCA2rVr4+3tTalSpVi2bJlazvz580lJSaFXr146benbt6+ap0qVKqxZs4alS5dSpkwZxo0bR2hoKO3bt1fz3Lx5k9jYWHXbycmJdevWcfLkSSpXrsy0adP48ccfZalZ8dGREQvxwcp4wzcwMCBfvnyUL1+eWbNm0alTJ/T09ChfvjzTp09n8uTJDBs2jNq1axMcHEzHjh3fqt68efOyevVqgoKCePbsGS4uLixdulS9YuXi4sKRI0cICgqiTZs23L59G0VR+Oqrr/j55591phtNmzaNzp07U6tWLezs7Jg5cybHjh1T93/55Zf069cPf39/kpKS8Pb2ZtSoUQQFBb12ewcOHEinTp0oXbo0T58+5cqVK+ryiV27dmXixIl07tz5rc6JEELklOTkZDZt2qROV3odWd0H16hRIxo1avTS4+zs7Fi1alW2+3ft2vVa9Tdt2pSmTZtmuz+rp2rXqVOHGTNmvFGcQnxoNMqr7kIVQrzS6NGjmT59OlFRUXz++ec53RzV3r17adCgAdevX6dw4cJvdGxCQgJWVlbcvXs3199j8aZfWj5GEmfu86nEKnHmLhLn+5fx+R0fH//Wi8G8KRmxEOIdGDNmDI6Ojhw8eBAPDw/1no+ckpSUxJ07dwgKCqJ169Zv3KkQQgghhHhT0rEQ4h35kKYbLV26lK5du1KhQgX15kAhhBBCiPdJbt4WIhfy8/MjNTWVY8eOUaRIkZxujhBCCCE+AdKxEEIIIYQQQrw16VgIIYQQQggh3pp0LIQQQgghhBBvTToWQvxLGo2GtWvXAnD16lU0Gg0nTpx4L3X5+fnh4+PzXsoWQogPSXBwMFWqVMHCwoJChQrRsmVLbty4kWVeRVFo3Lixzvvxi+7du0fRokXRaDQ8fPhQZ9+SJUsoX748ZmZm2Nra0qVLF/Vp2gALFiygVq1a5MuXj3z58tGwYUMOHz6sU0ZQUBAlS5bE3NxczXPo0KFXxjlnzhwcHR0xMTGhatWqHDly5JXHCPGhk46FENm4c+cO33//PQ4ODhgbG2NjY4Onpyf79+8H0p+c2rhx4yyP3bVrV5YfYq+SXQdl5syZWT5QSQghcpvdu3fTq1cvDh48SFRUFCkpKQQFBfHkyZNMeUNDQ9FoNC8tr2vXrpQrVy5T+v79++nYsSNdu3blr7/+4tdff+Xw4cN0795dzbNr1y7atWvHzp07iY6Oxt7eni+++EKno+Pq6srs2bM5deoU+/btw9HRkS+++II7d+5k26bly5fTv39/Ro8ezR9//EH58uXx9vZ+488MIT40stysENlo2bIlycnJ/PTTTxQvXpxbt26xfft29WqWjY3Nf9YWKyur/6wuIYTISVu2bNHZ/vHHHylSpAh//PEH9evXV9NPnDjBtGnTOHr0KLa2tlmWFRYWxsOHDwkMDGTz5s06+6Kjo3F0dKRPnz4AODk58e233zJ58mQ1z5IlSzK1ZdWqVWzfvp2OHTsC8PXXX+vkmT59OgsXLuTPP/+kQYMGWbZr+vTpdO/eXV2mfN68eWzcuJHt27dnKk+Ij4mMWAiRhYcPH7J3714mT55MvXr1KFasGB4eHgwbNowvv/wSINuh96tXr1KvXj0A8uXLh0ajwc/PD0j/wKxZsyZ58+bF2tqapk2bcunSJfVYJycnANzd3dFoNNStWxfIPBUqKSmJPn36UKhQIUxMTKhZs6bOMHrGiMn27dupXLkyZmZmVK9enZiYmHd4loQQ4v2Lj48H0t9PMyQmJvL1118zZ86cbC/ynDlzhrFjx7J48eIsH1parVo1rl+/zqZNm1AUhVu3brFy5UqaNGmSbVsSExPRarXkz58/y/3JycnMnz8fKysrypcvn22eY8eO0bBhQzVNT0+P+vXry3u0+OjJiIUQWciTJw958uRh7dq1fP755xgbG7/2sfb29qxatYqWLVsSExODpaUlpqamADx58oT+/ftTrlw5Hj9+TGBgIC1atODEiRPo6elx+PBhPDw82LZtG5999hlGRkZZ1jF48GBWrVrFTz/9RLFixZgyZQqenp5cvHhR5wNvxIgRTJs2jYIFC/Ldd9/RpUsXdSrXi5KSkkhKSlK3ExISAKg9eRsphuavHf/HxlhPYVxlqDR2C0lpL59S8TGTOHOf3Bjr6SBPne20tDT69+9PqVKlcHNzQ6vVAtC3b18+//xzmjRpoqalpKSovyclJdG2bVuCg4OxtbXl/PnzAGi1WjWPh4cHP/30E76+vjx79oyUlBS8vb0JDQ1V87xo0KBB2NnZUadOHZ08GzdupEOHDiQmJmJra8vmzZuxsrLKspybN2+SmpqKtbW1zv4CBQpw6NChbOvOLTLikzjff905QToWQmTBwMCAiIgIunfvzrx586hYsSJ16tShbdu2Wc7VfZ6+vr765b5QoULkzZtX3deyZUudvIsWLaJgwYKcOXOGMmXKULBgQQCsra2zvQr35MkTwsLCiIiIUO/xWLBgAVFRUSxcuJBBgwapeSdMmECdOnUAGDp0KN7e3jx79gwTE5NM5QYHBzNmzJhM6SPd0zAzS31pzLnBuMppOd2E/4TEmfvkplg3bdqksz1v3jyOHTtGcHAwUVFRABw+fJiNGzcyffp0nfzHjh3D0NAQSH9vtbKyIl++fGzatIlTp04B8Pvvv5MnTx4Arl+/TmBgIC1btsTd3Z0HDx4QERHBl19+Se/evTO1bdWqVaxZs4bx48ezY8cOnX1JSUmEhISQkJDA77//jo+PD1OmTNF5/89w//59AA4cOKD+Dumj3YAaZ24ncb4/iYmJ/3mdGaRjIUQ2WrZsibe3N3v37uXgwYNs3ryZKVOm8OOPP6pTm97UhQsXCAwM5NChQ9y9e5e0tPQvBLGxsZQpU+a1yrh06RJarZYaNWqoaYaGhnh4eHD27FmdvM93gjLmIN++fRsHB4dM5Q4bNoz+/fur2wkJCdjb2zP+uB4phvqvH+RHJv2qbxqjjurlmqu+WZE4c5/cGOvzIxZ9+/bl9OnT7Nq1iwsXLtCoUSMMDQ3Zvn07cXFxdOjQQefYKVOmULNmTbZt20ZgYCCnT59WL+YoigJAp06dGDp0KKNHj8bPz4969eqxYMECtYy6detSr149Fi1apHPfxvTp01m/fj1RUVFUqlTppTH069eP0qVLc/369Szvl0hOTqZ79+44OzvrTLtasWIF+fLlU+PMrbRaLVFRURLne5Qx4yAnSMdCiJcwMTGhUaNGNGrUiFGjRtGtWzf1A+nfaNasGcWKFWPBggXY2dmRlpZGmTJlSE5OfrcN//+efzPLWDklozPzImNj4yynfO0Z0hBra+v30r4PgVarZdOmTRwL9Mr1H3ISZ+6SW2NVFIXevXuzbt06du3ahaOjIxcuXMDQ0BBDQ0OGDx9Ojx49dI4pW7YsM2bMoFmzZhgaGrJ69WqePn2q7j9y5AhdunRh7969ODs7Y2hoyLNnzzAwMNA5dxnvgc+nT5kyhYkTJ7J161Y+//zz14ohLS2NlJSULF8XQ0NDKlWqxO7du2nVqpWaf/fu3dSvX1+NM7eTON9vnTlFOhZCvIHSpUtnu1b68zLujUhN/b8pRPfu3SMmJkZdFx1g3759rzzuRc7OzhgZGbF//36KFSsGpH/BOHLkCAEBAW8SjhBCfHB69epFZGQk69atw8LCgri4OB48eMDTp08xNDTExsYmy6miDg4O6gIYzs7OOvvu3r0LQKlSpdTpSc2aNaN79+6EhYXh6enJzZs3CQgIwMPDAzs7OwAmT55MYGAgkZGRODo6EhcXB/zffXhPnjxhwoQJfPnll9ja2nL37l3mzJnDjRs3aN26tVp/gwYNaNGiBf7+/gD079+fTp06UblyZTw8PAgNDeXJkyfZriIlxMdCOhZCZOHevXu0bt2aLl26UK5cOSwsLDh69ChTpkyhefPmrzy+WLFiaDQafvvtN5o0aYKpqSn58uXD2tqa+fPnY2trS2xsLEOHDtU5rlChQpiamrJlyxaKFi2KiYlJpqVmzc3N+f777xk0aBD58+fHwcGBKVOmkJiYSNeuXd/peRBCiP9aWFgYgLoqXobU1NR3+h7n5+fHo0ePmD17NgMGDCBv3rzUr19fZ7nZsLAwkpOT1ZGFDKNHjyYoKAh9fX3OnTvHTz/9xN27d7G2tqZKlSrs3buXzz77TM1/6dIltXMD4Ovry507dwgMDCQuLo4KFSrw22+/6eQR4mMkHQshspAnTx6qVq3KjBkz1Hsa7O3t6d69O8OHD3/l8UWKFGHMmDEMHTqUzp0707FjRyIiIli2bBl9+vShTJkyuLm5MWvWLJ0PTwMDA2bNmsXYsWMJDAykVq1a7Nq1K1P5kyZNIi0tjW+++YZHjx5RuXJltm7dqrMcoxBCfIwy7ofIkDHl62XLwL54zIvq1q2bZZ7evXtneaN2howbqrNjYmLC6tWrX5onu3L8/f3VEQz4vziF+JhJx0KILBgbGxMcHExwcHC2eZ7/kHJ0dMz0oTVq1ChGjRqlk9awYUPOnDmTbTkA3bp1o1u3bjppLz5128TEhFmzZjFr1qws25bVh2iFChVe+eErhBBCCPFvyQPyhBBCCCGEEG9NOhZCCCGEEEKItyYdCyGEEEIIIcRbk46FEEIIIYQQ4q1Jx0IIIYQQQgjx1qRjIYQQQogPQnBwMFWqVMHCwoJChQrh4+NDTExMlnkVRaFx48ZoNJpsH1x67949ihYtikaj4eHDhzr7kpKSGDFiBMWKFcPY2BhHR0cWLVqkk+fhw4f06tULW1tbjI2NcXV11VkSds+ePTRr1gw7O7uXtuNFu3btomLFihgbG1OiRIlMK/8J8bGSjoXIlp+fHz4+Pu+svIiICPWJpznF0dGR0NDQHG1Ddj6E8yOEEDlp9+7d9OrVi4MHDxIVFYVWq8Xb25tnz55lyhsaGopGo3lpeV27dqVcuXJZ7mvTpg3bt29n4cKFxMTEsHTpUtzc3NT9ycnJNGrUiKtXr7Jy5UpiYmJYsGABRYoUUfM8efKE8uXLM2fOnNeO8cqVK3h7e1OvXj1OnDhBQEAA3bp14/fff3/tMoT4UMlzLHKJ6OhoatasiZeXFxs3bnwnZc6cOfO9PvcgKCiItWvXcuLEifdWx6s4Ojpy7do1AMzMzHBzc2PYsGG0bt36vdcbEBBAQECAmubr6/vSB0AJIURut2XLFp3tiIgIChUqxKVLl3TST5w4wbRp0zh69Ci2trZZlhUWFsbDhw8JDAxk8+bNmerZvXs3ly9fJn/+/ED6+/LzFi1axP379zlw4ACGhoZZ5mncuDGNGzd+oxjnzZuHk5MT06ZNA6BUqVLs27ePWbNm0bNnzzcqS4gPjYxY5BILFy6kd+/e7Nmzh3/++eetykpNTSUtLQ0rK6uP4gq6oiikpKT86+PHjh3LzZs3OX78OFWqVMHX15cDBw5kmTc5Oflf1/MqpqamFCpU6L2VL4QQH5v4+HgA8uTJo6YlJiby9ddfM2fOHGxsbLI87syZM4wdO5bFixejp5f5q8769eupXLkyU6ZMoUiRIri6ujJw4ECePn2qk6datWr06tWLwoULU6ZMGSZOnEhqaupbxRQdHU3Dhg110jw9PTl48OBblSvEh0BGLHKBx48fs3z5co4ePUpcXBwREREMHz5c3b9+/XoGDBjA9evXqVatGn5+fvj5+fHgwQPy5s1LREQEAQEBLF68mKFDh3L+/HkuXrxIUFAQDx8+VOeMpqWlERISwvz587l+/TqFCxfm22+/ZcSIEezatYt69eqpZUL6FSV3d3euXLmS6SpPREQEY8aMAVCHssPDw6lbty5OTk4cP36cChUqAOlzXPPly8fOnTupW7euWtemTZsYOXIkp06d4vfff8fe3p7+/ftz8OBBnjx5QqlSpQgODs70Bv4iCwsLbGxssLGxYc6cOfzyyy9s2LCB6tWr4+joSNeuXblw4QJr167lq6++IiIigiFDhrBmzRr+/vtvbGxsaN++PYGBgepVLYANGzYwduxYTp06RZ48eahVqxZr1qyhbt26XLt2jX79+tGvXz8gvXOU8To8Pw84uzLg/+YHL126lIcPH1KmTBkmT55M3bp1Abh27Rr+/v7s27eP5ORkHB0dmTp16huPilQN3k6KgfkbHfMxMdZXmOIBZYK2kpT68mkVHzOJM/fJbbFeneSts52WlkZAQADVq1enWLFianq/fv2oXr06zZs3z7KcpKQk2rVrx9SpU3FwcODy5cuZ8ly+fJl9+/ZhYmLCmjVruHv3Lj179uTevXuEh4ereXbs2EH79u3ZtGkTFy9epGfPnmi1WkaPHv2v44yLi6Nw4cI6aYULFyYhIYGkpKR/Xa4QHwLpWOQCK1asoGTJkri5udGhQwcCAgIYNmwYGo2GK1eu0KpVK/r27Uu3bt04fvw4AwcOzFRGYmIikydP5scff8Ta2jrLK+fDhg1jwYIFzJgxg5o1a3Lz5k3OnTv3r9rs6+vL6dOn2bJlC9u2bQPAysqKW7duvXYZQ4cOJSQkhOLFi5MvXz6uX79OkyZNmDBhAsbGxixevJhmzZoRExODg4PDa5VpYGCAoaGhzshESEgIgYGBOh8kFhYWREREYGdnx6lTp+jevTsWFhYMHjwYgI0bN9KiRQtGjBjB4sWLSU5OVm/4W716NeXLl6dHjx50794927a8rAwAf39/zpw5w7Jly7Czs2PNmjV4eXlx6tQpXFxc6NWrF8nJyezZswdzc3POnDmjc9XvRUlJSTofagkJCQAY6yno67+/KXE5zVhP0fk3t5I4c5/cFqtWq9XZ9vf35/Tp00RFRXHmzBm0Wi0bNmxgx44dHD58WCd/SkqKuj1kyBDc3Nzw9fVFq9WqI9parVbNk5qaikajISIiAisrKwCmTJlC27ZtmTlzJqampqSmplKoUCHmzJmDvr4+5cqVIzY2lunTp+tcvHve8+3IjqIopKamZmp/ducht8mIT+J8/3XnBOlY5AILFy6kQ4cOAHh5eREfH8/u3bupW7cuP/zwA25ubkydOhUANzc3Tp8+zYQJE3TK0Gq1zJ07l/Lly2dZx6NHj5g5cyazZ8+mU6dOADg7O1OzZs1/1WZTU1Py5MmDgYFBtkPZrzJ27FgaNWqkbufPn1+n/ePGjWPNmjWsX78ef3//V5aXnJzMtGnTiI+Pp379+mp6/fr1GTBggE7ekSNHqr87OjoycOBAli1bpnYsJkyYQNu2bdVRGUBtW/78+dHX11dHSrLzsjJiY2MJDw8nNjYWOzs7AAYOHMiWLVsIDw9n4sSJxMbG0rJlS8qWLQtA8eLFXxp/cHCwTl1qrO5pmJm93dD/x2Bc5bScbsJ/QuLMfXJLrM9fOJk/fz6HDh1i4sSJnDlzBoCoqCjCw8O5dOkSBQoU0DnW19eXUqVKMWHCBNatW0dsbCyrVq3SyWNjY0Pr1q1p164dqamp5M2bl/3796v7b9++jaIoLFmyBDs7O4yNjTEzM2Pr1q1qnkePHhEXF8e6det0RqgzHDt2LMv05xkZGXHo0CGdeLdv346ZmRnGxsZERUW9xtn6+Emc709iYuJ/XmcG6Vh85GJiYjh8+LA6PcbAwABfX18WLlxI3bp1iYmJoUqVKjrHeHh4ZCrHyMgo25UzAM6ePUtSUhINGjR4twG8hcqVK+tsP378mKCgIDZu3MjNmzdJSUnh6dOnxMbGvrScIUOGMHLkSJ49e0aePHmYNGkS3t7/NyT/Yj0Ay5cvZ9asWVy6dInHjx+TkpKCpaWluv/EiRMvHY14HS8r49SpU6SmpuLq6qqTnpSUhLW1NQB9+vTh+++/5/fff6dhw4a0bNnypa/xsGHD6N+/v7qdkJCAvb0944/rkWKo/1axfMiM9RTGVU5j1FE9ktI+/ukk2ZE4c5/cFuvpIE8URSEgIIATJ06wZ88eXFxc0Gq1REVF0ahRIypWrMjdu3d1jqtYsSIhISF4e3vj5OSEm5ubzr0Sx44do3v37uzatYvixYtTqFAh/vnnHwYMGEDt2rXVkdz169ejp6dH+/btMTU15cCBAyxfvhwvLy/1Po1Lly5ha2ub7TSsSpUqvXK66d69e9myZYtOvqVLl1K9enUAGjVq9MrOycfs+ddT4nw/MmYc5ATpWHzkFi5cSEpKinrVGtKHWY2NjZk9e/Zrl2NqavrSZftMTU1fenzGm+7zq0j9m6G4NynH3Fx33v/AgQOJiooiJCSEEiVKYGpqSqtWrV55w/WgQYPw8/MjT548FC5cONN5eLGe6Oho2rdvz5gxY/D09MTKyoply5apK3zAq8/X63hZGY8fP0ZfX59jx46hr6/7pT/jQ7Jbt254enqyceNGfv/9d4KDg5k2bRq9e/fOskxjY2OMjY0zpe8Z0lDtrORGWq2WTZs2cSzQK9d/yEmcuUtujLVnz55ERkaybt068ufPz71799BqtSQlJWFoaIi9vT329vaZjnNyclIvtJQsWVJnX8YN4GXLllXvAfzmm2+YOHEiPXr0YMyYMdy9e5dhw4bRpUsX9SKRv78/YWFhDBw4kN69e3PhwgUmT55Mnz591PP9+PFjLl68qNZ1/fp1/vrrL/Lnz69OwR02bBg3btxg8eLFAPTq1YuwsDBGjBhBly5d2LFjBytXrmTdunWkpKRgaGiYa17Pl5E432+dOUVWhfqIpaSksHjxYqZNm8aJEyfUn5MnT2JnZ6euyX306FGd444cOfLGdbm4uGBqasr27duz3F+wYEEAbt68qaa9ahlZIyOjTKtr/JtyMuzfvx8/Pz9atGhB2bJlsbGx4erVq688rkCBApQoUQIbG5tXrokOcODAAYoVK8aIESOoXLkyLi4u6pK1GcqVK5ftuYKsY3/Ry8pwd3cnNTWV27dvU6JECZ2f56dX2dvb891337F69WoGDBjAggULXhmfEELklLCwMOLj46lbty62trbY2tri4ODAvn373mk9efLkISoqiocPH1K5cmXat29Ps2bNmDVrlprH3t6erVu3cuTIEcqVK0efPn3o27cvQ4cOVfMcPXoUd3d33N3dAejfvz/u7u4EBgaqeW7evKkzcu7k5MTGjRuJioqifPnyTJs2jR9//JEvvvjincYoRE6QEYuP2G+//caDBw/o2rWrevNZhpYtW7Jw4UJWrFjB9OnTGTJkCF27duXEiRPqEz5f50t0BhMTE4YMGcLgwYMxMjKiRo0a3Llzh7/++ouuXbtSokQJ7O3tCQoKYsKECZw/f17nCn5WHB0duXLlCidOnKBo0aJYWFhgamrK559/zqRJk3BycuL27ds69zO8jIuLC6tXr6ZZs2ZoNBpGjRpFWtq7n3vs4uJCbGwsy5Yto0qVKmzcuFGdipZh9OjRNGjQAGdnZ9q2bUtKSgqbNm1iyJAhaux79uyhbdu2GBsbZ5ov/KoyXF1dad++PR07dmTatGm4u7tz584dtm/fTrly5fD29iYgIIDGjRvj6urKgwcP2LlzJ6VKlXrn50MIId6VrJ6dlDEy8ybHPK9u3bpZ5ilZsuQr579Xq1btpcvAZlf287J6qnbdunU5fvy4Tlpuv5lZfBpkxOIjtnDhQho2bJipUwHpHYujR4/y6NEjVq5cyerVqylXrpw6/ApkOe3lZUaNGsWAAQMIDAykVKlS+Pr6cvv2bSB92G3p0qWcO3eOcuXKMXnyZMaPH//S8lq2bImXlxf16tWjYMGCLF26FEh/KFFKSgqVKlUiICDgleVkmD59Ovny5aN69eo0a9YMT09PKlas+EYxvo4vv/ySfv364e/vT4UKFThw4ACjRo3SyVO3bl1+/fVX1q9fT4UKFahfvz6HDx9W948dO5arV6/i7OysjtK86FVlhIeH07FjRwYMGICbmxs+Pj4cOXJEHX5PTU2lV69elCpVCi8vL1xdXZk7d+47Px9CCCGEEAAa5X0+Wll8kCZMmMC8efO4fv16TjdFfMASEhKwsrLi7t27n8Q9Fk2aNMnV830lztznU4lV4sxdJM73L+PzOz4+Xmdhmf+CTIX6BMydO5cqVapgbW3N/v37mTp16mstvyqEEEIIIcTrko7FJ+DChQuMHz+e+/fv4+DgwIABAxg2bFhON0sIIYQQQuQi0rH4BMyYMYMZM2bkdDOEEEIIIUQuJjdvCyGEEEIIId6adCyEEEIIIYQQb006FiJHaDQa1q5dC8DVq1fRaDSv/SC8D1VERIT6VFchhBBvLjg4mCpVqmBhYUGhQoXw8fEhJiYmy7yKotC4cWOdz5MX3bt3j6JFi6LRaHj48KHOvqSkJEaMGEGxYsUwNjbG0dGRRYsWZVnOsmXL0Gg0+Pj46KSvXr2aL774Amtr6zf6HPv1118pWbIkJiYmlC1b9qXP6RDiYyIdC/FexMXF0bt3b4oXL46xsTH29vY0a9YsyydJ29vbc/PmTcqUKfNe2/S2HZidO3fSpEkTrK2tMTMzo3Tp0gwYMIAbN26824YKIcQnavfu3fTq1YuDBw8SFRWFVqvF29ubZ8+eZcobGhr6yge9du3alXLlymW5r02bNmzfvp2FCxcSExPD0qVLcXNzy5Tv6tWrDBw4kFq1amXa9+TJE2rWrMnkyZNfM0I4cOAA7dq1o2vXrhw/fhwfHx98fHw4ffr0a5chxIdKbt4W79zVq1epUaMGefPmZerUqZQtW5b/x96dx/WU/Q8cf31KeylRiYlCkS1ZMrKFNtHIvo6asashIbJmzRZlH1uNbRjGNvZQlhDTWMbYi4mvGstQU1Gf6v7+8Oj+fFR2Y8p5Ph49uOeee+553099Pp9zz3KVSiUHDhzA19eXq1evquRXV1enfPnyn6i2b+b7779n6NCheHt78/PPP2NpaUlSUhJr164lNDSU+fPnf+oqCoIgFHv79+9X2Y6MjMTU1JSEhASV9PPnzxMaGsqvv/6Kubl5oWUtW7aMJ0+eMGnSJPbt21fgPEePHiUxMRFjY2MALC0tC5SRm5tL7969mTJlCsePHy/Q6/H1118Dzz/33lR4eDju7u6MHj0agGnTphEVFcWyZcto167dG5cjCP9FosdC+OCGDh2KQqHgzJkzdO7cGRsbG2rVqkVAQACnT58ukP/lnoSYmBgUCgUHDhzA3t4eHR0dWrduzf3799m3bx+2traULl2aXr16kZmZKZezf/9+mjVrhpGREWXLlqV9+/YqH0ZWVlYA2Nvbo1AocHJykvetWrUKW1tbtLW1qVGjhsoTqu/evcuwYcMYNmwYa9aswcnJCUtLS1q0aMGqVauYNGmSSjwHDhzA1tYWfX193N3dSU5OlvedPXsWFxcXypUrh6GhIS1btuS3335TOV6hULBq1So6duyIrq4u1tbW7Nq1SyXPrl27sLa2Rltbm1atWvHDDz8U6Oo/ceIEzZs3R0dHBwsLC4YNG0ZGRsZrXj1BEIT/jtTUVAD09fXltMzMTHr16sWSJUuKvCl1+fJlpk6dytq1a1FTK/hVZ9euXTRs2JA5c+ZQsWJFbGxsGDVqFE+fPlXJN3XqVExNTenXr98Hi+nUqVM4OzurpLm5uRX6+SgIxY3osRA+qL///pv9+/czY8YM9PT0Cux/mzkIwcHBLF68GF1dXbp160a3bt3Q0tJi48aNpKen07FjRxYtWsSYMWOA513SAQEB1K1bl/T0dCZNmkTHjh05f/48ampqnDlzBgcHBw4dOkStWrXQ1NQEYMOGDUyaNInFixdjb2/PuXPnGDBgAHp6enh7e7Nlyxays7MJDAwstJ4vxpSZmcm8efNYt24dampq9OnTh1GjRrFhwwYA/vnnH7y9vVm0aBGSJBEaGoqHhwc3btzAwMBALmfKlCnMmTOHuXPnsmjRInr37s2ff/6JsbExt27dokuXLgwfPpz+/ftz7tw5Ro0apVKnhIQE3N3dmT59OmvWrOHBgwf4+fnh5+dHRETEG78GAI1DDpNTquBrWVJoqUvMcYDawQfIyn31sIriTMRZ8pS0WG/PUr1bn5eXh7+/P46OjlSuXFlOHzFiBI6OjnTo0KHQcrKysujZsydz586lUqVKJCYmFsiTmJjIiRMn0NbWZvv27Tx8+JChQ4fy6NEj+T3yxIkTrF69+oPP/0tJScHMzEwlzczMjL/++uuDnkcQPoUP1rB48uSJmLgqcPPmTSRJokaNGu9d1vTp02natCnwfJxsUFAQCQkJVKlSBYAuXboQHR0tNyw6d+6scvyaNWswMTHh8uXL1K5dGxMTEwDKli2rcpdr8uTJhIaG0qlTJ+B5z8bly5f5/vvv8fb25saNG5QuXbrI7vYXKZVKli9fTtWqVQHw8/Nj6tSp8v7WrVur5F+xYgVGRkYcPXqU9u3by+k+Pj707NkTgJkzZ7Jw4ULOnDmDu7s733//PdWrV2fu3LkAVK9enUuXLjFjxgz5+JCQEHr37o2/vz8A1tbWLFy4kJYtW7Js2TK0tbUL1D0rK4usrCx5Oy0tDQAtNQl1dem1sRdXWmqSyr8llYiz5ClpsSqVSpVtPz8/Ll26RFRUFJcvX0apVPLLL79w5MgRzpw5o5I/JydH3h4zZgzVq1ene/fuKJVKcnJy5PLz8+Tm5qJQKIiMjMTQ0BCAOXPm0KNHD8LDw8nJyeHrr79m2bJlGBoaolQqycvLIy8vr0A9X6z7i+d4lRfrm18fSZIKvQ4lzYvXqiT7lHF+ymv7Tg2L2bNnY2lpSffu3YHnE6B+/vlnypcvz969e7Gzs/uglRSKj/w3xg/hxQl3ZmZm6Orqyo2K/LQzZ87I2zdu3GDSpEnExcXx8OFD8vLyAEhKSipyYnhGRgYJCQn069ePAQMGyOk5OTnyh40kSa+dIJhPV1dXblQAmJubc//+fXn7r7/+YsKECcTExHD//n1yc3PJzMwkKSmpyNj19PQoXbq0XM61a9do1KiRSn4HBweV7QsXLnDx4kW5pyQ/jry8PG7duoWtrW2BuoeEhDBlypQC6RPs89DVzX2T8Iu1aQ3zPnUV/hUizpKnpMT64spIK1asIC4ujpkzZ3L58mUAoqKiiIiIICEhgXLlyqkc2717d2xtbZkxYwY7d+4kKSmJn3/+WSVP+fLl6dq1Kz179iQ3NxcjIyNiY2Pl/ffv30eSJDZs2MCzZ8+4ffu2yipQ+Z9v2traLFmyROVmU35vw4kTJ7h3794r4zQ0NCQmJobSpUvLabGxsXIvf1RU1GuvVUkg4vx4Xhwm/m97p4bF8uXL5S8sUVFRREVFsW/fPn766SdGjx7NwYMHP2glheLD2toahUJRYIL2u9DQ0JD/r1AoVLbz0/IbDwCenp5UrlyZlStXUqFCBfLy8qhduzbZ2dlFniM9PR2AlStX0rhxY5V96urqANjY2JCamkpycvJrey0Kq+OLjS1vb28ePXpEeHi4vMRhkyZNCtTxdbG+Tnp6OoMGDWLYsGEF9lWqVKnQY4KCgggICJC309LSsLCwoFWrVpQtW/aNz13cKJVKoqKicHFxKXDdSxIRZ8lTEmOVJAl/f3/Onz/PsWPHsLa2Vomzfv36PHz4UOWY+vXrM2/ePNq1a4eVlRXVq1dXmSsRHx/PgAEDiImJoUqVKpiamnLv3j1GjhxJixYt5Pkbu3btQk1Njd69exeYhwfPe7fT09MJDQ3FxsZGHk4L/z95u1mzZtSrV++VMTo5OZGSkoKHh4ecNmvWLNq0aQNQol7PwpTE39vCfMo480ccfArv1LBISUnBwsICgN27d9OtWzdcXV2xtLQs8OVM+LwYGxvj5ubGkiVLGDZsWIF5Fh9ryNyjR4+4du0aK1eulJcEPHHihEqe/A+B3Nz/v/tuZmZGhQoVSExMpHfv3oWW3aVLF8aOHcucOXNYsGBBgf1vE1NsbCxLly6VP1Du3LlT4EPydapXr15gzfOzZ8+qbNevX5/Lly9TrVq1Ny5XS0sLLS2tAukaGhol+s0/n4izZPlc4oSSFevQoUPZuHEjO3fuxNjYmEePHqFUKsnKykJDQwMLCwv5+8eLrKyssLGxASgwFDd/AnidOnXk9+qvv/6amTNnMnDgQKZMmcLDhw8JCgri22+/lXsS7O3tVcoxNjZGTU1NJf3vv/8mKSlJ7qVITExEQ0OD8uXLy0Nu+/btS8WKFQkJCQGezxFp2bIlCxcupF27dmzatIn4+HiWLl1KUlJSiXo9X0XE+XHP+am806pQZcqU4c6dO8DzlXjyVzeQJEnlS5vweVqyZAm5ubk4ODjw888/c+PGDa5cucLChQtp0qTJRzlnmTJlKFu2LCtWrODmzZscOXJE5e47gKmpKTo6Ouzfv5+//vpL/rCZMmUKISEhLFy4kOvXr/P7778TEREhLyFrYWHBggULCA8Pp1+/fhw9epQ///yT2NhYBg0axLRp0964ntbW1qxbt44rV64QFxdH79690dHReatYBw0axNWrVxkzZgzXr1/np59+IjIyEkAesjVmzBhOnjyJn58f58+f58aNG+zcuRM/P7+3OpcgCMK/admyZaSmpuLk5IS5uTnm5uZUqlSpwI2i96Wvr09UVBRPnjyhYcOG9O7dG09PTxYuXPhW5ezatQt7e3t5mdgePXpgb2/P8uXL5TxJSUkqqwM6OjqyceNGVqxYgZ2dHVu3bmXHjh0f/VlOgvBveKcei06dOtGrVy+sra159OgRbdu2BeDcuXNvdYdUKJmqVKnCb7/9xowZMxg5ciTJycmYmJjQoEEDli1b9lHOqaamxqZNmxg2bBi1a9emevXqLFy4UKUru1SpUixcuJCpU6cyadIkmjdvTkxMDP3790dXV5e5c+cyevRo9PT0qFOnjjzxGZ7fRbOxsWHevHl07NiRp0+fYmlpSfv27Qs0YF5l9erVDBw4kPr162NhYcHMmTMLrOj0OlZWVmzdupWRI0cSHh5OkyZNGD9+PEOGDJF7HOrWrcvRo0cZP348zZs3R5IkqlatKs+LEgRB+C8qbJ6eUql85ZOpXze3z8nJqdA8NWrUeKvx7/k3cF7k4+ODj4/PK4+LiYkpkNa1a1e6du2qklbSJzMLnweF9A6zbZVKJeHh4dy5cwcfHx+5W3DBggUYGBjQv3//D15RQRCKNmPGDJYvXy73JH4IaWlpGBoa8vDhwxI/x2Lv3r14eHiU6G55EWfJ87nEKuIsWUScH1/+53dqaqrKIgH/hnfqsdDQ0Cj0LuuIESPeu0KCILze0qVLadSoEWXLliU2Npa5c+eKYU6CIAiCIHxS7/zk7XXr1tGsWTMqVKjAn3/+CUBYWBg7d+78YJUTBKFwN27coEOHDtSsWZNp06YxcuRIgoODP3W1BEEQBEH4jL1Tw2LZsmUEBATQtm1bnjx5Ik/YNjIyIiws7EPWTxCEQixYsIB79+7x7Nkzrl+/zsSJEylV6oM971IQBEEQBOGtvVPDYtGiRaxcuZLx48fLa/0DNGzYkN9///2DVU4QBEEQBEEQhOLhnRoWt27dKrC+MzxfBz8jI+O9KyUIgiAIgiAIQvHyTg0LKysrzp8/XyB9//792Nravm+dBEEQBEH4jISEhNCoUSMMDAwwNTXFy8uLa9euFZpXkiTatm2LQqFgx44dcvqFCxfo2bMnFhYW6OjoYGtrS3h4uMqxMTExKBSKAj8pKSkq+f73v//Rp08fypYti46ODnXq1OHXX3+V9//111/4+PhQoUIFdHV1cXd358aNG6+Nc8uWLdSoUQNtbW3q1KnzymV0BaE4eqeGRUBAAL6+vmzevBlJkjhz5gwzZswgKCiIwMDAD11HQfjkIiMjP8oTwwVBEAQ4evQovr6+nD59mqioKJRKJa6uroWOgggLC5MfBvqi+Ph4TE1NWb9+PX/88Qfjx48nKCiIxYsXF8h77do1kpOT5R9TU1N53+PHj2natCkaGhrs27ePy5cvExoaSpkyZYDnDRsvLy8SExPZuXMn586do3Llyjg7O79y1MbJkyfp2bMn/fr149y5c3h5eeHl5cWlS5fe5ZIJwn/SO8327N+/Pzo6OkyYMIHMzEx69epFhQoVCA8Pp0ePHh+6jkIx4uPjww8//FAg3c3Njf3793+CGn0eLC0t8ff3V3monyAIQnHx8udDZGQkpqamxMfH06RJEzn9/PnzhIaG8uuvv2Jubq5yzLfffquyXaVKFU6dOsW2bdsKLMdtampa5M2i2bNnY2FhQUREhJxmZWUl///GjRucPn2aS5cuUatWLeD5ojbly5fnxx9/LPJZXuHh4bi7uzN69GgApk2bRlRUFIsXL1Z5UrcgFGdv3WORk5PD2rVrcXZ25saNG6Snp5OSksLdu3fp16/fx6ijUMy4u7ur3AlKTk7mxx9//Cjnys7O/ijlCoIgCJ9OamoqAMbGxnJa/o3MJUuWUL58+Tcu58Uy8tWrVw9zc3NcXFyIjY1V2bdr1y4aNmxI165dMTU1xd7enpUrV8r7s7KyANDW1pbT1NTU0NLS4sSJE0XW5dSpUzg7O6ukubm5cerUqTeKRRCKg7fusShVqhSDBw/mypUrAOjq6qKrq/vBKyYUX1paWkW+6SsUClauXMmePXs4cOAAFStWJDQ0lK+++krO88cffzBmzBiOHTuGJEnUq1ePyMhIqlatio+PD0+ePKFRo0YsWbIELS0tbt26xe+//87w4cM5deoUurq6dO7cmfnz56Ovrw/A2bNnGTduHOfOnUOpVFKvXj0WLFhA/fr15fM+efKEMWPGsGPHDlJTU6lWrRqzZs2iffv2cp4DBw7g7+/PnTt3aNasGREREfJds/y6OTg4EB4eTlZWFgEBAYwbN46goCBWr16Nrq4u06ZN45tvvpHLvHPnDiNHjuTgwYOoqanRvHlzwsPDsbS0VCm3WbNmhIaGkp2dTY8ePQgLC0NDQwMnJyf+/PNPRowYIT+kUpIk/vzzT/z8/Dhx4gTZ2dlYWloyd+5cPDw83ur1bBxymJxSem91THGipS4xxwFqBx8gK7fg8IqSQsRZ8pSUWG/PaqeynZeXh7+/P02bNqV27doolUoARo0ahaOjIx06dHijck+ePMnmzZvZs2ePnGZubs7y5ctp2LAhWVlZrFq1CicnJ+Li4uTPg8TERHlZ/XHjxnH27FmGDRuGpqYm3t7e1KhRg0qVKhEUFMT333+Pnp4eCxYs4O7duyQnJxdZn5SUFMzMzFTSzMzMCszvEITi7J2GQjk4OMhjCgXhbU2ZMoU5c+Ywd+5cFi1aRO/evfnzzz8xNjbmf//7Hy1atMDJyYkjR45QunRpYmNjycnJkY8/fPgwpUuXJioqCoCMjAzc3Nxo0qQJZ8+e5f79+/Tv3x8/Pz8iIyMB+Oeff/D29mbRokVIkkRoaCgeHh7cuHEDAwMD8vLyaNu2Lf/88w/r16+natWqXL58WWU55czMTObNm8e6detQU1OjT58+jBo1ig0bNsh5jhw5whdffMGxY8eIjY2lX79+nDx5khYtWhAXF8fmzZsZNGgQLi4ufPHFFyiVSrnux48fp1SpUkyfPh13d3cuXryIpqYmANHR0ZibmxMdHc3Nmzfp3r079erVY8CAAWzbtg07OzsGDhzIgAED5Lr4+vqSnZ3NsWPH0NPT4/Lly3JDqzBZWVnynTiAtLQ0ALTUJNTVpfd4xf/btNQklX9LKhFnyVNSYs1vOOTz8/Pj0qVLREdHo1QqUSqVnDlzhujoaM6ePauSPycnp8DxAJcuXaJDhw5MmDCBVq1ayXmqVKlClSpV5HyNGjXi5s2bhIaGyp8XeXl5NGjQgClTpgBQu3ZtLl68yLJly+jVqxcAP/30EwMHDsTY2Bh1dXXatGmDu7s7kiQVWp+i6pv/HLD8OAu7HiWNiPPfO/en8E4Ni6FDhzJy5Eju3r1LgwYN0NNTvZtZt27dD1I5oXjavXt3gS+w48aNY9y4ccDzO/A9e/YEYObMmSxcuJAzZ87g7u7OkiVLMDQ0ZNOmTWhoaABgY2OjUpaenh6rVq2Sv3SvXLmSZ8+esXbtWvl3cfHixXh6ejJ79mzMzMxo3bq1ShkrVqzAyMiIo0eP0r59ew4dOsSZM2e4cuWKfL4XP3zg+R/q8uXLqVq1KvD8w2/q1KkqeYyNjVm4cCFqampUr16dOXPmkJmZKcceFBTErFmzOHHiBD169GDz5s3k5eWxatUqeTJiREQERkZGxMTE4OrqCkCZMmVYvHgx6urq1KhRg3bt2nH48GEGDBggf7AZGBio9BQlJSXRuXNn6tSpU2g8LwsJCZE/SF80wT4PXd3cVx5bEkxrmPepq/CvEHGWPMU91hdXRlqxYgVxcXHMnDmTixcvcvHiRQAuXrxIYmIi5cqVUzm2e/fu2NraMmPGDDntzp07TJgwARcXF+rVq/falZfKli1LfHy8nM/IyAh9fX2V43Jycrhx44ZK2tSpU8nIyCAnJwdDQ0NGjx5NtWrVijyfoaEhMTExlC5dWk6LjY1FV1dX5Zj8m2YlnYjz48nMzPzXz5nvnRoW+RO0hw0bJqcpFAokSUKhUMgtcOHz1KpVK5YtW6aS9uIY1xcbnnp6epQuXZr79+8DzyfmNW/eXG5UFKZOnTpyowLgypUr2NnZqTRwmzZtSl5eHteuXcPMzIy//vqLCRMmEBMTw/3798nNzSUzM5OkpCT5vF988UWBRsyLdHV15UYFPO9Sz693vlq1aqGm9v9Tl8zMzKhdu7a8ra6uTtmyZeXjLly4wM2bNzEwMFAp59mzZyQkJKiU+2Lvibm5+WsfRjls2DCGDBnCwYMHcXZ2pnPnzq9s9AcFBREQECBvp6WlYWFhwfRzauRoqBd5XHGnpSYxrWEeE39VIyuv+A4neR0RZ8lTUmK9FOyGJEn4+/tz/vx5jh07hrW1tbxfqVTy+PFjJk2aRKlS//+1pX79+sybN4927drJk6v/+OMPBg4cSL9+/Zg1a9YbnX/RokXUqFFDHibaunVr7t69qzJs9MiRI9jY2BQ5lPTGjRskJCQQFhaGi4tLoXmcnJxISUlRKWPWrFm4uLjg4eGBUqkkKioKFxeXV34GFncizo8vf8TBp/BODYtbt2596HoIJYienh7VqlUrcv/Lf2AKhYK8vOd33HR0dN6o/Lfl7e3No0ePCA8Pp3LlymhpadGkSRN58vebnLewekuS9No8r4o3PT2dBg0aqAynymdiYvLKcvPLKEr//v1xc3Njz549HDx4kJCQEEJDQ/nuu+8Kza+lpYWWllaB9GNjnClbtuwrz1WcKZVK9u7dS/wk9xL/ISfiLFlKUqxDhw5l48aN7Ny5E2NjYx49egQ8v8uvoaFBmTJlqFevXoE4rays5BtCly5dwtXVFTc3N0aPHi2Xoa6uLr+fhoWFYWVlRa1atXj27BmrVq0iOjqagwcPymWPHDkSR0dH5s6dS7du3Thz5gyrVq1ixYoVcp4tW7ZgYmJCpUqV5Dl+Xl5eKo2Gvn37UrFiRUJCQgAYMWIELVu2ZOHChbRr145NmzYRHx/PypUrVeLS0NAo9q/nmxBxftxzfirv1LAQcyuEj6Vu3br88MMPKJXKN/7DsLW1JTIykoyMDLnRERsbKw9Hyt9eunSp/KZ/584dHj58qHLeu3fvcv369Vf2Wnxo9evXZ/PmzZiamqp0j78tTU3NQnsKLSwsGDx4MIMHDyYoKIiVK1cW2bAQBEH4VPJ7uZ2cnFTSIyIi6N279xuVsXXrVh48eMD69etZv369nF65cmVu374NPF9JcOTIkfzvf/9DV1eXunXrcujQIVq1aiXnb9SoEdu3bycoKIipU6diZWVFWFiYSj2Sk5MJCAjgr7/+wtzcnL59+zJx4kSV+iQlJan0YDs6OrJx40YmTJjAuHHjsLa2ZseOHSq92oJQ3L1Tw2Lt2rWv3N+3b993qoxQMmRlZRVY5aJUqVIFxsYWxs/Pj0WLFtGjRw+CgoIwNDTk9OnTODg4yI2El/Xu3ZvJkyfj7e1NcHAwDx484LvvvuPrr7+WV+CwtrZm3bp1NGzYkLS0NEaPHq3SS9GyZUtatGghryZVrVo1rl69ikKhwN3d/T2uxqv17t2buXPn0qFDB6ZOncoXX3zBn3/+ybZt2wgMDOSLL754o3IsLS05duwYPXr0QEtLi3LlyuHv70/btm2xsbHh8ePHREdHY2tr+9FiEQRBeFcv9/6+qKiJqC8fExwcTHBw8CvPExgY+EYP8m3fvr3KioAvGzZsmMpw8MLExMQUSOvatStdu3Z97fkFobh6p4bF8OHDVbaVSiWZmZloamqiq6srGhafuf379xd4cFH16tW5evXqa48tW7YsR44cYfTo0bRs2RJ1dXXq1atH06ZNizxGV1eXAwcOMHz4cBo1aqSy3Gy+1atXM3DgQOrXr4+FhQUzZ85k1KhRKuX8/PPPjBo1ip49e5KRkSEvN/sx6erqcuzYMcaMGUOnTp34559/qFixIm3atHmrHoypU6cyaNAgqlatSlZWFpIkkZubi6+vL3fv3qV06dK4u7uzYMGCjxiNIAiCIAifM4X0qtsEb+HGjRsMGTKE0aNH4+bm9iGKFAThE0pLS8PQ0JCHDx9+FnMsPDw8SvR4XxFnyfO5xCriLFlEnB9f/ud3amrqew2zfhdv/eTtolhbWzNr1qwCvRmCIAiCIAiCIJR8H6xhAc/H0d+7d+9DFikIgiAIgiAIQjHwTnMsdu3apbItSRLJycksXrz4lWPhBUEQBEEQBEEomd6pYeHl5aWyrVAoMDExoXXr1oSGhn6IegmCIAiCIAiCUIy8U8PidQ/mEgRBEARBEATh8/JOcyymTp1KZmZmgfSnT58yderU966U8Pny8fEp0CP2voKDg6lXr94HLfN9KBQKduzYUeT+27dvo1AoOH/+PPB8LXSFQsGTJ08AiIyMxMjI6KPXUxAE4d8QEhJCo0aNMDAwwNTUFC8vL65du1ZoXkmSaNu2bYH30QsXLtCzZ08sLCzQ0dHB1taW8PDwAsfHxMRQv359tLS0qFatGpGRkW9dl4SEBDp27IiJiQmlS5emW7du/PXXX6+Nc8mSJVhaWqKtrU3jxo05c+bM6y+OIBQz79SwmDJlCunp6QXSMzMzmTJlyntXSnh/KSkpfPfdd1SpUgUtLS0sLCzw9PTk8OHD/8r5nZyc8Pf3f68yPD09i3w43fHjx1EoFFy8ePG9zvFfZGFhQXJycpFPY+3evTvXr1+Xt/9rDSdBEIS3cfToUXx9fTl9+jRRUVEolUpcXV3JyMgokDcsLAyFQlEgPT4+HlNTU9avX88ff/zB+PHjCQoKYvHixXKeW7du0a5dO1q1asX58+fx9/enf//+HDhw4I3rkpGRgaurKwqFgiNHjhAbG0t2djaenp6vHM2xefNmAgICmDx5Mr/99ht2dna4ublx//7997l0gvCf805DoSRJKvQP+8KFCxgbG793pYT3c/v2bZo2bYqRkRFz586lTp06KJVKDhw4gK+v7xs9qO6/oF+/fnTu3Jm7d+8WeAJ1REQEDRs2pG7dup+odqpyc3NRKBSoqb3/Qmvq6uqUL1++yP06OjoqTw0XBEEozvbv36+yHRkZiampKfHx8bRo0UJOP3/+PKGhofz6668FHsL67bffqmxXqVKFU6dOsW3bNvz8/ABYvnw5VlZW8lxQW1tbTpw4wYIFC+Tnb72uLrGxsdy+fZtz587Jzwf44YcfKFOmDEeOHMHZ2bnQGOfPn8+AAQP45ptv5Lrs2bOHNWvWMHbs2Le6XoLwX/ZW34LKlCmDsbExCoUCGxsbjI2N5R9DQ0NcXFzo1q3bx6qr8IaGDh2KQqHgzJkzdO7cGRsbG2rVqkVAQACnT58GICkpiQ4dOqCvr19oV25CQgIdOnTAzMwMfX19GjVqxKFDh1TOs3TpUqytrdHW1sbMzIwuXboAz4czHT16lPDwcBQKBQqFgtu3b5Obm0u/fv2wsrJCR0eH6tWrF9pVna99+/aYmJgU6KpOT09ny5Yt9OvXr9BhQTt27Ci04Zsvf7jVvHnzMDc3p2zZsvj6+qJUKuU8WVlZjBo1iooVK6Knp0fjxo2JiYmR9+efd9euXdSsWRMtLS2SkpI4e/YsLi4ulCtXDkNDQ1q2bMlvv/1WoA7Jycm0bdsWHR0dqlSpwtatW+V9Lw+FetmLMUdGRjJlyhQuXLggX+vIyEi+/fZb2rdvr3KcUqnE1NSU1atXF3ltBEEQPrXU1FQAlRuVWVlZ9O3blyVLlrzyxsvL5bxYxqlTpwp88Xdzc+PUqVNvXJesrCwUCgVaWlpyHm1tbdTU1Dhx4kShZWRnZxMfH69ybjU1NZydnV95bkEojt6qxyIsLAxJkvj222+ZMmUKhoaG8j5NTU0sLS1p0qTJB6+k8Ob+/vtv9u/fz4wZM9DT0yuw38jIiLy8PLlRcfToUXJycvD19aV79+7yl+f09HQ8PDyYMWMGWlparF27Fk9PT65du0alSpX49ddfGTZsGOvWrcPR0ZG///6b48ePAxAeHs7169epXbu2POfGxMSEvLw8vvjiC7Zs2ULZsmU5efIkAwcOxNzcvNAGaalSpejbty+RkZGMHz9ebixs2bKF3Nxcevbsyfbt29/pOkVHR2Nubk50dDQ3b96ke/fu1KtXjwEDBgDg5+fH5cuX2bRpExUqVGD79u24u7vz+++/Y21tDTwf+jd79mxWrVpF2bJlMTU1JTExEW9vbxYtWoQkSYSGhuLh4cGNGzcwMDCQzz9x4kRmzZpFeHg469ato0ePHvz+++/Y2tq+VRzdu3fn0qVL7N+/X274GRoaYmNjQ4sWLUhOTpbv7O3evZvMzEy6d+/+VudoHHKYnFIFf5dKCi11iTkOUDv4AFm5RTdIizsRZ8lTEmK9PaudynZeXh7+/v40bdpUZTjo6tWradKkCR06dHijck+ePMnmzZvZs2ePnJaSkoKZmZlKPjMzM9LS0nj69GmBnuDC6vLll1+ip6fHmDFjmDlzJpIkMXbsWHJzc0lOTi60Lg8fPiQ3N7fQcxeXEQSC8KbeqmHh7e0NgJWVFY6OjiX6UezF1c2bN5EkiRo1ahSZ5/Dhw/z+++/cunULCwsLANauXUutWrU4e/YsjRo1ws7ODjs7O/mYadOmsX37dnbt2oWfnx9JSUno6enRvn17DAwMqFy5Mvb29sDzL7aampro6uqq3FlSV1dXmYNjZWXFqVOn+Omnn4rs6fr222+ZO3cuR48excnJCXg+DKpz584qDdu3VaZMGRYvXoy6ujo1atSgXbt2HD58mAEDBpCUlERERARJSUlUqFABgFGjRrF//34iIiKYOXMm8LwHYOnSpSrXqXXr1irnWbFiBUZGRhw9elSlB6Fr1670798feH5to6KiWLRoEUuXLn2rOHR0dNDX16dUqVIq19rR0ZHq1auzbt06AgMDgefXrWvXrujr6xdaVlZWFllZWfJ2WloaAFpqEurq0lvVqzjRUpNU/i2pRJwlT0mI9cWeYnh+U+fSpUtER0fL+3bs2MHvv//OunXrVPLn5OQUOB7g0qVLdOjQgQkTJtCqVSs5jyRJ5ObmFigjvx6lSql+JSqsLkZGRvz444989913LFy4EDU1Nbp37y5//hVWn/y0l+ubm5uLJEly2sv/llQizn/v3J/CO82xaNmypfz/Z8+ekZ2drbI/f9yh8O+TpNd/wFy5cgULCwu5UQFQs2ZNjIyMuHLlCo0aNSI9PZ3g4GD27NlDcnIyOTk5PH36lKSkJABcXFyoXLkyVapUwd3dHXd3dzp27Iiuru4rz71kyRLWrFlDUlIST58+JTs7+5UTj2vUqIGjoyNr1qzBycmJmzdvcvz48fdefaxWrVqoq6vL2+bm5vz+++8A/P777+Tm5mJjY6NyTFZWFmXLlpW3NTU1C8zx+Ouvv5gwYQIxMTHcv3+f3NxcMjMz5euW7+WevSZNmhQ59Old9e/fnxUrVhAYGMhff/3Fvn37OHLkSJH5Q0JCCl18YYJ9Hrq6uR+0bv9F0xp+HstoizhLnuIc6969e+X/r1ixgri4OGbOnMnFixflxTnWrl1LSkpKgXkV3bt3x9bWlhkzZshpd+7cYcKECbi4uFCvXj2V8jU1NYmLi1NJO3z4MLq6ukRHR6uUXVRd8s2fP5+0tDTU1NTQ19fHx8eHunXrqpSdT6lUoqamxt69e/n777/l9HPnzqFQKAocExUV9drrVhKIOD+ewlZu/be8U8MiMzOTwMBAfvrpJx49elRgf25uyf8S8l9lbW2NQqF47+7VUaNGERUVxbx586hWrRo6Ojp06dJFbkQaGBjw22+/ERMTw8GDB5k0aRLBwcGcPXu2yKVQN23axKhRowgNDaVJkyYYGBgwd+5c4uLiXlmXfv368d1337FkyRIiIiKoWrWq3LhVU1Mr0Jh6k5b6y71tCoVCXtEjPT0ddXV14uPjVRofgMrdfh0dnQJzOby9vXn06BHh4eFUrlwZLS0tmjRpUqDx/W/o27cvY8eO5dSpU5w8eRIrKyuaN29eZP6goCACAgLk7bS0NCwsLGjVqpVKg6qkUSqVREVF4eLiUqJ7YUWcJU9JiVWSJPz9/Tl//jzHjh2Th5vmq1OnDi4uLjRp0kTuVahfvz7z5s2jXbt2WFlZAfDHH38wcOBA+vXrx6xZswqc5/jx4+zfvx8PDw857ccff6RZs2Zy2uvqUpjo6GhSU1MZNWoU1atXLzRPgwYNSEtLk8+Tl5eHr68vQ4YMkdNKyuv5OiLOjy9/xMGn8E4Ni9GjRxMdHc2yZcv4+uuvWbJkCf/73//4/vvvC/1jFv49xsbGuLm5sWTJEoYNG1ZgnsWTJ0+wtbXlzp073LlzR+61uHz5Mk+ePKFmzZoAxMbG4uPjQ8eOHYHnX7Zv376tUlapUqVwdnbG2dmZyZMnY2RkxJEjR+jUqROampoFGpixsbE4OjoydOhQOS0hIeG1MXXr1o3hw4ezceNG1q5dy5AhQ+Qv9CYmJvzzzz9kZGTIsb7vnX97e3tyc3O5f//+K7+IFyY2NpalS5fKHxR37tzh4cOHBfKdPn2avn37qmznd6W/rcKuNUDZsmXx8vIiIiKCU6dOyauRFEVLS0tlQmI+DQ2NEv3mn0/EWbJ8LnFC8Y916NChbNy4kZ07d2JsbCzfsDQ0NERHRwcLCwsqV65MvXr1VOK0srKSe5YvXbqEq6srbm5ujB49Wi5DXV0dExMTAHx9fVm2bBnjx4/n22+/5ciRI2zdupU9e/bI5b6uLvB8WKmtrS0mJiacOnWK4cOHM2LECJU5IW3atKFjx47yilQjR47E29sbBwcHHBwcCAsLIyMjg/79+xd47Yr76/mmRJwf95yfyjs1LH755RfWrl2Lk5MT33zzDc2bN6datWpUrlyZDRs20Lt37w9dT+EtLFmyhKZNm+Lg4MDUqVOpW7cuOTk5REVFsWzZMi5fvkydOnXo3bs3YWFh5OTkMHToUFq2bEnDhg2B5z0f27Ztw9PTE4VCwcSJE1XW6N69ezeJiYm0aNGCMmXKsHfvXvLy8uS7NZaWlsTFxXH79m309fUxNjbG2tqatWvXcuDAAaysrFi3bh1nz56V7zYVRV9fn+7duxMUFERaWho+Pj7yvsaNG6Orq8u4ceMYNmwYcXFxBVaRels2Njb07t2bvn37Ehoair29PQ8ePODw4cPUrVuXdu3aFXmstbU169ato2HDhqSlpTF69OhCl4bdsmULDRs2pFmzZmzYsIEzZ86882pNlpaW3Lp1i/Pnz/PFF19gYGAgNxD69+9P+/btyc3NledICYIg/JcsW7YMQJ5Hly8iIkLl/f5Vtm7dyoMHD1i/fj3r16+X0ytXrizfFLOysmLPnj2MGDGC8PBwvvjiC1atWiUvNfumdbl27RpBQUH8/fffWFpaMn78eEaMGKGSPyEhQeWmUvfu3Xnw4AGTJk0iJSWFevXqsX///gITugWh2JPegZ6envTnn39KkiRJFStWlOLi4iRJkqTExERJT0/vXYoUPrB79+5Jvr6+UuXKlSVNTU2pYsWK0ldffSVFR0dLkiRJf/75p/TVV19Jenp6koGBgdS1a1cpJSVFPv7WrVtSq1atJB0dHcnCwkJavHix1LJlS2n48OGSJEnS8ePHpZYtW0plypSRdHR0pLp160qbN2+Wj7927Zr05ZdfSjo6OhIg3bp1S3r27Jnk4+MjGRoaSkZGRtKQIUOksWPHSnZ2dvJx3t7eUocOHQrEc/LkSQmQPDw8Cuzbvn27VK1aNUlHR0dq3769tGLFCunFX+3Jkye/9hzDhw+XWrZsKW9nZ2dLkyZNkiwtLSUNDQ3J3Nxc6tixo3Tx4kVJkiQpIiJCMjQ0LFCX3377TWrYsKGkra0tWVtbS1u2bJEqV64sLViwQM4DSEuWLJFcXFwkLS0tydLSUuXa3bp1SwKkc+fOSZIkSdHR0RIgPX78uNBzP3v2TOrcubNkZGQkAVJERIS8Ly8vT6pcuXKh1+11UlNTJUB6+PDhWx9bnGRnZ0s7duyQsrOzP3VVPioRZ8nzucQq4ixZRJwfX/7nd2pq6r9+boUkvcFs35fUrVuXRYsW0bJlS5ydnalXrx7z5s1j4cKFzJkzh7t3737Apo8gCO8qPT2dihUrEhERQadOnd7q2LS0NAwNDXn48GGJn2Oxd+9ePDw8SnS3vIiz5PlcYhVxliwizo8v//M7NTX1X19Q6Z0eE/zNN99w4cIFAMaOHcuSJUvQ1tZmxIgRjB49+oNWUBCEt5eXl8f9+/eZNm0aRkZGfPXVV5+6SoIgCIIglHDvNMfixbGEzs7OXL16lfj4eKpVq1Zg+U1BEP59SUlJWFlZ8cUXXxAZGVlgfXZBEARBEIQP7b2/bTx79ozKlStTuXLlD1EfQRA+AEtLyzd6pokgCIIgCMKH8k5DoXJzc5k2bRoVK1ZEX1+fxMREACZOnPjOK9sIgiAIgiAIglB8vVPDYsaMGURGRjJnzhw0NTXl9Nq1a7Nq1aoPVjlBEARBEARBEIqHd2pYrF27lhUrVtC7d2+VJxPb2dm99xOfBUEQBEEQBEEoft6pYfG///2PatWqFUjPy8tDqVS+d6WEks3HxwcvL69PXQ1BEAThEwoJCaFRo0YYGBhgamqKl5cX165dU8kzaNAgatSoQbdu3ahQoQIdOnQocAPz8OHDODo6YmBgQPny5RkzZgw5OTkqeSRJYt68edjY2KClpUXFihWZMWOGvN/HxweFQlHgp1atWirlLFmyBEtLS7S1tWncuDFnzpx5bZxbtmyhRo0aaGtrU6dOHfbu3fu2l0oQio13aljUrFmT48ePF0jfunUr9vb2710p4dN68Q1WQ0MDMzMzXFxcWLNmjcrTt99VeHj4ez8d+2O5cOECX331Faampmhra2NpaUn37t25f//+Bynf0tKSsLCwD1KWIAhCcXb06FF8fX05ffo0UVFRKJVKXF1dycjIkPM0aNCAlStXsmjRIvbs2YMkSbi6upKbmws8f8/28PDA3d2dc+fOsXnzZnbt2sXYsWNVzjV8+HBWrVrFvHnzuHr1Krt27cLBwUHeHx4eTnJysvxz584djI2N6dq1q5xn8+bNBAQEMHnyZH777Tfs7Oxwc3N75efDyZMn6dmzJ/369ePcuXN4eXnh5eXFpUuXPtRlFIT/lnd5qt6OHTskQ0NDadasWZKurq40d+5cqX///pKmpqZ08ODBD/j8PuFT8Pb2ltzd3aXk5GTp7t27Unx8vDRjxgxJX19fatu2raRUKgs9rrg/RfP+/ftS2bJlJW9vb+m3336TEhMTpSNHjkj+/v5SYmLiBznHy0/h/i8TT94uWUScJU9Ji/X+/fsSIB09elQl/cU4L1y4IAHSzZs3JUmSpKCgIKlhw4Yq+Xft2iVpa2tLaWlpkiRJ0uXLl6VSpUpJV69efeO6bN++XVIoFNLt27flNAcHB8nX11fezs3NlSpUqCCFhIQUWU63bt2kdu3aqaQ1btxYGjRoUIG8Je31LIqI8+P7lE/efqsei8TERCRJokOHDvzyyy8cOnQIPT09Jk2axJUrV/jll19wcXH5GO0f4V+mpaVF+fLlqVixIvXr12fcuHHs3LmTffv2yb0NCoWCZcuW8dVXX6Gnp8eMGTPIzc2lX79+WFlZoaOjQ/Xq1QkPD1cp++WhUE5OTgwbNozAwECMjY0pX748wcHBKsfMnz+fOnXqoKenh4WFBUOHDiU9PV0lz8qVK7GwsEBXV5eOHTsyf/58jIyMVPLs3LmT+vXro62tTZUqVZgyZYrcZR4bG0tqaiqrVq3C3t4eKysrWrVqxYIFC7CyskKSJKpVq8a8efNUyjx//jwKhYKbN28iSRLBwcFUqlQJLS0tKlSowLBhw+Q4//zzT0aMGCH3COU7ceIEzZs3R0dHBwsLC4YNG6Zy187S0pLp06fTt29f9PX1qVy5Mrt27eLBgwd06NABfX196taty6+//iof8+eff+Lp6UmZMmXQ09OjVq1aogteEIT/rNTUVACMjY0L3Z+RkUFERARWVlZYWFgAkJWVhba2tko+HR0dnj17Rnx8PAC//PILVapUYffu3VhZWWFpaUn//v35+++/i6zL6tWrcXZ2lpfSz87OJj4+HmdnZzmPmpoazs7OnDp1qshyTp06pXIMgJub2yuPEYTi7K2eY2FtbU1ycjKmpqY0b94cY2Njfv/9d8zMzD5W/YT/kNatW2NnZ8e2bdvo378/AMHBwcyaNYuwsDBKlSpFXl4eX3zxBVu2bKFs2bKcPHmSgQMHYm5uTrdu3Yos+4cffiAgIIC4uDhOnTqFj48PTZs2lRuqampqLFy4ECsrKxITExk6dCiBgYEsXboUeN4oGDx4MLNnz+arr77i0KFDTJw4UeUcx48fp2/fvixcuJDmzZuTkJDAwIEDAZg8eTLly5cnJyeH7du306VLF5Uv/vC8IfXtt98SERHBqFGj5PSIiAhatGhBtWrV2Lp1KwsWLGDTpk3UqlWLlJQU+Sn127Ztw87OjoEDBzJgwAD5+ISEBNzd3Zk+fTpr1qzhwYMH+Pn54efnR0REhJxvwYIFzJw5k4kTJ7JgwQK+/vprHB0d+fbbb5k7dy5jxoyhb9++/PHHHygUCnx9fcnOzubYsWPo6elx+fJl9PX1i3wNsrKyyMrKkrfT0tIAaDH7EDkaekUeV9xpqUlMawgNpu4nK0/x+gOKKRFnyVOcY70U7KaynZeXx/Dhw3F0dKR69eoq8zWXLFlCUFAQz549w8bGhr1796JQKFAqlbRp04awsDDWrVtH165dSUlJYcqUKQDcuXMHpVLJzZs3+fPPP/npp59Ys2YNubm5jBo1is6dO3Pw4MECdbt37x779u1j7dq1cj2Sk5PJzc2lbNmyKnUrV64cV65cKXJ+aUpKSqHHpKSkFDgmf7ukz1UVcf575/4UFJL05k/RUlNTIyUlBVNTUwBKly7N+fPnqVKlykeroPDv8/Hx4cmTJ+zYsaPAvh49enDx4kUuX76MQqHA39+fBQsWvLI8Pz8/UlJS2Lp1a6HlOzk5kZubqzJvx8HBgdatWzNr1qxCy9y6dSuDBw/m4cOHcr3S09PZvXu3nKdPnz7s3r2bJ0+eAM+fEt+mTRuCgoLkPOvXrycwMJB79+4BMH78eObMmUPp0qXlOvTt21duPN+7d49KlSpx8uRJHBwcUCqVVKhQgXnz5uHt7c38+fP5/vvvuXTpEhoaGgXqbWlpib+/P/7+/nJa//79UVdX5/vvv5fTTpw4QcuWLcnIyJDnejRv3px169YBzz+szM3NmThxIlOnTgXg9OnTNGnShOTkZMqXL0/dunXp3LkzkydPfuXrky84OFj+QH7Rxo0b0dXVfaMyBEEQ3sXy5cuJj48nJCSEcuXKqezLyMggNTWVx48fs2PHDh49esSsWbPk5e537tzJ5s2befbsGRoaGnTr1o1169YxatQomjVrxpIlS4iKimLJkiVUrFgReH5DZ+TIkSpp+bZu3crOnTtZs2aN/D7+999/8+233zJr1ixq1Kgh542MjOSPP/5g7ty5hcbVpUsXhg0bRosWLeS0vXv3snnzZn744Yf3v3CCUIjMzEx69epFamoqpUuX/lfP/V5P3n6LNolQQkiSpHInv2HDhgXyLFmyhDVr1pCUlMTTp0/Jzs6mXr16ryy3bt26Ktvm5uYqE+IOHTpESEgIV69eJS0tjZycHJ49e0ZmZia6urpcu3aNjh07qpTh4OCg0tC4cOECsbGxKiuB5ObmqpQzY8YMAgICOHLkCHFxcSxfvpyZM2dy7Ngx6tSpQ4UKFWjXrh1r1qzBwcGBX375haysLHmCX9euXQkLC6NKlSq4u7vj4eGBp6cnpUoV/ad24cIFLl68yIYNG1Suc15eHrdu3cLW1rbANcpv6NSpU6dA2v379ylfvjzDhg1jyJAhHDx4EGdnZzp37lzgOr8oKCiIgIAAeTstLQ0LCwumn1MjR0O9yOOKu+d3ffOY+Ktasbvr+zZEnCVPcY71xR6L4cOHc+nSJU6cOIGVlVWBvEqlkqioKLy9vRk+fDimpqY8e/ZMHlLr4eHB8uXLSU5OpkyZMty+fZt169bRqVMnGjZsyNmzZ4mOjlbpKX769CkjR47EyspKZaiSJEmMGjWKb775hg4dOsjp2dnZDBgwgKpVq+Lh4SGnb926lerVq6ukvcjc3JwKFSqo7D979iyVKlUqcEx+nC4uLoXemCopRJwfX/6Ig0/hrRoWL48Lz08TPh9XrlxReePX01MdIrNp0yZGjRpFaGgoTZo0wcDAgLlz5xIXF/fKcl/+o1MoFPIKVLdv36Z9+/YMGTKEGTNmYGxszIkTJ+jXrx/Z2dlvfDc9PT2dKVOm0KlTpwL7XhyjW7ZsWbp27UrXrl2ZOXMm9vb2zJs3T7671L9/f77++msWLFhAREQE3bt3l+tgYWHBtWvXOHToEFFRUQwdOpS5c+dy9OjRIt9Y0tPTGTRokDwX40WVKlUq9Brl/90VlpZ/3fr374+bmxt79uzh4MGDhISEEBoaynfffVdoPbS0tNDS0iqQfmyMM2XLli30mJJAqVSyd+9e4ie5l/gPORFnyVLcY5Ukie+++46dO3cSExODtbX1K/NraGiQl5eHJEnk5uYWiDl/PsTWrVuxsLDAwcEBdXV1WrRowYwZM0hKSqJq1aoAXL58GYCqVauqlBMTE8PNmzcZMGCASrqGhgYNGjTg6NGjdOnSBXj+XhsdHY2fn1+R179JkybExMQwcuRIOe3IkSM4OjoWeYyGhkaxfD3flojz457zU3mrhoUkSfj4+MhfPp49e8bgwYMLfLnctm3bh6uh8J9x5MgRfv/9d0aMGFFkntjYWBwdHRk6dKiclpCQ8F7njY+PJy8vj9DQUNTUnq838NNPP6nkqV69OmfPnlVJe3m7fv36XLt2rdBnsBRFU1OTqlWrqkyk9vDwQE9Pj2XLlrF//36OHTumcoyOjg6enp54enri6+tLjRo1+P3336lfvz6ampryMokv1uvy5ctvVa83ZWFhweDBgxk8eDBBQUGsXLmyyIaFIAjCv8nX15eNGzeyc+dODAwMSElJAcDQ0BAdHR0SExPZvHkzrVu35sGDB5w6dYp58+aho6Ojcrd/7ty5uLu7o6amxrZt25g1axY//fST/ABfZ2dn6tevz7fffktYWBh5eXn4+vri4uKCjY2NSp1Wr15N48aNqV27doH6BgQE4O3tTcOGDXFwcCAsLIyMjAy++eYbOU/fvn2pWLEiISEhwPPemJYtWxIaGkq7du3YtGkTv/76KytWrPjg11MQ/gveqmHh7e2tst2nT58PWhnhvyMrK4uUlBRyc3P566+/2L9/PyEhIbRv356+ffsWeZy1tTVr167lwIEDWFlZsW7dOs6ePVto9/abqlatGkqlkkWLFuHp6UlsbCzLly9XyfPdd9/RokUL5s+fj6enJ0eOHGHfvn0qPWqTJk2iffv2VKpUiS5duqCmpsaFCxe4dOkS06dPZ/fu3WzatIkePXpgY2ODJEn88ssv7N27V2UStbq6Oj4+PgQFBWFtbU2TJk3kfZGRkeTm5tK4cWN0dXVZv349Ojo68p00S0tLjh07Ro8ePdDS0qJcuXKMGTOGL7/8Ej8/P/r37y9PtI6KimLx4sXvfN38/f1p27YtNjY2PH78mOjoaHlYlSAIwqe2bNky4Pk8uxdFRETg4+ODtrY2x48fJywsjL///pvy5cvTokULTp48Kc/1BNi3bx8zZswgKysLOzs7du7cSdu2beX9ampq/PLLL/LnhJ6eHm3btiU0NFTlvKmpqfz8888FVjLM1717dx48eMCkSZNISUmhXr167N+/X2UBm6SkJPkGGICjoyMbN25kwoQJjBs3Dmtra3bs2FFow0UQSoR/fYFb4T/P29tbAiRAKlWqlGRiYiI5OztLa9askXJzc+V8gLR9+3aVY589eyb5+PhIhoaGkpGRkTRkyBBp7Nixkp2dnUr5HTp0kLdbtmwpDR8+XKWcDh06SN7e3vL2/PnzJXNzc0lHR0dyc3OT1q5dKwHS48eP5TwrVqyQKlasKOno6EheXl7S9OnTpfLly6uUu3//fsnR0VHS0dGRSpcuLTk4OEgrVqyQJEmSEhISpAEDBkg2NjaSjo6OZGRkJDVq1EiKiIgocI0SEhIkQJozZ45K+vbt26XGjRtLpUuXlvT09KQvv/xSOnTokLz/1KlTUt26dSUtLS3pxT+/M2fOSC4uLpK+vr6kp6cn1a1bV5oxY4a8v7DnX7x8/W/duiUB0rlz5yRJkiQ/Pz+patWqkpaWlmRiYiJ9/fXXb/VMCvEci5JFxFnyfC6xijhLFhHnx/cpn2PxVqtCCUJxMmDAAK5evVroU+Lf1/Hjx2nTpg137twpscstp6WlYWhoyMOHDz+LORYeHh4leryviLPk+VxiFXGWLCLOjy//87vYrQolCP8l8+bNw8XFBT09Pfbt28cPP/wgP+fiQ8nKyuLBgwcEBwfTtWvXEtuoEARBEARBeFtv9eRtQfgvO3PmDC4uLtSpU4fly5ezcOFC+UF+H8qPP/5I5cqVefLkCXPmzPmgZQuCIAiCIBRnosdCKDFeXinqY/Dx8cHHx+ejn0cQBEEQBKG4ET0WgiAIgiAIgiC8N9GwEARBEARBEAThvYmGhSAIgiAI/5qQkBAaNWqEgYEBpqameHl5ce3aNZU8gwYNomrVqujo6FChQgVmzpzJ1atX5f2RkZEoFIpCf+7fvy/n27BhA3Z2dujq6mJubs63337Lo0eP5P0rV66kefPmlClThjJlyuDs7MyZM2dU6hIcHEyNGjXQ09OT88TFxb02ziVLlmBpaYm2tjaNGzcuUK4glEQlrmGxYsUKLCwsUFNTIywsrMi0j8HS0vKjlv8qwcHB1KtX75OcW3gzkZGRGBkZfepqCIIgfFJHjx7F19eX06dPExUVhVKpxNXVlYyMDDlPgwYNiIiI4MqVK+zZswdJkmjXrh25ubnA84fVJScnq/y4ubnRsmVL+eF5sbGx9O3bl379+vHHH3+wZcsWzpw5w4ABA+TzxMTE0LNnT6Kjozl16hQWFha4urryv//9T85jY2PD4sWL+f333zlx4gSWlpa4urry4MGDImPcvHkzAQEBTJ48md9++w07Ozvc3NxUGj2CUCL960/OeMHLD0p7X6mpqZKGhoa0aNEi6d69e1JGRkahae8rIiJCMjQ0LJB+//79D1J+vvwHnuX/6OvrSzVr1pSGDh0qXb9+XSXvP//88689yKywB9q9j8qVK8sx6urqSvb29tJPP/30wcr/ryjq9+a/Sjwgr2QRcZY8JSXW+/fvS4B09OjRQvdnZ2dLYWFhEiDdvHmzyDI0NDSktWvXymlz586VqlSpopJv4cKFUsWKFYusS05OjmRgYCD98MMPRebJf2988eGnL3NwcJB8fX3l7dzcXKlChQpSSEhIkceUlNfzdUScH9+nfEBeieqxSEpKQqlU0q5dO8zNzdHV1S007WMxMTH5KOUfOnSI5ORkLly4wMyZM7ly5Qp2dnYcPnxYzqOvr1/sHmKWnZ0t/3/q1KkkJydz7tw5GjVqRPfu3Tl58uRrj/u35ebmkpeX98nOLwiCUNKkpqYCYGxsXOj+jIwMDh8+jJWVFRYWFoXmWbt2Lbq6unTp0kVOa9KkCXfu3GHv3r1IksRff/3F1q1b8fDwKLIumZmZKJXKIuuSnZ3NihUrMDQ0xM7Orsg88fHxODs7y2lqamo4Oztz6tSpIs8tCCXBf2a5WScnJ+rWrYu2tjarVq1CU1OTwYMHExwcLOd58uQJo0aNYufOnWRlZdGwYUMWLFiAnZ0dkZGRfPPNNwBUqVIFgIiIiAJpt27dwtLSkp07dzJlyhQuX75MhQoV8Pb2Zvz48ZQqVUo+15gxY9ixYwepqalUq1aNWbNmoa+vL5epUCgAmDx5MsHBwVhaWuLv74+/vz+9evUiNzeXzZs3y/VXKpWYm5szf/58+vbtS15eHrNnz2bFihWkpKRgY2PDxIkTVd4YAcqWLUv58uXlODw9PWnTpg39+vUjISEBdXV1goOD2bFjB+fPnweed+8GBgbyxx9/oKGhQa1atdi4cSOVK1cmISGBgIAATp8+TUZGBra2toSEhKi8CS5dupQFCxZw584dDA0Nad68OVu3bsXHx4ejR49y9OhRwsPDVa7ppUuXGD16NMePH0dPTw9XV1cWLFhAuXLl5Ne4du3alCpVivXr11OnTh2io6MBMDAwoHz58pQvX54lS5awfv16fvnlFxwdHbG0tKRfv37cuHGDHTt20KlTJyIjIzlx4gRBQUH8+uuvlCtXjo4dOxISEoKenh6AfNzly5fZtWsXRkZGjBs3Dl9fXznO+fPnExERQWJiIsbGxnh6ejJnzhz09fWB58OX/P39Wbt2LWPHjuX69evcvHkTc3Nzxo8fz48//siTJ0+oXbs2s2fPxsnJSS47MjKSSZMm8fDhQ9zc3GjWrJnK65r/mo0cOZKJEyfy+PFj2rZty8qVKzEwMAB47e/I48eP8fPz4+DBg6Snp/PFF18wbtw4vvnmG7KzswkICODnn3/m8ePHmJmZMXjwYIKCggr/IyxC45DD5JTSe6tjihMtdYk5DlA7+ABZuYpPXZ2PRsRZ8hTHWG/PaqeynZeXh7+/P02bNqV27doq+5YuXUpgYCAZGRlUrFiRQ4cOoampWWi5q1evplevXujo6MhpTZs2ZcOGDXTv3p1nz56Rk5ODp6cnS5YsKbJ+Y8aMoUKFCiqfhwC7d++mR48eZGZmYm5uTlRUlPzZ9rKHDx+Sm5tb4AGqZmZmKvNEBKEk+s80LAB++OEHAgICiIuL49SpU/j4+NC0aVNcXFwA6Nq1Kzo6Ouzbtw9DQ0O+//572rRpw/Xr1+nevTsWFhbyxCsLCwsMDAwKpJmYmHD8+HH69u3LwoULad68OQkJCQwcOBB43kjIy8ujbdu2/PPPP6xfv56qVaty+fJl1NXVcXR0JCwsjEmTJsmTzfK/hL6od+/edO3alfT0dHn/gQMHyMzMpGPHjsDzCWzr169n+fLlWFtbc+zYMfr06YOJiQktW7Ys8jqpqakxfPhwOnbsSHx8PA4ODir7c3Jy8PLyYsCAAfz4449kZ2dz5swZuSGUnp6Oh4cHM2bMQEtLi7Vr1+Lp6cm1a9eoVKkSv/76K8OGDWPdunU4Ojry999/c/z4cQDCw8O5fv06tWvXZurUqcDznponT57QunVr+vfvz4IFC3j69CljxoyhW7duHDlyROU1HjJkCLGxsUXGV6pUKTQ0NFR6JubNm8ekSZOYPHkyAAkJCbi7uzN9+nTWrFnDgwcP8PPzw8/Pj4iICPm4uXPnMm7cOKZMmcKBAwcYPnw4NjY28u+UmpoaCxcuxMrKisTERIYOHUpgYKDKE7szMzOZPXs2q1atomzZspiamuLn58fly5fZtGkTFSpUYPv27bi7u/P7779jbW1NXFwc/fr1IyQkBC8vL/bv3y/X/UUJCQns2LGD3bt38/jxY7p168asWbOYMWPGG/2OTJw4kcuXL7Nv3z7KlSvHzZs3efr0KQALFy5k165d/PTTT1SqVIk7d+5w586dIq97VlYWWVlZ8nZaWhoAWmoS6upSkccVd1pqksq/JZWIs+QpjrEqlUqVbT8/Py5dukR0dHSBfd26dcPJyYm7d+8yYcIEevbsybFjx9DW1lbJd/r0aa5cuUJERIRKGZcvX2b48OGMHz8eFxcXUlJSGDt2LAMHDmTFihUF6jZnzhw2bdpEVFQU6urqKmU1a9aMs2fP8ujRI1avXk23bt04ceKEPJ+jsBhzcnJUysjNzUWSpAJxvnxcUftLChHnv3fuT0EhSdIne0fy8fHhyZMn7NixAycnJ3Jzc+UvsAAODg60bt2aWbNmceLECdq1a8f9+/fR0tKS81SrVo3AwEAGDhzI+fPnsbe3l++gA4WmOTs706ZNG5U7t+vXrycwMJB79+5x8OBB2rZty5UrV7CxsSlQ7/y72E+ePFFJf7HHIicnR+6d+PrrrwHo1asXeXl5bNq0iaysLIyNjTl06BBNmjSRy+jfvz+ZmZls3LiR27dvY2Vlxblz5wpMzL569Sq2trZs3ryZbt26qfRY/P3335QtW5aYmJhXNlBeVLt2bQYPHoyfnx/btm3jm2++4e7du/Kd8xc5OTlRr149lYnq06dP5/jx4xw4cEBOu3v3LhYWFly7dg0bGxucnJxIS0vjt99+K/K6ZWdnExoayrhx49i9ezft2rXD0tISe3t7tm/frnKd1NXV+f777+W0EydO0LJlSzIyMtDW1sbS0hJbW1v27dsn5+nRowdpaWns3bu30OuwdetWBg8ezMOHDwHknrDz58/L3d5JSUlUqVKFpKQkKlSoIB/r7OyMg4MDM2fOpFevXqSmprJnzx6Vc+/fv1/+vQkODmbu3LmkpKTI1zkwMJBjx45x+vTpN/od+eqrryhXrhxr1qwpEMuwYcP4448/OHTokNyofJXg4GCmTJlSIH3jxo0fdQihIAifpxUrVhAXF8fMmTML3N1/mVKppE+fPvj6+tKiRQuVfYsWLSIxMZEFCxaopC9YsAClUklgYKCcdvnyZcaNG8eaNWtUhjvt2LGDn376ialTp1KtWrXX1n3IkCG0adOmwAiD/Lp2796dwMBAvvzySzk9PDycjIwMxo0b99ryBeF9ZGZmyt9DSpcu/a+e+z/VY1G3bl2VbXNzc3kFhQsXLpCenl5gHsHTp09JSEh4q/NcuHCB2NhY+a4wPL+T8OzZMzIzMzl//jxffPFFoY2KN1WqVCm6devGhg0b+Prrr8nIyGDnzp1s2rQJgJs3b5KZmSnfOc+XnZ2Nvb39a8vPbw8W9oXR2NgYHx8f3NzccHFxwdnZmW7dumFubg4877EIDg5mz549JCcnk5OTw9OnT0lKSgLAxcWFypUrU6VKFdzd3XF3d6djx46v/HJ54cIFoqOjC+29SUhIkK9lgwYNCj1+zJgxTJgwgWfPnqGvr8+sWbNo1+7/u8wbNmxY4HwXL15kw4YNKtckLy+PW7duYWtrC6DyhTx/+8UG0aFDhwgJCeHq1aukpaWRk5Mj/x7kx6upqanyu/n777+Tm5tb4PcjKytL/v28cuWK3DP14rn379+vkmZpaanSeHvxd/5NfkeGDBlC586d+e2333B1dcXLywtHR0fgecPdxcWF6tWr4+7uTvv27XF1daUoQUFBBAQEyNtpaWlYWFgw/ZwaORrqRR5X3GmpSUxrmMfEX9XIyisew0nehYiz5CmOsV4KdkOSJPz9/Tl//jzHjh3D2tr6lccolUr27t2LmpoaNWvWVJkjkZ6eTp8+fZg+fXqBuRORkZGUKlVKJT2/MdG6dWv5xtC8efPYtm0bBw4coHHjxm8Uh46ODpaWlkXO12jQoAFpaWny/ry8PHx9fRkyZEiRxyiVSqKionBxcUFDQ+ON6lEciTg/vvwRB5/Cf6ph8fKFVygU8kTZ9PR0zM3NiYmJKXDc2y7hmZ6ezpQpU+jUqVOBfdra2ipjNN9H7969admyJffv3ycqKgodHR3c3d3lOgDs2bOHihUrqhz3Yo9MUa5cuQKAlZVVofsjIiIYNmwY+/fvZ/PmzUyYMIGoqCi+/PJLRo0aRVRUFPPmzaNatWro6OjQpUsXeeiRgYEBv/32GzExMRw8eJBJkyYRHBzM2bNni7zW6enpeHp6Mnv27AL78hs0gDz/4WWjR4/Gx8cHfX19zMzMCjSYXj4uPT2dQYMGMWzYsAJlVapUqdBzvOz27du0b9+eIUOGMGPGDIyNjTlx4gT9+vUjOztbbljo6Oio1Cc9PR11dXXi4+NRV1f9wl1Yw+pVXvc7D6/+HWnbti1//vkne/fuJSoqijZt2uDr68u8efOoX78+t27dYt++fRw6dIhu3brh7OzM1q1bC62LlpZWob97x8Y4F7uFAd5G/peW+EnuJf5DTsRZshTXWIcOHcrGjRvZuXMnxsbG8nMlDA0N0dHRITExkc2bN+Pq6oqJiQm3b99mzpw56Ojo4OnpqRLrtm3byMnJwdvbu8A16NChAwMGDGDVqlW4ubmRnJxMQEAADg4OVK5cGYDZs2cTHBzMxo0bqVatmlwXfX199PX1ycjIYMaMGXz11VeYm5vz8OFDlixZwv/+9z969Oghn7NNmzZ07NgRPz8/AEaOHIm3tzcODg44ODgQFhZGRkYG/fv3f+1rpaGhUaxez3cl4vy45/xU/lMNi1epX78+KSkplCpVSh7S9D5lXbt2rcjuzrp163L37l2uX79eaK+FpqamvJb2qzg6OmJhYcHmzZvZt28fXbt2lV/smjVroqWlRVJS0hsPV8qXl5cnzwt4Ve+Gvb099vb2BAUF0aRJEzZu3MiXX35JbGwsPj4+8h319PR0bt++rXJsqVKlcHZ2xtnZmcmTJ2NkZMSRI0fo1KlTofHXr1+fn3/+GUtLS3kC/NsoV67cG3U/v3i+y5cvv/aY06dPF9jO782Ij48nLy+P0NBQ1NSeL5D2008/vfbc9vb25Obmcv/+fZo3b15oHltb2wIPUHq5Lq/zpr8jJiYmeHt74+3tTfPmzRk9ejTz5s0DoHTp0nTv3p3u3bvTpUsX3N3d+fvvv4tc8UQQBOFjW7ZsGYDKYhfw/IaYj48P2traHD9+nLCwMHnhiSpVqnD06NECcxpWr15Np06dCr3p5ePjwz///MPixYsZOXIkRkZGtG7dWuUG2LJly8jOzi4wpCl/URZ1dXWuXr3KDz/8wMOHDylbtiyNGjXi+PHj1KpVS86fkJAgD6GF58/ZePDgAZMmTSIlJYV69eqxf//+1w75EoTirtg0LJydnWnSpAleXl7MmTMHGxsb7t27x549e+jYsWOBoTKvMmnSJNq3b0+lSpXo0qULampqXLhwgUuXLjF9+nRatmxJixYt6Ny5M/Pnz6datWpcvXoVhUKBu7s7lpaWpKenc/jwYfmJnkUNE+rVqxfLly/n+vXr8gpI8LxXYNSoUYwYMYK8vDyaNWtGamoqsbGxlC5dGm9vbznvo0ePSElJITMzk0uXLhEWFsaZM2fYs2dPgTvm8HyVphUrVvDVV19RoUIFrl27xo0bN+jbty8A1tbWbNu2DU9PTxQKBRMnTlRZQnX37t0kJibSokULypQpw969e8nLy6N69erA8+E7cXFx3L59G319fYyNjfH19WXlypX07NmTwMBAjI2NuXnzJps2bWLVqlWF1vN9jBkzhi+//BI/Pz/69++Pnp4ely9fJioqisWLF8v5YmNjmTNnDl5eXkRFRbFlyxZ53kO1atVQKpUsWrQIT09PYmNjWb58+WvPbWNjQ+/evenbty+hoaHY29vz4MEDDh8+TN26dWnXrh3Dhg2jadOmzJs3jw4dOnDgwIECw6Be501+RyZNmkSDBg2oVasWWVlZ7N69W244zZ8/H3Nzc+zt7VFTU2PLli2UL19ePKRPEIRP6nVTOytUqKAyDy6/Zyb/M+hFRS1Lnu+7777ju+++K3L/yzfVXqatrc22bdtemaeocvIXFBGEz0mxeY6FQqFg7969tGjRgm+++QYbGxt69OjBn3/++dZ3ANzc3Ni9ezcHDx6kUaNGfPnllyxYsEDuGgX4+eefadSoET179qRmzZoEBgbKd+kdHR0ZPHgw3bt3x8TEhDlz5hR5rt69e3P58mUqVqxI06ZNVfZNmzaNiRMnEhISgq2tLe7u7uzZs6fA8CZnZ2fMzc2pU6cOY8eOxdbWlosXL9KqVatCz6mrq8vVq1fp3LkzNjY2DBw4EF9fXwYNGgQ8/8JZpkwZHB0d8fT0xM3Njfr168vHGxkZsW3bNlq3bo2trS3Lly/nxx9/lO/OjBo1CnV1dWrWrImJiYk8iTk2Npbc3FxcXV2pU6cO/v7+GBkZyb0BH1LdunU5evQo169fp3nz5tjb2zNp0iSVydTwvDv6119/xd7enunTpzN//nzc3NwAsLOzY/78+cyePZvatWuzYcMGQkJC3uj8ERER9O3bl5EjR1K9enW8vLw4e/asPAzryy+/ZOXKlYSHh2NnZ8fBgweZMGHCW8f5ut8RTU1NgoKCqFu3Li1atEBdXV2ex2NgYMCcOXNo2LAhjRo14vbt2/I4ZUEQBEEQhA/tk64KJQgf04urTQlvLy0tDUNDQ7n7v6TKvxvq4eFRosf7ijhLns8lVhFnySLi/PjyP78/xapQ4talIAiCIAiCIAjvTTQsBEEQBEEQBEF4b8Vm8rYgvK3XTcoTBEEQBEEQPhzRYyEIgiAIgiAIwnsTDQtBEARBEARBEN6baFgIwr8sMjLyozxL4vbt2ygUCs6fP//ByxYEQfgQQkJCaNSoEQYGBpiamuLl5cW1a9dU8gwaNIiqVauio6ODiYkJnTp14u7du/L+yMhIFApFoT/3798Hnj8cr7D9Lz7U7nV1+fvvv/nuu++oXr06Ojo6VKpUiWHDhpGamvrKGCVJYtKkSZibm6Ojo4OzszM3btz4EJdPEP7zRMNCKHaWL1+OgYEBOTk5clp6ejoaGhoFnuQaExODQqEgISHhlWXm53vy5MlHqLEgCIIAcPToUXx9fTl9+jRRUVEolUpcXV3JyMiQ8zRo0ICIiAiuXLnCgQMHkCSJ4OBg+VlS3bt3Jzk5WeXHzc2Nli1byk/mDg8PV9l/584djI2N6dq16xvX5d69e9y7d4958+Zx6dIlIiMj2b9/P/369XtljHPmzGHhwoUsX76cuLg49PT0cHNz49mzZx/6cgrCf46YvC0UO61atSI9PZ1ff/2VL7/8EoDjx49Tvnx54uLiePbsGdra2gBER0dTqVIlqlat+q/UTZIkcnNzKVVK/GkJgiC8bP/+/SrbkZGRmJqaEh8fT4sWLQAYOHCgvN/S0pIpU6bQsGFDbt++TY0aNdDR0UFHR0fO8+DBA44cOcLq1avlNENDQwwNDeXtHTt28PjxY7755ps3rkvt2rX5+eef5f1Vq1ZlxowZ9OnTh5ycnELf5yVJIiwsjAkTJtChQwcA1q5di5mZGTt27KBHjx5vdb0EobgRPRZCsVO9enXMzc2JiYmR02JiYujQoQNWVlacPn1aJb1Vq1asW7eOhg0bYmBgQPny5enVq5fcZX779m35KeZlypRBoVDg4+MDQF5eHiEhIVhZWaGjo4OdnR1bt25VKV+hULBv3z4aNGiAlpYWJ06c4MKFC7Rq1QoDAwNKly5NgwYN+PXXX1XiOHDgALa2tujr6+Pu7k5ycrLK/lWrVmFra4u2tjY1atRg6dKlKvvPnDmDvb092traNGzYkHPnzqnsf/z4Mb1798bExAQdHR2sra2JiIh4t4suCILwEeQPKzI2Ni50f0ZGhvzF3MLCotA8a9euRVdXly5duhR5ntWrV+Ps7EzlypXfuS75eUqXLl3kzaNbt26RkpKCs7OznGZoaEjjxo05depUkeUKQkkhbqsKxVKrVq2Ijo5m7NixwPOeicDAQHJzc4mOjsbJyYmnT58SFxfHt99+i1KpZNq0aVSvXp379+8TEBCAj48Pe/fuxcLCgp9//pnOnTtz7do1SpcuLd8NCwkJYf369Sxfvhxra2uOHTtGnz59MDExoWXLlnJ9xo4dy7x586hSpQplypShRYsW2Nvbs2zZMtTV1Tl//rzKkzczMzOZN28e69atQ01NjT59+jBq1Cg2bNgAwIYNG5g0aRKLFy/G3t6ec+fOMWDAAPT09PD29iY9PZ327dvj4uLC+vXruXXrFsOHD1e5RhMnTuTy5cvs27ePcuXKcfPmTZ4+ffrW17pxyGFySum99XHFhZa6xBwHqB18gKxcxaeuzkcj4ix5ilust2e1U9nOy8vD39+fpk2bUrt2bZV9S5cuJTAwkIyMDGxsbAgODkZTU7PQclevXk2vXr1UejFedO/ePfbt28fGjRuLrNur6pLv4cOHTJs2TaVH5WUpKSkAmJmZqaSbmZnJ+wShJBMNC6FYatWqFf7+/uTk5PD06VPOnTtHy5YtUSqVLF++HIBTp06RlZVFq1atqFSpknxslSpVWLhwIY0aNSI9PR19fX35DpWpqak8sTorK4uZM2dy6NAhmjRpIh974sQJvv/+e5WGxdSpU3FxcZG3k5KSGD16NDVq1ADA2tpapf759cwfouXn58fUqVPl/ZMnTyY0NJROnToBYGVlxeXLl/n+++/x9vZm48aN5OXlsXr1arS1talVqxZ3795lyJAhKnWwt7enYcOGwPMhBa+SlZVFVlaWvJ2WlgaAlpqEurr0ymOLMy01SeXfkkrEWfIUt1iVSqXKtp+fH5cuXSI6OrrAvm7duuHk5ERKSgqhoaHMnTuXbt26YWBgoJLv9OnTXLlyhYiIiAJl5FuzZg1GRka0a9euyDyvqgs8fz/08PDA1taW8ePHF1lO/tw/pVKpkicvLw+FQlHkcfnHvPhvSSXi/PfO/SmIhoVQLDk5OZGRkcHZs2d5/PgxNjY2ci/CN998w7Nnz4iJiaFKlSpUqlSJ+Ph4goODuXDhAo8fPyYvLw94/uW7Zs2ahZ7j5s2bZGZmqjQYALKzs7G3t1dJy//yni8gIID+/fuzbt06nJ2d6dq1q8o8D11dXZVtc3NzeWhWRkYGCQkJ9OvXjwEDBsh5cnJy5DHDV65coW7duvJcEkBu/OQbMmQInTt35rfffsPV1RUvLy8cHR2LvKYhISFMmTKlQPoE+zx0dXOLPK6kmNYw71NX4V8h4ix5ikuse/fulf+/YsUK4uLimDlzJhcvXuTixYtFHvfNN9/Qp08fZsyYIc/DyLdo0SKsrKxISUlRKT+fJEksXboUR0dHDh06VGj5r6vL06dPCQ4ORktLi379+hEVFVVkXfN7JX7++WeqVKkip1+9ehUrK6tC6/iyV5Vfkog4P57MzMx//Zz5RMNCKJaqVavGF198QXR0NI8fP5Z7DypUqICFhQUnT54kOjqa1q1bk5GRgZubG25ubmzYsAETExOSkpJwc3MjOzu7yHOkp6cDsGfPHipWrKiyT0tLS2VbT091qFBwcDC9evViz5497Nu3j8mTJ7Np0yY6duwIoDIsCkChUCBJksp5V65cSePGjVXyqaurv9H1AWjbti1//vkne/fuJSoqijZt2uDr68u8efMKzR8UFERAQIC8nZaWhoWFBa1ataJs2bJvfN7iRqlUEhUVhYuLS4HXpSQRcZY8xTFWSZLw9/fn/PnzHDt2rEBvbmHS09ORJAkbGxs8PDxU0vv06cP06dNV0l909OhRkpOTmTJlSoEhTm9Sl7S0NNq1a4eZmRm7du1CV1f3tfEFBwejVCrlOqWlpXHz5k3Gjh1bZD2heL6e70LE+fHljzj4FETDQii2WrVqRUxMDI8fP2b06NFyeosWLdi3bx9nzpxhyJAhXL16lUePHjFr1ix58t/LE6nzx+7mL2cIULNmTbS0tEhKSlIZ9vSmbGxssLGxYcSIEfTs2ZOIiAi5YfEqZmZmVKhQgcTERHr37l1oHltbW9atW6eyAtaLk9bzmZiY4O3tjbe3N82bN2f06NFFNiy0tLQKNJjgeSOoJL/55xNxliyfS5xQvGIdOnQoGzduZOfOnRgbG/Po0SPg+QRnHR0dEhMT2bx5M66urpiYmHD37l1mzpyJlpYW7du3V4lz27Zt5OTk4O3tXWT8P/zwA40bNy7Qy/wmdclvVGRmZrJhwwaePn0qz1MzMTGRb/TUqFGDkJAQ+f3d39+fkJAQatSogZWVFRMnTqRChQp06dLljV6n4vR6vg8R58c956ciGhZCsdWqVSt8fX1RKpUqX/xbtmyJn58f2dnZtGrVilKlSqGpqcmiRYsYPHgwly5dYtq0aSplVa5cGYVCwe7du/Hw8EBHRwcDAwNGjRrFiBEjyMvLo1mzZqSmphIbG0vp0qXx9vYutF5Pnz5l9OjRdOnSBSsrK+7evcvZs2fp3LnzG8c2ZcoUhg0bhqGhIe7u7mRlZfHrr7/y+PFjAgIC6NWrF+PHj2fAgAEEBQVx+/btAg2GSZMm0aBBA2rVqkVWVha7d+/G1tb2La6wIAjCh7Vs2TKAAs8cioiIwMfHB21tbY4fP05YWBiPHz/GzMyMZs2aMWvWLPkZFflWr15Np06dinzgaGpqKj///DPh4eHvVJfffvuNuLg44Hkv+Ytu3bolz1u7du2aykPz8iedDxw4kCdPntCsWTP279+vMnRVEEoq0bAQiq1WrVrx9OlTatSoobICR8uWLfnnn3/kZWnh+frk48aNY+HChdSvX5958+bx1VdfycdUrFiRKVOmMHbsWL755hv69u1LZGQk06ZNw8TEhJCQEBITEzEyMqJ+/fqMGzeuyHqpq6vz6NEj+vbty19//UW5cuXo1KlTofMXitK/f390dXWZO3cuo0ePRk9Pjzp16uDv7w+Avr4+v/zyC4MHD8be3p6aNWsye/ZslcaLpqam3OjQ0dGhefPmbNq06Y3rIAiC8KHlD/ksSoUKFQrMQ1AqlYXOTTh58uQryzI0NHzlWPPX1cXJyem1eQorR6FQMHXqVJUFOQThc6GQ3uSvRhCEz05aWhqGhoY8fPiwxM+x2Lt3Lx4eHiW6W17EWfJ8LrGKOEsWEefHl//5nf/clX+TeECeIAiCIAiCIAjvTTQsBEEQBEEQBEF4b6JhIQiCIAiCIAjCexMNC0EQBEEQBEEQ3ptoWAiCIAiCIAiC8N5Ew0IQBEEQhI8qJCSERo0aYWBggKmpKV5eXly7dk0lz6BBg6hatSo6OjqYmJjQoUMHrl69qpJHoVAU+HlxGe0TJ07QtGlTypYti46ODjVq1GDBggUF6vO///2PPn36yPnq1KlT4MGpV65c4auvvsLQ0BA9PT0aNWpEUlLSK+PcsmULNWrUQFtbmzp16hS6TK4glGSiYSG8k8jIyCIfSlRSfaqYP8drLQhCyXL06FF8fX05ffo0UVFRKJVKXF1dycjIkPM0aNCAiIgIrly5woEDB5AkCVdXV3Jzc1XKioiIIDk5Wf7x8vKS9+np6eHn58exY8e4cuUKEyZMYMKECaxYsULO8/jxY5o2bYqGhgb79u3j8uXLhIaGUqZMGTlPQkICzZo1o0aNGsTExHDx4kUmTpz4yofcnTx5kp49e9KvXz/OnTuHl5cXXl5eXLp06QNcQUEoHsQD8kogHx8fnjx5wo4dOz51VT4JJycn6tWrR1hY2Fsd5+Pjww8//ACAhoYGlSpVom/fvowbN45SpT7dn0r37t3x8PD4ZOcXBEF4X/v371fZjoyMxNTUlPj4eFq0aAHAwIED5f2WlpZMnz4dOzs7bt++rXKskZER5cuXL/Q89vb22Nvbq5Szbds2jh8/Lpc/e/ZsLCwsiIiIkPNZWVmplDN+/Hg8PDyYM2eOnFa1atVXxhgeHo67uzujR48GYNq0aURFRbF48WKWL1/+ymMFoaQQPRaC8AJ3d3eSk5O5ceMGI0eOJDg4mLlz537SOuno6GBqavpJ6yAIgvAhpaamAmBsbFzo/oyMDCIiIrCyssLCwkJln6+vL+XKlcPBwYE1a9a88unY586d4+TJk7Rs2VJO27VrFw0bNqRr166Ymppib2/PypUr5f15eXns2bMHGxsb3NzcMDU1pXHjxq+9WXfq1CmcnZ1V0tzc3Dh16tQrjxOEkkT0WJRwTk5O1K1bF21tbVatWoWmpiaDBw8mODhYzjN//nwiIiJITEzE2NgYT09P5syZg76+vpwnMjKSSZMm8fDhQ9zc3GjWrFmBc+3cuZMpU6Zw+fJlKlSogLe3N+PHj5fv9t+4cYN+/fpx5swZqlSpQnh4OK6urmzfvh0vLy9iYmJo1aoVjx8/lof+nD9/Hnt7e27duoWlpSWPHj2Su7kfP35M1apVGTduHD179gSe9zocPXqUo0ePEh4eDiAfe+nSJUaPHs3x48fR09PD1dWVBQsWUK5cOTkGLS0t+U7YkCFD2L59O7t27SIoKKhAvAkJCQQEBHD69GkyMjKwtbUlJCRE5YPF0tKSgQMHcvPmTbZs2UKZMmWYMGGCfOfs9u3bWFlZ8fPPP7No0SLi4uKwtrZm+fLlNGnSRL72/v7+PHnyBIDg4GB27NjByJEjmThxIo8fP6Zt27asXLkSAwMDAP755x8GDx7Mjh07KF26NIGBgezcufOdenIahxwmp5TeWx1TnGipS8xxgNrBB8jKVXzq6nw0Is6Sp7jEentWO5XtvLw8/P39adq0KbVr11bZt3TpUgIDA8nIyKB69epERUWhqakp7586dSqtW7dGV1eXgwcPMnToUNLT0xk2bJhKOV988QUPHjwgJyeH4OBg+vfvL+9LTExk2bJlBAQEMG7cOM6ePcuwYcPQ1NTE29ub+/fvk56ezqxZs5g+fTqzZ89m//79dOrUiejoaJVGyotSUlIwMzNTSTMzMyMlJeWdrpsgFEeiYfEZ+OGHHwgICCAuLo5Tp07h4+ND06ZNcXFxAUBNTY2FCxdiZWVFYmIiQ4cOJTAwkKVLlwIQFxdHv379CAkJwcvLi/379zN58mSVcxw/fpy+ffuycOFCmjdvTkJCgvzlefLkyeTl5dGpUyfMzMyIi4sjNTUVf3//t47l2bNnNGjQgDFjxlC6dGn27NnD119/TdWqVXFwcCA8PJzr169Tu3Ztpk6dCoCJiQlPnjyhdevW9O/fnwULFvD06VPGjBlDt27dOHLkSJHn09HR4dGjR4XuS09Px8PDgxkzZqClpcXatWvx9PTk2rVrVKpUSc4XGhrKtGnTGDduHFu3bmXIkCG0bNmS6tWry3nGjx/PvHnzsLa2Zvz48fTs2ZObN28WOQQrISGBHTt2sHv3bh4/fky3bt2YNWsWM2bMACAgIIDY2Fh27dqFmZkZkyZN4rfffqNevXpFxpqVlUVWVpa8nZaWBoCWmoS6etF3BIs7LTVJ5d+SSsRZ8hSXWJVKpcq2n58fly5dIjo6usC+bt264eTkREpKCvPnz6dr164cOnRILmfs2LFy3tq1a5OWlsbcuXMZMmSISjlHjhwhPT2dM2fOMH78eCwtLenRowfwvGHToEEDpkyZIpdz8eJFli1bRq9eveT3QU9PT/z8/ACoVasWJ06cYOnSpTg6OhYZa05OjkpM+fNDXo7zVdfpTfIWZyLOf+/cn4JoWHwG6tatKzcErK2tWbx4MYcPH5YbFi9+wc8f1zp48GC5YZE/bjQwMBAAGxsbTp48qTJmdsqUKYwdOxZvb28AqlSpwrRp0wgMDGTy5MkcOnSIq1evcuDAASpUqADAzJkzadu27VvFUrFiRUaNGiVvf/fddxw4cICffvoJBwcHDA0N0dTURFdXV2UM7uLFi7G3t2fmzJly2po1a7CwsOD69evY2NionEeSJA4fPsyBAwf47rvvCq2LnZ0ddnZ28va0adPkHo78DyMADw8Phg4dCsCYMWNYsGAB0dHRKg2LUaNG0a5dO/la1qpVi5s3b1KjRo1Cz52Xl0dkZKTcQ/H1119z+PBhZsyYwT///MMPP/zAxo0badOmDfB8smP+dS9KSEiI/EH7ogn2eejq5hZyRMkyrWHep67Cv0LEWfL812N9cWWkFStWEBcXx8yZM7l48SIXL14s8jgfHx/69OnDjBkzaNGiBVFRUQXyqKmpcffuXXbu3ImGhkaB/ebm5ri7uzN27FhKly4NPJ+joa+vr1KvnJwcbty4wd69e1Eqlairq6Ourq6SR1NTk4sXLxa50pOhoSExMTHyeQBiY2PR1dV9q9WhCouzJBJxfjyZmZn/+jnziYbFZ6Bu3boq2+bm5ty/f1/ePnToECEhIVy9epW0tDRycnJ49uwZmZmZ6OrqcuXKFTp27KhSRpMmTVQaFhcuXCA2Nla+Yw7P79Tkl3PlyhUsLCxUvtzmD/V5G7m5ucycOZOffvqJ//3vf2RnZ5OVlYWuru4rj7tw4QLR0dEqw7vyJSQkyA2L3bt3o6+vj1KpJC8vj169eqkMG3tReno6wcHB7Nmzh+TkZHJycnj69GmB5QhfvP4KhYLy5curXP+X85ibmwNw//79IhsWlpaWcqMi/5j8MhMTE1EqlTg4OMj7DQ0NVRoyhQkKCiIgIEDeTktLw8LCgunn1MjRUH/lscWZlprEtIZ5TPxVjay8/+5wkvcl4ix5ikusl4LdkCQJf39/zp8/z7Fjx7C2tn7tcVlZWaipqcnvzy4uLgUaDxcuXKBMmTJ06NChyHJ+++03YmNj5UUwWrduzd27d1UWxThy5Ag2NjZyWqNGjQBU8qxZswY7O7siF9PI72l5cf+sWbNwcXF5owU4lEolUVFRhcZZkog4P778EQefgmhYfAZe/oVWKBTk5T2/w3X79m3at2/PkCFDmDFjBsbGxpw4cYJ+/fqRnZ392i/s+dLT05kyZQqdOnUqsO9Vy/O9SE3t+VoCL07Ee7k7b+7cuYSHhxMWFkadOnXQ09PD39+f7Ozs19bP09OT2bNnF9iX/0UeoFWrVixbtgxNTU0qVKjwytWgRo0aRVRUFPPmzaNatWro6OjQpUuXAnV51fUvLI9C8fwLwst53rbMt6WlpYWWllaB9GNjnClbtux7lf1fplQq2bt3L/GT3Ev8h5yIs2QpTrEOHTqUjRs3snPnToyNjeUhpoaGhujo6JCYmMjmzZtxdXXFxMSEu3fvMmvWLHR0dGjfvj2//vorBw4c4NGjR3z55Zdoa2sTFRXF7NmzGTVqlBz/kiVLqFSpknxT5tixYyxYsIBhw4bJeUaOHImjoyNz586lW7dunDlzhlWrVrFixQo5T2BgIN27d8fJyYlWrVqxf/9+9uzZQ0xMjJynb9++VKxYkZCQEABGjBhBy5YtWbhwIe3atWPTpk3Ex8ezcuXKt3p9NDQ0/vOv54cg4vy45/xURMPiMxcfH09eXh6hoaHyF/uffvpJJY+trS1xcXEqaadPn1bZrl+/PteuXaNatWqFnsfW1pY7d+6QnJwsf5F/uQwTExMAkpOT5fXEz58/r5InNjaWDh060KdPH+D5l+/r169Ts2ZNOY+mpmaBdc/r16/Pzz//jKWl5SsbC3p6ekXG8LLY2Fh8fHzk3pz09PQCyyJ+ClWqVEFDQ4OzZ8/Kcz1SU1O5fv26vKyjIAjCv2nZsmXA87v6L4qIiMDHxwdtbW2OHz9OWFgYjx8/xszMjBYtWnDy5El5VTwNDQ2WLFnCiBEjkCSJatWqMX/+fAYMGCCXl5eXR1BQELdu3aJUqVJUrVqV2bNnM2jQIDlPo0aN2L59O0FBQUydOhUrKyvCwsLo3bu3nKdjx44sX76ckJAQhg0bRvXq1fn5559VFi5JSkqSPzcBHB0d2bhxIxMmTGDcuHFYW1uzY8eOAhPUBaEkEw2Lz1y1atVQKpUsWrQIT09PYmNjC6y3PWzYMJo2bcq8efPo0KEDBw4cKLAm+aRJk2jfvj2VKlWiS5cuqKmpceHCBS5dusT06dNxdnbGxsYGb29v5s6dS1paGuPHjy9QFwsLC4KDg5kxYwbXr18nNDRUJY+1tTVbt27l5MmTlClThvnz5/PXX3+pNCwsLS2Ji4vj9u3b6OvrY2xsjK+vLytXrqRnz54EBgZibGzMzZs32bRpE6tWrUJd/e2H+lhbW7Nt2zY8PT1RKBRMnDjxvXsNPgQDAwO8vb0ZPXo0xsbGmJqaMnnyZNTU1OTeEEEQhH/Tq5aEBahQoUKR8xDye67d3Nxo3779K8v57rvvipwX96L27du/tqxvv/2Wb7/9tsj9MTExBdK6du1K165dX3t+QSipxHMsPnN2dnbMnz+f2bNnU7t2bTZs2CB36+b78ssvWblyJeHh4djZ2XHw4EEmTJigksfNzY3du3dz8OBBGjVqxJdffsmCBQuoXLky8HyY0/bt23n69CkODg70799fZT4GPL8b9eOPP3L16lXq1q3L7NmzmT59ukqeCRMmUL9+fdzc3HBycqJ8+fIqT12F50OU1NXVqVmzJiYmJiQlJVGhQgViY2PJzc3F1dWVOnXq4O/vj5GRkcodp7cxf/58ypQpg6OjI56enri5uVG/fv13KutDmz9/Pk2aNKF9+/Y4OzvTtGlTbG1t33hYmiAIgiAIwttSSK+7jSAIH5FCoZCfYyF8PBkZGVSsWJHQ0FD69ev3RsekpaVhaGjIw4cPP4s5Fh4eHiV6vK+Is+T5XGIVcZYsIs6PL//zOzU1VWWVsn+DGAolCCXQuXPnuHr1Kg4ODqSmpsrP9HjVyimCIAiCIAjvQzQsBKGEmjdvHteuXUNTU5MGDRpw/PhxlaeMC4IgCIIgfEiiYSF8UmIk3sdhb29PfHz8p66GIAiCIAifETF5WxAEQRAEQRCE9yYaFoIgCIIgCIIgvDfRsBCED8THx+eNV7d6Oa+TkxP+/v6vPMbS0pKwsLB3rp8gCMKnEBISQqNGjTAwMMDU1BQvLy+uXbumkmfQoEFUrVoVHR0dTExM6NChA1evXlXJo6mpiUKhUPnZtGmTvD85OZlevXphY2ODmppaoe+pkZGRBcp4eRnubdu24erqStmyZVEoFAUe1FqULVu2UKNGDbS1talTp06Rz+UQhJJMNCyEEultvuT/F2zbto1p06Z96moIgiB8cEePHsXX15fTp08TFRWFUqnE1dWVjIwMOU+DBg2IiIjgypUrHDhwAEmScHV1JTc3V6WsiIgIkpOT5Z8X3+ezsrIwMTFhwoQJ2NnZFVmf0qVLq5Tx559/quzPyMigWbNmzJ49+41jPHnyJD179qRfv36cO3cOLy8vvLy8uHTp0huXIQglgZi8LQj/AcbGxp+6CoIgCB/F/v37VbYjIyMxNTUlPj6eFi1aADBw4EB5v6WlJdOnT8fOzo7bt29TqVIleZ+RkRHly5cv9DyWlpaEh4cDsGbNmiLro1AoiiwD4Ouvvwbg9u3brw7sBeHh4bi7uzN69GgApk2bRlRUFIsXL2b58uVvXI4gFHeix0L47MyfP586deqgp6eHhYUFQ4cOJT09Xd4fGRmJkZERBw4cwNbWFn19fdzd3UlOTpbz5ObmEhAQgJGREWXLliUwMLDACldbt26lTp066OjoULZsWZydnVXu0L3o5aFQ9+/fx9PTEx0dHaysrNiwYUOBY548eUL//v0xMTGhdOnStG7dmgsXLsj7L1y4QKtWrTAwMKB06dI0aNCAX3/99V0vmyAIwgeRmpoKFH1DJSMjg4iICKysrLCwsFDZ5+vrS7ly5XBwcGDNmjXvtLJgeno6lStXxsLCgg4dOvDHH3+8fRAvOXXqFM7Ozippbm5unDp16r3LFoTiRPRYCJ8dNTU1Fi5ciJWVFYmJiQwdOpTAwECWLl0q58nMzGTevHmsW7cONTU1+vTpw6hRo+Qv+KGhoURGRrJmzRpsbW0JDQ1l+/bttG7dGng+1rdnz57MmTOHjh078s8//3D8+PE3/hD08fHh3r17REdHo6GhwbBhw7h//75Knq5du6Kjo8O+ffswNDTk+++/p02bNly/fh1jY2N69+6Nvb09y5YtQ11dnfPnz7/T0z8bhxwmp5TeWx9XXGipS8xxgNrBB8jKVXzq6nw0Is6SpzjEentWO5XtvLw8/P39adq0KbVr11bZt3TpUgIDA8nIyKB69epERUWhqamJUqkEYPLkybi4uKCrq8vBgwflm0LDhg174/pUr16dNWvWULduXVJTU5k3bx6Ojo788ccffPHFF+8cZ0pKCmZmZippZmZmpKSkvHOZglAciYaF8Nl5sWcgv8t98ODBKg0LpVLJ8uXLqVq1KgB+fn7y06sBwsLCCAoKolOnTgAsX76cAwcOyPuTk5PJycmhU6dOVK5cGYA6deq8Uf2uX7/Ovn37OHPmDI0aNQJg9erV2NraynlOnDjBmTNnuH//PlpaWsDzB+Lt2LGDrVu3MnDgQJKSkhg9ejQ1atQAwNra+pXnzcrKIisrS95OS0sDQEtNQl295D5vREtNUvm3pBJxljzFIdb8RkE+Pz8/Ll26RHR0dIF93bp1w8nJiZSUFObPn0/Xrl05evQo6urqAAQGBso3R2rXrk1aWhpz585lyJAhBc4rSRJ5eXkFztGwYUMaNmwob2/evJm6deuydOlSpkyZUmjdlUplgXIKk5OTo5Ivf37Imxz78vlKMhHnv3fuT0E0LITPzqFDhwgJCeHq1aukpaWRk5PDs2fPyMzMRFdXFwBdXV25UQFgbm4u9xikpqaSnJxM48aN5f2lSpWiYcOGco+EnZ0dbdq0oU6dOri5ueHq6kqXLl0oU6bMa+t35coVSpUqRYMGDeS0GjVqYGRkJG9fuHCB9PR0ypYtq3Ls06dPSUhIACAgIID+/fuzbt06nJ2d6dq1q0pMLwsJCSnwwQowwT4PXd3cQo4oWaY1zPvUVfhXiDhLnv9yrC+ujLRixQri4uKYOXMmFy9e5OLFi0Ue5+PjQ58+fQgODpbnYURFRankUVNT4+7du+zcubNAb+yjR4+4devWG63MZGZmxokTJwrk/euvv4DnN3Lu3bv3yjIMDQ2JiYmhdOnSclpsbCy6urpvvTrUy3GWVCLOjyczM/NfP2c+0bAQPiu3b9+mffv2DBkyhBkzZmBsbMyJEyfo168f2dnZcsPi5Q8phULxVmN51dXViYqK4uTJkxw8eJBFixYxfvx44uLisLKyeu840tPTMTc3JyYmpsC+/AZIcHAwvXr1Ys+ePezbt4/JkyezadMmOnbsWGiZQUFBBAQEyNtpaWlYWFjQqlWrAg2YkkSpVBIVFYWLi8s7DRUrLkScJU9x1EiM1wAAU/9JREFUiVWSJPz9/Tl//jzHjh17be8pPO9BVVNTo2bNmri4uBQa54ULFyhTpgwdOnQocPz8+fOxsrLCw8PjlefJzc0lMDCQtm3bFsibP3m7WbNm1KtX75Xl5Pe0vFjGrFmzcHFxeW0d8hWX1/N9iTg/vvwRB5+CaFgIn5X4+Hjy8vIIDQ1FTe352gU//fTTW5VhaGiIubk5cXFx8p20nJwc4uPjqV+/vpxPoVDQtGlTmjZtyqRJk6hcuTLbt29X+fJemBo1asjl5Q+FunbtGk+ePJHz1K9fn5SUFEqVKoWlpWWRZdnY2GBjY8OIESPo2bMnERERRTYstLS05GFVL9LQ0CjRb/75RJwly+cSJ/z3Yx06dCgbN25k586dGBsb8+jRI+D5e6mOjg6JiYls3rwZV1dXTExMuHv3LrNmzUJHRwdPT080NDQ4c+YMKSkpNG3aFG1tbaKiopg9ezajRo1SiT3/mRMZGRk8evSIP/74A01NTWrWrAnA1KlT+fLLL6lWrRpPnjxh7ty5JCUlMXDgQLmcv//+m6SkJLmXIjExEQ0NDcqXLy+vJtW3b18qVqxISEgIACNGjKBly5YsXLiQdu3asWnTJuLj41m5cuVbvzb/9dfzQxFxftxzfiqiYSGUWKmpqQUebFSuXDmUSiWLFi3C09OT2NjYd1oKcPjw4cyaNQtra2tq1KjB/PnzVb74x8XFcfjwYVxdXTE1NSUuLo4HDx6ozJMoSvXq1XF3d2fQoEEsW7aMUqVK4e/vj46OjpzH2dmZJk2a4OXlxZw5c7CxseHevXvs2bOHjh07UqtWLUaPHk2XLl2wsrLi7t27nD17ls6dO791rIIgCO9j2bJlwPO7+i+KiIjAx8cHbW1tjh8/TlhYGI8fP8bMzIwWLVpw8uRJTE1NUSqVlCpVimXLljFq1CgkSaJatWrMnz+fAQMGqJRpb28v/z8+Pp6NGzdSuXJluffh8ePHDBgwgJSUFMqUKUODBg04efKk3PAA2LVrF99884283aNHD+D55PHg4GAAkpKS5JtTAI6OjmzcuJEJEyYwbtw4rK2t2bFjR4EJ6oJQ0omGhVBixcTEqHzIAPTr14/58+cze/ZsgoKCaNGiBSEhIfTt2/etyh45ciTJycl4e3ujpqbGt99+S8eOHeVlFEuXLs2xY8cICwsjLS2NypUrExoaStu2bd+o/IiICPr370/Lli0xMzNj+vTpTJw4Ud6vUCjYu3cv48eP55tvvuHBgweUL1+eFi1aYGZmhrq6Oo8ePaJv37789ddflCtXjk6dOhU6h0IQBOFjet0w0goVKrx2HkL9+vWZMGHCa+/Evu5cCxYsYMGCBa/M4+Pjg4+PzyvzFDYMtWvXrnTt2vWVxwlCSaeQ3mURaEEQSry0tDQMDQ15+PBhiZ9jsXfvXjw8PEp0t7yIs+T5XGIVcZYsIs6PL//zOzU1VWVBgX+DeECeIAiCIAiCIAjvTTQsBEEQBEEQBEF4b6JhIQiCIAiCIAjCexMNC0EQBEEQBEEQ3ptoWAiCIAiCIAiC8N5Ew0IQBEEQBEEQhPcmGhbCf1ZkZCRGRkbydnBwMPXq1XvlMbdv30ahUBR4MN77UCgU7Nix44OVJwiC8DkJCQmhUaNGGBgYYGpqipeXF9euXVPJM2jQIKpWrYqOjg4mJiZ06NCBq1evFlreo0eP+OKLL1AoFCoPJgXIyspi/PjxVK5cGS0tLSwtLVmzZo28X6lUMnXqVKpWrYq2tjZ2dnbs379fpQxLS0sUCkWBH19f31fGuWXLFmrUqIG2tjZ16tR57bM5BKEkEg0L4aPy8fGR35Q1NTWpVq0aU6dOJScn563LGjVqFIcPH1Yp28vLSyWPhYUFycnJH/Vpp4V94DRr1uy9y/0YjSJBEIRP7ejRo/j6+nL69GmioqJQKpW4urqSkZEh52nQoAERERFcuXKFAwcOIEkSrq6u5ObmFiivX79+1K1bt9BzdevWjcOHD7N69WquXbvGjz/+SPXq1eX9EyZM4Pvvv2fRokVcvnyZwYMH07FjR86dOyfnOXv2LMnJyfJPVFQUwCsffnfy5El69uxJv379OHfuHF5eXnh5eXHp0qW3vl6CUJyJJ28LH527uzsRERFkZWWxd+9efH190dDQICgo6K3K0dfXR19f/5V51NXVKV++/PtU941ERETg7u4ub2tqan70c74NpVJZoh88JAhC8fFyj0BkZCSmpqbEx8fTokULAAYOHCjvt7S0ZPr06djZ2XH79m0qVaok71u2bBlPnjxh0qRJ7Nu3r8B5jh49SmJiIsbGxnJZL1q3bh3jx4/Hw8MDgCFDhnDo0CFCQ0NZv349ACYmJirHzJo1i6pVq9KyZcsiYwwPD8fd3Z3Ro0cDMG3aNKKioli8eDHLly9/7TUShJJC9FgIH52Wlhbly5encuXKDBkyBGdnZ3bt2sXjx4/p27cvZcqUQVdXl7Zt23Ljxo0iy3lxKFRwcDA//PADO3fulHsNYmJiCr3r/8cff9C+fXtKly6NgYEBzZs3JyEhgf9r797jerz/x48/OpdUTh0JOeV8Piyniihh2MGYTQ0ZY/RhhDk0bBkzx43ZIWMM2yy+NIRyCCFCDs2ZbXJoSA71rl6/P7p1/bxVRFLa8367ddP7ul7X63o+ryvv9/t1vV6v64KsK1OdOnWiQoUK2NjY4O7uzqFDh56YU5kyZXBwcNB+ypUrR1JSEn379qVixYqUKlWKBg0a8PPPP+ttl5mZycyZM6lRowZmZmZUrlyZTz/9FAAXFxcAmjRpgoGBAR4eHto2U6dOpVKlSpiZmdG4cWO9D+rsnFevXo27uzvm5uasWLGCixcv0r17d8qWLYulpSX16tWTrnkhRJG7ffs2gPbl/1F3794lNDQUFxcXnJ2dteUnTpxg6tSpLFu2DEPDnF9f1q9fT/PmzZk5cyYVK1akVq1afPTRR9y/f18rk5qairm5ud52FhYW7N69O9dY0tLS+OmnnxgwYAAGBgZ55rR37168vLz0lnl7e7N37948txGiJJIeC/HCWVhYkJSUhL+/P6dPn2b9+vVYW1sTFBSEr68vJ06ceOLV9o8++oiTJ0+SnJxMaGgokPUh9c8//+iV+/vvv2nfvj0eHh5s374da2troqOjtaFYd+7cwc/PjwULFqCUYvbs2fj6+nL69GmsrKyeKq8HDx7QrFkzgoKCsLa2ZuPGjbz77rtUr16dli1bAjB+/Hi+/fZb5syZQ9u2bbly5Yo2jnj//v20bNmSrVu3Uq9ePa0XZN68ecyePZtvvvmGJk2a8MMPP/Dqq69y/Phxatasqe1/3LhxzJ49myZNmmBubk5AQABpaWns3LkTS0tLTpw48dgen9TUVFJTU7XXycnJALT/fCvpJpZPdSxeJmaGimnNodnUTaRm5v3F4WUneZY8L0Ou8cHeeq8zMzMZOXIkrVu3xtXVFZ1Op61bvHgx48eP5+7du9SqVYvw8HAMDAzQ6XTodDreeecdQkJCcHR05M8//wTQ1gGcPXuW3bt3Y2Zmxi+//MKNGzcYMWIE169f57vvvgOgU6dOzJ49Gzc3N6pXr8727dtZu3YtGRkZerFk+/XXX7l16xb9+vXLdX22xMREypcvr1emQoUKJCYmPna7h2WXy2/5l5Xk+eL2XRSkYSFeGKUU27ZtY/PmzXTp0oWwsDCio6Np3bo1ACtWrMDZ2ZmwsLDHjmWFrGFRFhYWpKamPnbo01dffYWNjQ2rVq3SGiu1atXS1nfo0EGv/JIlSyhTpgw7duygW7duedbbt29fjIyMtNc//fQTPXv25KOPPtKWffjhh2zevJk1a9bQsmVL7ty5w7x581i4cCF+fn4AVK9eXZufkd39Xr58eb2cvvjiC4KCgujTpw8An3/+OZGRkcydO5evvvpKKxcYGMhrr72mvb506RKvv/46DRo0AKBatWp55gNZEyw/+eSTHMsnNsmkVKmc45xLmmnNM4s6hBdC8ix5inOuj/aSLl68mNjYWEJCQnKsK1++PLNmzeLmzZuEhYXRtWtXZsyYgampKcuXL6dMmTKULVuW8PBwjh07BsCWLVu0CyZXr15FKUW/fv24fv06AH369GHmzJl07doVMzMzfH19OX/+vPa+6ODggIeHB9u2bcu1R3fWrFk0adKEuLi4x85/U0oRFxeHtbW1tiw+Pl4bAvw0sud0lHSSZ+G5d+/eC99nNmlYiEK3YcMGSpcujU6nIzMzk7fffpvXXnuNDRs20KpVK61c+fLlcXV15eTJk89t33FxcbRr1y7PHpCrV68yceJEoqKiuHbtGhkZGdy7d49Lly49tt45c+bodXs7OjqSkZHBZ599xpo1a/j7779JS0sjNTWVUqVKAXDy5ElSU1Pp2LFjvuNPTk7mn3/+oU2bNnrL27Rpw5EjR/SWNW/eXO/1iBEjGDp0KFu2bMHLy4vXX389zwmPkNWbMmrUKL19Ozs7M/2wIekmRnlu97LLuuqbyaSDhsX2qu/zIHmWPC9Drg/3WIwcOZL4+Hh2796tDf3My8iRI7Gzs+PBgwd07dqVwMBA7WIJZH2RB/Dz82PcuHFMmTKFX3/9lZSUFL0LUy4uLnz++efUr19f6+Ht27cvDx48ICkpCScnJyZMmMCFCxe0eRfZLl68yNGjR1mzZk2OdY9ydHTEyclJr9yBAweoXLnyE7fNptPpiIiIoFOnTiV6jpzkWfiyRxwUBWlYiELn6enJokWLMDU1xcnJCWNjY9avX/9C9m1hYfHY9X5+fiQlJTFv3jzt9oRubm6kpaU9djsHBwdq1Kiht2zGjBnMmzePuXPn0qBBAywtLQkMDNTqelIsBWVpqT9cadCgQXh7e7Nx40a2bNlCSEgIs2fP5sMPP8x1ezMzM8zMzHIs3xnkRfny5Qsl5uJAp9MRHh5O7GSfEv8hJ3mWLC9LrkopPvzwQ9atW0dUVJTeEM68ZGZmopQiIyMDExMTgoKCaNWqlZbngQMHGDBgALt27aJ69eqYmJjQrl07fvvtN1JTU7VejPPnz2NoaIiLi4veMTIxMcHKygqdTkdYWBi9e/fOcQx/+ukn7Ozs6NGjB8bGj/+65ObmRlRUFKNHj9aWbd++ndatWz/1uTExMSnW5/N5kTwLd59FRSZvi0JnaWlJjRo1qFy5svbmXKdOHdLT04mJidHKJSUlkZCQQN26dfNVr6mpaa63InxYw4YN2bVrV57jDaOjoxkxYgS+vr7Uq1cPMzMzbty4kc/MctbVo0cP3nnnHRo1akS1atW0ccAANWvWxMLCQu+WuY/mA+jlZG1tjZOTE9HR0Tn2lZ/j5OzszJAhQ1i7di2jR4/m22+/fZbUhBDimQ0bNoyffvqJlStXYmVlRWJiIomJidqk6nPnzhESEkJsbCyXLl1iz549vPnmm1hYWGhX+x0dHalfv772k93jUadOHezs7AB4++23KV++PO+99x4nTpxg586djBkzhgEDBmgXdmJiYli7di3nzp1j165d+Pj4kJmZydixY/VizszMJDQ0FD8/v1wbFf3799e7s+HIkSPZtGkTs2fP5tSpUwQHB3Pw4EGGDx/+/A+oEMWYNCxEkahZsyY9evQgICCA3bt3c+TIEd555x0qVqxIjx498lVH1apVOXr0KAkJCdy4cSPXxsPw4cNJTk6mT58+HDx4kNOnT7N8+XLt4Uw1a9Zk+fLlnDx5kpiYGPr16/fMPQs1a9YkIiKCPXv2cPLkSd5//32uXr2qrTc3NycoKIixY8eybNkyzp49y759+/j+++8BsLOzw8LCgk2bNnH16lXtziljxozh888/Z/Xq1SQkJDBu3Dji4uIYOXLkY+MJDAxk8+bNnD9/nkOHDhEZGUmdOnWeKTchhHhWixYt4vbt23h4eODo6Kj9rF69Gsh6b9y1axe+vr7UqFGDt956CysrK/bs2aM1GvKjdOnSREREcOvWLZo3b06/fv3o3r078+fP18o8ePCAiRMnUrduXXr16kXFihXZvXu33sNYAbZu3cqlS5cYMGBArvu6dOkSV65c0V63bt2alStXsmTJEho1asSvv/5KWFhYoT5TSYjiSIZCiSITGhrKyJEj6datG2lpabRv357w8PB8d+EFBAQQFRVF8+bNSUlJITIyMsc9y8uXL8/27dsZM2YM7u7uGBkZ0bhxY23Owvfff8/gwYNp2rQpzs7OfPbZZ3oTsJ/GxIkTOXfuHN7e3pQqVYrBgwfTs2dPrYEAMGnSJIyNjZk8eTL//PMPjo6ODBkyBABjY2Pmz5/P1KlTmTx5Mu3atSMqKooRI0Zw+/ZtRo8ezbVr16hbty7r169/4nCCjIwMhg0bxl9//YW1tTU+Pj7MmTPnmXITQohnlT0fIi9OTk5PPcHZw8Mj13pr16792Mmy7u7unDhx4on1d+7c+bFxR0VF5Vj25ptvPvHGI0KUdAbqSf/jhRD/ScnJydjY2HDjxo3/xBwLX1/fEj3eV/Isef4ruUqeJYvkWfiyP79v376td6eyF0GGQgkhhBBCCCEKTBoWQgghhBBCiAKThoUQQgghhBCiwKRhIYQQQgghhCgwaVgIIYQQQgghCkwaFkIIIYR4rkJCQmjRogVWVlbY2dnRs2dP7flB2d5//32qV6+OhYUFtra29OjRg1OnTmnrjxw5Qt++falWrRq9e/emQYMGzJs3T6+OqKgoDAwMcvwkJiZqZXbu3En37t1xcnLCwMCAsLAwvTp0Oh1BQUE0aNAAS0tLnJyc6N+/P//8888T8/zqq6+oWrUq5ubmtGrViv379z/D0RKi5JCGhXjpeXh4EBgYWGzqEUKI/7odO3YwbNgw9u3bR0REBDqdjs6dO3P37l2tTLNmzQgNDeXkyZNs3rwZpRSdO3cmIyMDgNjYWOzs7Fi6dCnz589n3LhxjB8/noULF+bYX0JCAleuXNF+Hn6w3t27d2nUqBFfffVVrrHeu3ePQ4cOMWnSJA4dOsTatWtJSEjg1VdffWyOq1evZtSoUUyZMoVDhw7RqFEjvL29uXbt2rMcMiFKBHlAnigQf39/fvzxRwBMTEyoXLky/fv3Z8KECRgbF88/r6ioKDw9Pbl586be01bXrl373O81fe/ePaZNm8aaNWv4+++/sbKyom7duowaNSrfTxgXQoiXzaZNm/ReL126FDs7O2JjY2nfvj0AgwcP1tZXrVqV6dOn06hRIy5cuED16tW1p17rdDpSUlLw9fXlwIEDrF27luHDh+vVb2dnl+Pp2dm6dOlCly5d8ozVxsYmx0P1Fi5cSMuWLbl06RKVK1fOdbsvv/ySgIAA3nvvPQAWL17Mxo0b+eGHHxg3blye+xOiJJMeC1FgPj4+XLlyhdOnTzN69GiCg4OZNWtWUYf11MqVK4eVldVzrXPIkCGsXbuWBQsWcOrUKTZt2sQbb7xBUlLSc93Pw9LS0gqtbiGEeBa3b98Gst5nc3P37l1CQ0NxcXHB2dn5sfXkVkfjxo1xdHSkU6dOREdHP5d4DQwM8myspKWlERsbi5eXl7bM0NAQLy8v9u7dW+D9C/GyKp6XlMVLxczMDAcHBwCGDh3K77//zvr16xkyZAgjR47k//7v/0hNTcXd3Z358+dTs2ZNIOsKVmBgIEuXLmXMmDFcvnwZd3d3vvvuO+2Dxd/fn1u3bumNiQ0MDCQuLo6oqKhc41m+fDnz5s0jISEBS0tLOnTowNy5c7Gzs+PChQt4enoCULZsWQD8/PxYunQpHh4eNG7cmLlz5wJw8+bNfMW/evVqAgMDuXz5Mm3btiU0NBRHR0cA1q9fz7x58/D19QWyrso1a9ZML97U1FQmT57MypUruXbtGs7OzowfP56BAwcCWUMKxowZw5EjRyhXrhx+fn5Mnz5d6xHy8PCgfv36GBsb89NPP9GgQQMiIyOJj49nzJgx7Nq1C0tLSzp37sycOXOoUKHCU53fViHbSDe2fKptXiZmRoqZLaF+8GZSMwyKOpxCI3mWPMU11wszuuq9zszMJDAwkDZt2lC/fn29dV9//TVjx47l7t27uLq6EhERgampaa717t27l9WrV7Nx40ZtmaOjI4sXL6Z58+akpqby3Xff4eHhQUxMDE2bNn2m+B88eEBQUBB9+/bN86nFN27cICMjA3t7e73l9vb2evNEhPivkYaFeO4sLCxISkrC39+f06dPs379eqytrQkKCsLX15cTJ05oQ47u3bvHp59+yrJlyzA1NeWDDz6gT58+BbripNPpmDZtGq6urly7do1Ro0bh7+9PeHg4zs7O/Pbbb7z++uskJCRgbW2NhYVFrvXkN/4vvviC5cuXY2hoyDvvvMNHH33EihUrAHBwcCA8PJzXXnstz96Q/v37s3fvXubPn0+jRo04f/48N27cAODvv//G19cXf39/li1bxqlTpwgICMDc3Jzg4GCtjh9//JGhQ4dqx+3WrVt06NCBQYMGMWfOHO7fv09QUBC9e/dm+/btucaRmppKamqq9jo5ORkAM0OFkZF6ijPwcjEzVHr/llSSZ8lTXHPV6XR6r4cPH058fDyRkZE51vXu3RsPDw8SExP58ssvefPNN9mxYwfm5uZ69V28eJFBgwYxceJEPD09tXqqVatGtWrVtLItWrTgzJkzzJ49m6VLl+YaX3p6eo44Ht5X7969yczMZP78+Y8tl1tdGRkZKKXy3O5xsrd5lm1fJpLni9t3UZCGhXhulFJs27aNzZs306VLF8LCwoiOjqZ169YArFixAmdnZ8LCwnjzzTeBrD/+hQsX0qpVKyDrC3KdOnXYv38/LVu2fKY4ssflQtaHzvz582nRogUpKSmULl1a60Z/3Jjc7AZFfuJfvHgx1atXB7I+QKdOnarVs2TJEvr160f58uVp1KgRbdu25Y033qBNmzYA/Pnnn6xZs4aIiAitS/3hD8mvv/4aZ2dnFi5ciIGBAbVr1+aff/4hKCiIyZMnY2iYNZqxZs2azJw5U9tu+vTpNGnShM8++0xb9sMPP+Ds7Myff/5JrVq1cuQcEhLCJ598kmP5xCaZlCqVkdfhLjGmNc8s6hBeCMmz5CluuYaHh2u/L1myhJiYGD777DOOHj3K0aNH89zO39+fd955h+DgYG0eBsDly5eZPHkynTp1onHjxnr156Z8+fLExsbmWS42NjbX+XTp6enMmjWLq1evMnXqVHbv3p3nPnQ6HYaGhoSHh/Pvv/9qyw8fPoyBgcETY3ycR+d7lFSSZ+G5d+/eC99nNmlYiALbsGEDpUuXRqfTkZmZydtvv81rr73Ghg0btAYDZL3Zu7q6cvLkSW2ZsbExLVq00F7Xrl2bMmXKcPLkyWduWMTGxhIcHMyRI0e4efMmmZlZH7qXLl2ibt26+arj5MmTGBsbPzH+UqVKaY0KyOqWf/iOIO3bt+fcuXPs27ePPXv2sG3bNubNm8cnn3zCpEmTiIuLw8jICHd39zzjcHNzw8Dg/w9zaNOmDSkpKfz111/apMJHh1cdOXKEyMhISpcunaPOs2fP5tqwGD9+PKNGjdJeJycn4+zszPTDhqSbGOV5rF52ZoaKac0zmXTQkNTM4jOc5HmTPEue4pprfLA3Silt2OrOnTu1IaSPk5qaiqGhIXXr1tWGjx4/fpyAgAA8PT358ccf83WDjQULFlC7dm2tjkc1a9YsxzqdTkffvn25c+cO0dHR2NraPnE/zZo1Izk5WasrMzOTYcOGMXTo0Dz3/Tg6nY6IiAg6der03G8kUpxInoUve8RBUZCGhSgwT09PFi1ahKmpKU5OThgbG7N+/frnUrehoSFK6XfzP66L7+7du3h7e+Pt7c2KFSuwtbXl0qVLeHt7F8qk5kffLAwMDHLEa2JiQrt27WjXrh1BQUFMnz6dqVOnEhQUlOcwrKdlaak/ByIlJYXu3bvz+eef5yibPf/jUWZmZpiZmeVYvjPIi/Llyz+XOIsjnU5HeHg4sZN9SvyHnORZshTnXD/44ANWrlzJunXrKFeunHbDChsbGywsLDh37hyrV6+mc+fO2Nra8tdffzFjxgwsLCzo3r07JiYmxMfH07lzZzp16kSnTp1ISkrCxMQEIyMj7Yv/3LlzcXFxoV69ejx48IDvvvuOyMhItmzZoh2TlJQUzpw5o8V2+fJljh8/Trly5ahcubLWqDh06BAbNmzA0NBQi7dcuXLanI+OHTvSq1cv7Y5Uo0ePxs/Pj5YtW9KyZUvmzp3L3bt3GTRoUIHOh4mJSbE7n4VB8izcfRYVaViIArO0tKRGjRp6y+rUqUN6ejoxMTHaUKKkpCQSEhL0eg3S09M5ePCg1juRkJDArVu3qFOnDgC2trbEx8fr1R0XF5fnf5pTp06RlJTEjBkztAngBw8e1CuT/SGRfa/03OQ3/mdRt25d0tPTefDgAQ0aNCAzM5MdO3bo3V3k4Th+++03lFJar0V0dDRWVlZUqlQpz300bdqU3377japVqxbb2/4KIUquRYsWAVk3l3hYaGgo/v7+mJubs2vXLubOncvNmzext7enffv27NmzR3sGxa+//sr169dZuXIlK1eu1OqoUqUKFy5cALLuzjR69Gj+/vtvSpUqRcOGDdm6dat2kw7I+gx4+HV2z2z2jTv+/vtv7WJY48aN9eKNjIzUcjh79qw2/w3grbfe4vr160yePJnExEQaN27Mpk2bckzoFuK/RG43KwpFzZo16dGjBwEBAezevZsjR47wzjvvULFiRb3nN5iYmPDhhx8SExNDbGws/v7+vPLKK1pDo0OHDhw8eJBly5Zx+vRppkyZkqOh8bDKlStjamrKggULOHfuHOvXr2fatGl6ZapUqYKBgQEbNmzg+vXrpKSkPHP8T+Lh4cE333xDbGwsFy5cIDw8nAkTJuDp6Ym1tTVVq1bFz8+PAQMGEBYWxvnz54mKimLNmjVA1lW/y5cv8+GHH3Lq1CnWrVvHlClTGDVqlDa/IjfDhg3j33//pW/fvhw4cICzZ8+yefNm3nvvvcc2qIQQ4nlQSuX64+/vD4CTkxPh4eFcvXqVtLQ0Ll++zIoVK3B1ddXqCA4ORilFWloaYWFhpKWloZTSGhUAY8eO5cyZM9y/f5+kpCQiIyP1GhGQ9T6cWyzZk7urVq2aZ7wPN4wuXLigd9MMyJpXd/HiRVJTU4mJidEbPivEf5E0LEShCQ0NpVmzZnTr1g03NzeUUoSHh+v1NpQqVYqgoCDefvtt2rRpQ+nSpVm9erW23tvbm0mTJjF27FhatGjBnTt36N+/f577tLW1ZenSpfzyyy/UrVuXGTNm8MUXX+iVqVixIp988gnjxo3D3t4+x4OWnib+J/H29ubHH3+kc+fO1KlThw8//BBvb2+t4QBZV/beeOMNPvjgA2rXrk1AQID2dNqKFSsSHh7O/v37adSoEUOGDGHgwIFMnDjxsft1cnIiOjqajIwMOnfuTIMGDQgMDKRMmTKPbZAIIYQQQjwrA/XogHAhXpDs50DcunWrqEMRuUhOTsbGxoYbN278J+ZY+Pr6lujxvpJnyfNfyVXyLFkkz8KX/fl9+/btPJ/FUljk0qUQQgghhBCiwKRhIYQQQgghhCgwaViIIuPv7y/DoIQQQgghSghpWAghhBBCCCEKTBoWQgghhBBCiAKThoUQZN3nPDAwsND3ExwcnOMBTEIIUVKEhITQokULrKyssLOzo2fPniQkJOiVef/996levToWFhbY2trSo0cPTp06pVfm0qVLdO3alVKlSlGxYkWWLl1Kenp6rvuMjo7G2Ng4x3vrokWLaNiwIdbW1lhbW+Pm5sYff/zx1LE8SinF5MmTcXR0xMLCAi8vL06fPp3PIyREySYNC1FsLV68GCsrK70Pk5SUFExMTHI8zTUqKgoDAwPOnj372DqzyxWXuR3S0BBClCQ7duxg2LBh7Nu3j4iICHQ6HZ07d9aezQPQrFkzQkNDOXnyJJs3b0YpRefOnbWHd2ZkZNC1a1fS0tLYs2cP33//Pdu3b8/xcDqAW7du0b9/fzp27JhjXaVKlZgxYwaxsbEcPHiQDh060KNHD44fP57vWHIzc+ZM5s+fz+LFi4mJicHS0hJvb28ePHhQgCMnRMlgXNQBCJEXT09PUlJSOHjwIK+88goAu3btwsHBgZiYGB48eIC5uTkAkZGRVK5cmerVqxdlyEII8Z+2adMmvddLly7Fzs6O2NhY2rdvD8DgwYO19VWrVmX69Ok0atSICxcuUL16dbZs2cKJEyfYunUr9vb21KtXj7fffpvFixczbdo0TE1Nte2HDBnC22+/jZGREWFhYXr77t69u97rTz/9lEWLFrFv3z7q1auXr1gepZRi7ty5TJw4kR49egCwbNky7O3tCQsLo0+fPs9w1IQoOaTHQhRbrq6uODo6EhUVpS2LioqiR48euLi4sG/fPr3lnp6eZGZmEhISgouLCxYWFjRq1Ihff/0VgAsXLuDp6QlA2bJlMTAwwN/fP9d9L1++nObNm2NlZYWDgwNvv/02165d09ufgYEB27Zto3nz5pQqVYrWrVvn6PKfMWMG9vb2WFlZMXDgwKe+onXs2DE6dOiAhYUF5cuXZ/DgwaSkpOjF0bJlSywtLSlTpgxt2rTh4sWLABw5cgRPT0+srKywtramWbNmHDx48Kn2L4QQBXH79m0AypUrl+v6u3fvEhoaiouLC87OzgDs3buXBg0aYG9vr5Vr0qQJycnJer0NoaGhnDt3jilTpjwxjoyMDFatWsXdu3dxc3PLdyyPOn/+PImJiXh5eWnLbGxsaNWqFXv37n1iHEKUdNJjIYo1T09PIiMjGTduHJDVMzF27FgyMjKIjIzEw8OD+/fvExMTw4ABAwgJCeGnn35i8eLF1KxZk507d/LOO+9ga2tL27Zt+e2333j99ddJSEjA2toaCwuLXPer0+mYNm0arq6uXLt2jVGjRuHv7094eLheuY8//pjZs2dja2vLkCFDGDBgANHR0QCsWbOG4OBgvvrqK9q2bcvy5cuZP38+1apVy1fud+/exdvbGzc3Nw4cOMC1a9cYNGgQw4cP18Yb9+zZk4CAAH7++WfS0tLYv38/BgYGAPTr148mTZqwaNEijIyMiIuLe6anf7YK2Ua6seVTb/eyMDNSzGwJ9YM3k5phUNThFBrJs+QpbrlemNFV73VmZiaBgYG0adOG+vXr6637+uuvGTt2LHfv3sXV1ZWIiAitJyIxMVGvUQFQpkwZbR3A6dOnGTduHLt27cLYOO+vMseOHcPNzY0HDx5QunRpfv/9d+rWrZvvWB6Vvf9H47O3t9fWCfFfJg0LUax5enoSGBhIeno69+/f5/Dhw7i7u6PT6Vi8eDGQdXUrNTUVDw8P6taty9atW7UrUtWqVWP37t188803uLu7a1fN7OzstA+q3AwYMED7vVq1asyfP58WLVqQkpJC6dKltXWffvop7u7uAIwbN46uXbtqQ7Tmzp3LwIEDGThwIADTp09n69at+e61WLlyJQ8ePGDZsmVYWmZ9sV+4cCHdu3fn888/x8TEhNu3b9OtWzety75OnTra9pcuXWLMmDHUrl0bgJo1az52f6mpqaSmpmqvk5OTATAzVBgZqXzF/DIyM1R6/5ZUkmfJU9xy1el0eq+HDx9OfHw8kZGROdb17t0bDw8PEhMT+fLLL3nzzTfZsWMH5ubmZGZmopTStnl42/T0dB48eEDfvn2ZPHkyLi4u6HQ6MjIy9LbJVq1aNQ4cOEBycjK//fYbfn5+bN26Va9x8bhYHpU950+n0+ntKzMzEwMDgxz7fxq55VsSSZ4vbt9FQRoWoljz8PDg7t27HDhwgJs3b1KrVi1sbW1xd3fnvffe48GDB0RFRVGtWjVSUlK4d+8enTp10qsjLS2NJk2aPNV+Y2NjCQ4O5siRI9y8eZPMzEwg68v6wx9IDRs21H53dHQE4Nq1a1SuXJmTJ08yZMgQvXrd3NyIjIzMVwwnT56kUaNGWqMCoE2bNmRmZpKQkED79u3x9/fH29ubTp064eXlRe/evbU4Ro0axaBBg1i+fDleXl68+eabj52DEhISwieffJJj+cQmmZQqlfdExpJiWvPMog7hhZA8S57ikuvDPbpLliwhJiaGzz77jKNHj3L06NE8t/P39+edd94hODiY9u3bc+fOHU6fPq1XX/YNN86cOUNycjKxsbEcPnyYESNGAFlzH5RSmJubExwcrPfenK1NmzZs3ryZsWPH8sEHH+Qrlkdl90r89ttver3Pp06dwsXFJUev9rOIiIgocB0vA8mz8Ny7d++F7zObNCxEsVajRg0qVapEZGQkN2/e1HoHnJyccHZ2Zs+ePURGRtKhQwdt7sHGjRupWLGiXj1mZmb53mf2ECRvb29WrFiBra0tly5dwtvbm7S0NL2yDw8tyh6ClN0IeRFCQ0MZMWIEmzZtYvXq1UycOJGIiAheeeUVgoODefvtt9m4cSN//PEHU6ZMYdWqVfTq1SvXusaPH8+oUaO018nJyTg7O+Pp6Un58uVfVEovnE6nIyIigk6dOj3TULGXheRZ8hTHXJVSBAYGEhcXx86dO5/YUwpZvaWGhobUrVsXX19fDA0N+fXXX2nevDl2dnbodDo++ugjrK2tCQgIwMTEJMdwpm+++YbIyEhWrVqFi4uL3gWZh82dOxd7e3t8fX3zFUtu+QUHB6PT6bT1ycnJnDlzhnHjxuVZb34Ux/NZGCTPwpc94qAoSMNCFHuenp5ERUVx8+ZNxowZoy1v3749f/zxB/v372fo0KHUrVsXMzMzLl26pDVAHpU9bvZxtxI8deoUSUlJzJgxQ5vA9yyTnuvUqUNMTAz9+/fXlj084Tw/2y9dupS7d+9qH5LR0dEYGhri6uqqlWvSpAlNmjRh/PjxuLm5sXLlSu0uWrVq1aJWrVr873//o2/fvoSGhubZsDAzM8u1AWZiYlKi3/yzSZ4ly38lTyheuX7wwQesXLmSdevWUa5cOZKSkoCsCc4WFhacO3eO1atX07lzZ2xtbfnrr7+YMWMGFhYWdO/eHRMTE3x9falbty4DBgxg5syZ/PXXX6xcuZIhQ4ZoQ1Ef7YV2cHDAwsJCb/n48ePp0qULlStX5s6dO6xcuZIdO3awefNmTExM8hULQO3atQkJCdHeOwMDAwkJCaF27dq4uLgwadIknJyceOONN57LeShO57MwSZ6Fu8+iIg0LUex5enoybNgwdDqdXoPB3d2d4cOHk5aWpt396KOPPuJ///sfmZmZtG3bltu3bxMdHY21tTV+fn5UqVIFAwMDNmzYgK+vLxYWFnpzJgAqV66MqakpCxYsYMiQIcTHxzNt2rSnjnvkyJH4+/vTvHlz2rRpw4oVKzh+/HiOydv3798nLi5Ob5mVlRX9+vVjypQp+Pn5ERwczPXr1/nwww959913sbe35/z58yxZsoRXX30VJycnEhISOH36NP379+f+/fuMGTOGN954AxcXF/766y8OHDjA66+//tR5CCFEfi1atAggx7OGQkND8ff3x9zcnF27djF37lxu3ryJvb097du3Z8+ePdjZ2QFgZGTEhg0bGDp0KG5ublhaWuLh4ZHrcywe59q1a/Tv358rV65gY2NDw4YN2bx5szZcNj+xACQkJGh3twK0id6DBw/m1q1btG3blk2bNuU6J0OI/xwlRDF3/vx5BajatWvrLb9w4YIClKurq7YsMzNTzZ07V7m6uioTExNla2urvL291Y4dO7QyU6dOVQ4ODsrAwED5+fkppZRyd3dXI0eO1MqsXLlSVa1aVZmZmSk3Nze1fv16BajDhw8rpZSKjIxUgLp586a2zeHDhxWgzp8/ry379NNPVYUKFVTp0qWVn5+fGjt2rGrUqJG2fsqUKQrI8dOxY0ellFJHjx5Vnp6eytzcXJUrV04FBASoO3fuKKWUSkxMVD179lSOjo7K1NRUValSRU2ePFllZGSo1NRU1adPH+Xs7KxMTU2Vk5OTGj58uLp//36+j/vt27cVoG7cuJHvbV5GaWlpKiwsTKWlpRV1KIVK8ix5/iu5Sp4li+RZ+LI/v2/fvv3C922glCoet5MQQhQrycnJ2NjYcOPGjRI/xyI8PBxfX98S3S0veZY8/5VcJc+SRfIsfNmf37dv38ba2vqF7lsekCeEEEIIIYQoMGlYCCGEEEIIIQpMGhZCCCGEEEKIApOGhRBCCCGEEKLApGEhhBBCCCGEKDBpWAghhBCiQEJCQmjRogVWVlbY2dnRs2dPEhIStPX//vsvH374Ia6urlhYWFC5cmVGjBih93wIgG3bttG6dWusrKxwcHAgKCiI9PR0vTJHjx6lXbt2mJub4+zszMyZM3PE88svv1C7dm3Mzc1p0KAB4eHheuuVUkyePBlHR0csLCzw8vLi9OnTT8zzq6++omrVqpibm9OqVSv279//NIdJiBJPGhYvCQ8PDwIDA4ts/8HBwTRu3LjI9v+w6OhoGjRogImJCT179izqcIQQ4j9vx44dDBs2jH379hEREYFOp6Nz587cvXsXgH/++Yd//vmHL774gvj4eJYuXcqmTZsYOHCgVseRI0fw9fXFx8eHw4cPs3r1atavX8/HH3+slUlOTqZz585UqVKF2NhYZs2aRXBwMEuWLNHK7Nmzh759+zJw4EAOHz5Mz5496dmzJ/Hx8VqZmTNnMn/+fBYvXkxMTAyWlpZ4e3vz4MGDPHNcvXo1o0aNYsqUKRw6dIhGjRrh7e3NtWvXnuehFOLl9sKfnFHM+fn5aQ8pMzY2VnZ2dsrLy0t9//33KiMjI9/1TJkyRe9BaAWVlJSkkpOTn1t9jwOo33//XW/ZnTt3CuVBaVWqVFFz5sx5qm1atmyp3nnnHXX58mW9B9Q9b48+NK8wZT8EMPsBfMWBPCCvZJE8S57inOu1a9cUoPdw0ketWbNGmZqaKp1Op5RSavz48ap58+Z6ZdavX6/Mzc3Vzz//rNLS0tTXX3+typYtq1JTU7UyQUFBeg9K7d27t+ratatePa1atVLvv/++UirrQaoODg5q1qxZ2vpbt24pMzMz9fPPP+cZb8uWLdWwYcO01xkZGcrJyUmFhIQ87lDkW3E+n8+T5Fn4ivIBedJjkQsfHx+uXLnChQsX+OOPP/D09GTkyJF069YtR5dsYUtLSwOgXLlyWFlZPXM9GRkZZGZmPvP2pUuXLjYPSTt79iwdOnSgUqVKlClTJsd6pdQLO08vcl/5lf03I4QQRSV7iFO5cuUeW8ba2hpjY2MAUlNTMTc31ytjYWHBgwcPOHPmDAB79+6lffv2mJqaamW8vb1JSEjg5s2bWhkvLy+9ery9vdm7dy8A58+fJzExUa+MjY0NrVq10so8Ki0tjdjYWL1tDA0N8fLyynMbIf6LjIs6gOLIzMwMBwcHACpWrEjTpk155ZVX6NixI0uXLmXQoEHcunWLjz76iHXr1pGamkrz5s2ZM2cOjRo1YunSpXzyyScAGBgYABAaGoq/v/9jt4OsIUdhYWEMHz6cTz/9lIsXL5KZmYmHhweNGzdm7ty5ANy8eZORI0fyf//3f6SmpuLu7s78+fOpWbMmAEuXLiUwMJBly5Yxbtw4/vzzT86cOcP169eZMGEChw8fRqfT0bhxY+bMmUPTpk0BqFq1KgC9evUCoEqVKly4cEGLKy4uDkDLpW3btsyePZu0tDT69OnD3LlztSdMXrlyhUGDBrF9+3YcHBz49NNPmTBhAoGBgXkO6zIwMODbb79l48aNbN68mYoVKzJ79mxeffVVLly4gIuLCwADBgxgwIABhIaGUrVqVTw9PQkPD2fixIkcO3aMLVu24OzszKhRo9i3bx93796lTp06hISE6H0wfP3118yZM4fLly9jY2NDu3bt+PXXX/H392fHjh3s2LGDefPmAVkfRhcuXMh1X0uXLuXWrVuEhYVpdQcGBhIXF0dUVBQAmZmZfPHFFyxZsoTLly9jb2/P+++/z8cff6zl1aRJEwDc3d2JiorKcd4BevbsSZkyZVi6dKl2zgYOHMjp06cJCwvjtddeY+nSpezevZvx48dz8OBBKlSoQK9evQgJCcHS0vIJ/wP0tQrZRrrx023zMjEzUsxsCfWDN5OaYVDU4RQaybPkKS65XpjRVe91ZmYmgYGBtGnThvr16+e6zY0bN5g2bRqDBw/Wlnl7ezN37lx+/vlnevfuTWJiIlOnTgXQGg2JiYna+2U2e3t7bV3ZsmVJTEzUlj1cJjExUSv38Ha5lckt3oyMjFy3OXXqVK7bCPFfJA2LfOrQoQONGjVi7dq1DBo0iDfffBMLCwv++OMPbGxs+Oabb+jYsSN//vknb731FvHx8WzatImtW7cCWVdDgMdul31l58yZM/z222+sXbsWIyOjXOPx9/fn9OnTrF+/Hmtra4KCgvD19eXEiRPaF/t79+7x+eef891331G+fHns7Ow4d+4cfn5+LFiwAKUUs2fPxtfXl9OnT2NlZcWBAwews7MjNDQUHx+fPPcPEBkZiaOjI5GRkZw5c4a33nqLxo0bExAQAED//v25ceMGUVFRmJiYMGrUqHyNRf3kk0+YOXMms2bNYsGCBfTr14+LFy/i7OzMlStXcHV1ZerUqbz11lvY2NgQExMDwLhx4/jiiy+oVq0aZcuW5fLly/j6+vLpp59iZmbGsmXL6N69OwkJCVSuXJmDBw8yYsQIli9fTuvWrfn333/ZtWsXAPPmzePPP/+kfv362gebra0tFy5cyHVf+TF+/Hi+/fZb5syZQ9u2bbly5Yr2gbR//35atmzJ1q1bqVevnt7VuPz44osvmDx5MlOmTAGyenV8fHyYPn06P/zwA9evX2f48OEMHz6c0NDQXOtITU0lNTVVe52cnAyAmaHCyEg9VTwvEzNDpfdvSSV5ljzFJVedTqf3evjw4cTHxxMZGZljHWS9t/j6+lKnTh0+/vhjrYynpyczZsxgyJAhvPvuu5iZmTFhwgR27dqFoaEhOp0OpRSZmZl69Wb/rtPptN/T09P1ymRkZGhlsnuZHy4PWQ0iAwODXGN+XL1KqVy3eVoP51GSSZ4vbt9FQRoWT6F27docPXqU3bt3s3//fq5du4aZmRmQ9cUuLCyMX3/9lcGDB1O6dGmMjY21ng8gX9tBVpfrsmXLsLW1zTWO7AZFdHQ0rVu3BmDFihU4OzsTFhbGm2++CWT9YX399ddabwhkNZAetmTJEsqUKcOOHTvo1q2bts8yZcroxZ6bsmXLsnDhQoyMjKhduzZdu3Zl27ZtBAQEcOrUKbZu3cqBAwdo3rw5AN99953Wo/I4/v7+9O3bF4DPPvuM+fPns3//fnx8fHBwcMDAwAAbG5sc8U2dOpVOnTppr8uVK6eX+7Rp0/j9999Zv349w4cP59KlS1haWtKtWzesrKyoUqWK1mNgY2ODqakppUqVyvU4PLqvJ7lz5w7z5s1j4cKF+Pn5AVC9enXatm0LoB338uXLP/G456ZDhw6MHj1aez1o0CD69eun9QzVrFmT+fPn4+7uzqJFi3IMN4Csu7pk97Q9bGKTTEqVynjqmF4205o/+1DBl4nkWfIUda4P33FpyZIlxMTE8Nlnn3H06FGOHj2qV/b+/fsEBwdjZmbGwIEDiYiI0Ftfq1YtfvzxR27evImlpaV2Mcre3p6IiAjS09M5evSo3j6PHTum/Xv+/HlsbGyIiorC2tpaKxMdHU2pUqUIDw/XeiV+++03qlWrppU5deoULi4uOe4gBVmfp4aGhoSHh/Pvv/9qyw8fPoyBgUGu2zyrR49JSSV5Fp579+698H1mk4bFU1BKYWBgwJEjR0hJSckx5+D+/fucPXs2z+3zu12VKlXybFQAnDx5EmNjY1q1aqUtK1++PK6urpw8eVJbZmpqSsOGDfW2vXr1KhMnTiQqKopr166RkZHBvXv3uHTp0uOTz0W9evX0ejQcHR21N/iEhASMjY21IVYANWrUyNfV/YdjtrS0xNraOl89HdkNmGwpKSkEBwezceNGrly5Qnp6Ovfv39dy7dSpE1WqVKFatWr4+Pjg4+NDr169KFWq1FPv60lOnjxJamoqHTt2fKrt8uvReI4cOcLRo0dZsWKFtiz7St/58+epU6dOjjrGjx/PqFGjtNfJyck4Ozsz/bAh6SZ591y97MwMFdOaZzLpoCGpmSV36IzkWfIUl1zjg71RSmnDP3fu3JnrRaTk5GS6du2Kvb0969evz9d7bXBwMJUqVaJatWp06tSJy5cvM3nyZDp16qT1zu/Zs4datWrRu3dvIOsuiomJifj6+mr1zJgxg06dOuHr64tSiuDgYHQ6nVYmOTmZM2fOMG7cOL3tHtasWTOttwWyejiGDRvG0KFD89zmaeh0OiIiIvRyK4kkz8KXPeKgKEjD4imcPHkSFxcXUlJScHR01MbOPyy3ycTZ8rvd046Bz4uFhYU2xyObn58fSUlJzJs3jypVqmBmZoabm9szTfh99D+KgYFBgSaIF7TeR4/bRx99REREBF988QU1atTAwsKCN954Q8vVysqKQ4cOERUVxZYtW5g8eTLBwcEcOHDgsecxt30ZGhqilP5whIe7Ii0sLJ4Yf26eVG9e8aSkpPD+++8zYsSIHGUrV66c677MzMy0nrSH7QzyKjYT9wuDTqcjPDyc2Mk+Jf5DTvIsWYpTrh988AErV65k3bp1lCtXjqSkJCCr99fCwkJrVNy7d48VK1Zw//597t+/D2T12GZfpJo1axY+Pj4YGhqydu1aZs2axcqVKzEyMsLExIR3332X6dOnM2TIEIKCgoiPj2fhwoXMmTNHOwb/+9//tHmHXbt2ZdWqVcTGxvLtt99qZQIDAwkJCaF27dq4uLgwadIknJyceOONN7QyHTt2pFevXgwfPhyA0aNH4+fnR8uWLWnZsiVz587l7t27DBo06LkefxMTkyI/ny+C5Fm4+ywq0rDIp+3bt3Ps2DH+97//UalSJRITEzE2NtYmOz/K1NRUG9OZrWnTpk/cLj/q1KlDeno6MTEx2lCopKQkEhISqFu37mO3jY6O5uuvv9aurly+fJkbN27olTExMckR+9NydXUlPT2dw4cP06xZMyBr7kj2BLwXITo6Gn9/f20iekpKijZHIpuxsTFeXl54eXkxZcoUypQpw/bt23nttddyPYd5sbW11btHOkBcXJz2n7tmzZpYWFiwbds2Bg0alGP77DkVj+7P1taWK1euaK8zMjKIj4/H09PzsfE0bdqUEydOUKNGjXzFL4QQBbFo0SIgq7fgYdk3Ljl06JA2H+7R96Xz589rn4l//PEHn376KampqTRq1Ih169bh5eWlDTWysbFhy5YtDBs2jGbNmlGhQgUmT56sNwm8devWrFy5kokTJzJhwgRq1qxJWFiY3kTysWPHcvfuXQYPHqzdiGTTpk16w0TPnj2r9/n41ltvcf36dSZPnkxiYiKNGzdm06ZNOSZ0C/FfJg2LXKSmppKYmEhGRgZXr15l06ZNhISE0K1bN/r374+hoSFubm707NmTmTNnUqtWLf755x82btxIr169aN68OVWrVuX8+fPExcVRqVIlrKys8PLyeuJ2+VGzZk169OhBQEAA33zzDVZWVowbN46KFSvSo0ePJ267fPlymjdvTnJyMmPGjMlxNb1q1aps27aNNm3aYGZmlu/JyQ+rXbs2Xl5eDB48mEWLFmFiYsLo0aNz7UUpLDVr1mTt2rV0794dAwMDJk2apNfzsWHDBs6dO0f79u0pW7Ys4eHhZGZm4urqCmQdh5iYGC5cuEDp0qUfe9vEDh06MGvWLJYtW4abmxs//fQT8fHx2pwNc3NzgoKCGDt2LKamprRp04br169z/PhxBg4ciJ2dHRYWFmzatIlKlSphbm6OjY0NHTp0YNSoUWzcuJHq1avz5ZdfcuvWrSfmHhQUxCuvvMLw4cMZNGgQlpaWnDhxgoiICBYuXFiwAyuEEI94tGf1UR4eHk8sA1kX8R71aC9tw4YNtRtt5OXNN9/U5hvmxsDAgKlTp2o358jNoxeiAO0mGEKI3MlzLHKxadMmHB0dqVq1Kj4+PkRGRjJ//nzWrVuHkZGRNlGrffv2vPfee9SqVYs+ffpw8eJF7crF66+/jo+PD56entja2vLzzz/na7v8Cg0NpVmzZnTr1g03NzeUUoSHhz+x++v777/n5s2bNG3alHfffZcRI0ZgZ2enV2b27NlERETg7OysfTF+FsuWLcPe3p727dvTq1cvAgICsLKyynXicGH48ssvKVu2LK1bt6Z79+54e3vrzfkoU6YMa9eupUOHDtSpU4fFixfz888/U69ePSBrKJWRkRF169bF1tb2sfNQvL29mTRpEmPHjqVFixbcuXOH/v3765WZNGkSo0ePZvLkydSpU4e33npLmztibGzM/Pnz+eabb3ByctIaiAMGDMDPz4/+/fvj7u5OtWrVnthbAVkfvDt27ODPP/+kXbt2NGnShMmTJ+Pk5PTUx1EIIYQQIj8MVH4uIQjxHPz11184OzuzdevWQpvELJ6f5ORkbGxsuHHjxn9ijoWvr2+JHu8reZY8/5VcJc+SRfIsfNmf39kPoXyRZCiUKDTbt28nJSWFBg0acOXKFcaOHUvVqlVp3759UYcmhBBCCCGeM2lYiEKj0+mYMGEC586dw8rKitatW7NixYoSfYVCCCGEEOK/ShoWotB4e3vj7e1d1GEIIYQQQogXQCZvCyGEEEIIIQpMGhZCCCGEEEKIApOGhRBCCCGEEKLApGEhhBBCCCGEKDBpWAghhBBCCCEKTBoWQgghhBBCiAKThoUQQgghhBCiwOQ5FkKIXCmlALhz506JfqihTqfj3r17JCcnS54lwH8lT/jv5Cp5liySZ+FLTk4G/v/n+IskDQshRK6SkpIAcHFxKeJIhBBCCPG07ty5g42NzQvdpzQshBC5KleuHACXLl164W9ML1JycjLOzs5cvnwZa2vrog6n0EieJc9/JVfJs2SRPAufUoo7d+7g5OT0QvcL0rAQQuTB0DBrCpaNjU2JfvPPZm1tLXmWIP+VPOG/k6vkWbJInoWrqC4IyuRtIYQQQgghRIFJw0IIIYQQQghRYNKwEELkyszMjClTpmBmZlbUoRQqybNk+a/kCf+dXCXPkkXyLNkMVFHci0oIIYQQQghRokiPhRBCCCGEEKLApGEhhBBCCCGEKDBpWAghhBBCCCEKTBoWQgghhBBCiAKThoUQIldfffUVVatWxdzcnFatWrF///6iDgmA4OBgDAwM9H5q166trX/w4AHDhg2jfPnylC5dmtdff52rV6/q1XHp0iW6du1KqVKlsLOzY8yYMaSnp+uViYqKomnTppiZmVGjRg2WLl2aI5bnfYx27txJ9+7dcXJywsDAgLCwML31SikmT56Mo6MjFhYWeHl5cfr0ab0y//77L/369cPa2poyZcowcOBAUlJS9MocPXqUdu3aYW5ujrOzMzNnzswRyy+//ELt2rUxNzenQYMGhIeHP3Usz5qnv79/jnPs4+PzUuUZEhJCixYtsLKyws7Ojp49e5KQkKBXpjj9reYnlmfN08PDI8f5HDJkyEuVJ8CiRYto2LCh9sAzNzc3/vjjj6equyTkWVLO56NmzJiBgYEBgYGBT1X/y5hroVJCCPGIVatWKVNTU/XDDz+o48ePq4CAAFWmTBl19erVog5NTZkyRdWrV09duXJF+7l+/bq2fsiQIcrZ2Vlt27ZNHTx4UL3yyiuqdevW2vr09HRVv3595eXlpQ4fPqzCw8NVhQoV1Pjx47Uy586dU6VKlVKjRo1SJ06cUAsWLFBGRkZq06ZNWpnCOEbh4eHq448/VmvXrlWA+v333/XWz5gxQ9nY2KiwsDB15MgR9eqrryoXFxd1//59rYyPj49q1KiR2rdvn9q1a5eqUaOG6tu3r7b+9u3byt7eXvXr10/Fx8ern3/+WVlYWKhvvvlGKxMdHa2MjIzUzJkz1YkTJ9TEiROViYmJOnbs2FPF8qx5+vn5KR8fH71z/O+//+qVKe55ent7q9DQUBUfH6/i4uKUr6+vqly5skpJSdHKFKe/1SfFUpA83d3dVUBAgN75vH379kuVp1JKrV+/Xm3cuFH9+eefKiEhQU2YMEGZmJio+Pj4fNVdUvIsKefzYfv371dVq1ZVDRs2VCNHjsx3/S9jroVNGhZCiBxatmyphg0bpr3OyMhQTk5OKiQkpAijyjJlyhTVqFGjXNfdunVLmZiYqF9++UVbdvLkSQWovXv3KqWyvtQaGhqqxMRErcyiRYuUtbW1Sk1NVUopNXbsWFWvXj29ut966y3l7e2tvS7sY/ToF+7MzEzl4OCgZs2apZevmZmZ+vnnn5VSSp04cUIB6sCBA1qZP/74QxkYGKi///5bKaXU119/rcqWLavlqpRSQUFBytXVVXvdu3dv1bVrV714WrVqpd5///18x/KseSqV1bDo0aNHntu8jHleu3ZNAWrHjh1aPcXlbzU/sTxrnkplfRF9+Mvao17GPLOVLVtWfffddyX2fD6ap1Il73zeuXNH1axZU0VEROjlVtLPaWGRoVBCCD1paWnExsbi5eWlLTM0NMTLy4u9e/cWYWT/3+nTp3FycqJatWr069ePS5cuARAbG4tOp9OLvXbt2lSuXFmLfe/evTRo0AB7e3utjLe3N8nJyRw/flwr83Ad2WWy6yiKY3T+/HkSExP19mljY0OrVq30citTpgzNmzfXynh5eWFoaEhMTIxWpn379piamurllpCQwM2bN7Uyj8s/P7EUVFRUFHZ2dri6ujJ06FCSkpK0dS9jnrdv3wagXLlyQPH6W81PLM+aZ7YVK1ZQoUIF6tevz/jx47l375627mXMMyMjg1WrVnH37l3c3NxK7Pl8NM9sJel8Dhs2jK5du+aIp6Se08JmXNQBCCGKlxs3bpCRkaH3Rglgb2/PqVOniiiq/69Vq1YsXboUV1dXrly5wieffEK7du2Ij48nMTERU1NTypQpo7eNvb09iYmJACQmJuaaW/a6x5VJTk7m/v373Lx584Ufo+zYctvnw3Hb2dnprTc2NqZcuXJ6ZVxcXHLUkb2ubNmyeeb/cB1PiqUgfHx8eO2113BxceHs2bNMmDCBLl26sHfvXoyMjF66PDMzMwkMDKRNmzbUr19fq7u4/K3mJ5ZnzRPg7bffpkqVKjg5OXH06FGCgoJISEhg7dq1L12ex44dw83NjQcPHlC6dGl+//136tatS1xcXIk6n3nlCSXrfK5atYpDhw5x4MCBHOtK4v/RF0EaFkKIl0qXLl203xs2bEirVq2oUqUKa9aswcLCoggjE89Lnz59tN8bNGhAw4YNqV69OlFRUXTs2LEII3s2w4YNIz4+nt27dxd1KIUqrzwHDx6s/d6gQQMcHR3p2LEjZ8+epXr16i86zAJxdXUlLi6O27dv8+uvv+Ln58eOHTuKOqznLq8869atW2LO5+XLlxk5ciQRERGYm5sXdTglhgyFEkLoqVChAkZGRjnuNnH16lUcHByKKKq8lSlThlq1anHmzBkcHBxIS0vj1q1bemUejt3BwSHX3LLXPa6MtbU1FhYWRXKMsut93D4dHBy4du2a3vr09HT+/fff55L/w+ufFMvzVK1aNSpUqMCZM2e0/b8seQ4fPpwNGzYQGRlJpUqVtOXF6W81P7E8a565adWqFYDe+XxZ8jQ1NaVGjRo0a9aMkJAQGjVqxLx580rc+cwrz9y8rOczNjaWa9eu0bRpU4yNjTE2NmbHjh3Mnz8fY2Nj7O3tS9Q5fVGkYSGE0GNqakqzZs3Ytm2btiwzM5Nt27bpjbEtLlJSUjh79iyOjo40a9YMExMTvdgTEhK4dOmSFrubmxvHjh3T+2IaERGBtbW11tXv5uamV0d2mew6iuIYubi44ODgoLfP5ORkYmJi9HK7desWsbGxWpnt27eTmZmpffi7ubmxc+dOdDqdXm6urq6ULVtWK/O4/PMTy/P0119/kZSUhKOj40uTp1KK4cOH8/vvv7N9+/Ycw7KK099qfmJ51jxzExcXB6B3Pot7nnnJzMwkNTW1xJzPJ+WZm5f1fHbs2JFjx44RFxen/TRv3px+/fppv5fkc1poinr2uBCi+Fm1apUyMzNTS5cuVSdOnFCDBw9WZcqU0bvzRVEZPXq0ioqKUufPn1fR0dHKy8tLVahQQV27dk0plXVLvsqVK6vt27ergwcPKjc3N+Xm5qZtn317wM6dO6u4uDi1adMmZWtrm+vtAceMGaNOnjypvvrqq1xvD/i8j9GdO3fU4cOH1eHDhxWgvvzyS3X48GF18eJFpVTWrU/LlCmj1q1bp44ePap69OiR6+1mmzRpomJiYtTu3btVzZo19W7DeuvWLWVvb6/effddFR8fr1atWqVKlSqV4zasxsbG6osvvlAnT55UU6ZMyfU2rE+K5VnyvHPnjvroo4/U3r171fnz59XWrVtV06ZNVc2aNdWDBw9emjyHDh2qbGxsVFRUlN5tOe/du6eVKU5/q0+K5VnzPHPmjJo6dao6ePCgOn/+vFq3bp2qVq2aat++/UuVp1JKjRs3Tu3YsUOdP39eHT16VI0bN04ZGBioLVu2lJjz+aQ8S9L5zM2jd7wqKef0RZKGhRAiVwsWLFCVK1dWpqamqmXLlmrfvn1FHZJSKus2fY6OjsrU1FRVrFhRvfXWW+rMmTPa+vv376sPPvhAlS1bVpUqVUr16tVLXblyRa+OCxcuqC5duigLCwtVoUIFNXr0aKXT6fTKREZGqsaNGytTU1NVrVo1FRoamiOW532MIiMjFZDjx8/PTymVdfvTSZMmKXt7e2VmZqY6duyoEhIS9OpISkpSffv2VaVLl1bW1tbqvffeU3fu3NErc+TIEdW2bVtlZmamKlasqGbMmJEjljVr1qhatWopU1NTVa9ePbVx40a99fmJ5VnyvHfvnurcubOytbVVJiYmqkqVKiogICBHg62455lbfoDe31Fx+lvNTyzPkuelS5dU+/btVbly5ZSZmZmqUaOGGjNmjN5zD16GPJVSasCAAapKlSrK1NRU2draqo4dO2qNivzW/bLnWZLOZ24ebViUlHP6IhkopdSL6x8RQgghhBBClEQyx0IIIYQQQghRYNKwEEIIIYQQQhSYNCyEEEIIIYQQBSYNCyGEEEIIIUSBScNCCCGEEEIIUWDSsBBCCCGEEEIUmDQshBBCCCGEEAUmDQshhBBCCCFEgUnDQgghhCiG/P39MTAwyPFz5syZog5NCCFyZVzUAQghhBAidz4+PoSGhuots7W1LaJo9Ol0OkxMTIo6DCFEMSI9FkIIIUQxZWZmhoODg96PkZFRrmUvXrxI9+7dKVu2LJaWltSrV4/w8HBt/fHjx+nWrRvW1tZYWVnRrl07zp49C0BmZiZTp06lUqVKmJmZ0bhxYzZt2qRte+HCBQwMDFi9ejXu7u6Ym5uzYsUKAL777jvq1KmDubk5tWvX5uuvvy7EIyKEKM6kx0IIIYQoAYYNG0ZaWho7d+7E0tKSEydOULp0aQD+/vtv2rdvj4eHB9u3b8fa2pro6GjS09MBmDdvHrNnz+abb76hSZMm/PDDD7z66qscP36cmjVravsYN24cs2fPpkmTJlrjYvLkySxcuJAmTZpw+PBhAgICsLS0xM/Pr0iOgxCi6BgopVRRByGEEEIIff7+/vz000+Ym5try7p06cIvv/ySa/mGDRvy+uuvM2XKlBzrJkyYwKpVq0hISMh1+FLFihUZNmwYEyZM0Ja1bNmSFi1a8NVXX3HhwgVcXFyYO3cuI0eO1MrUqFGDadOm0bdvX23Z9OnTCQ8PZ8+ePc+UtxDi5SU9FkIIIUQx5enpyaJFi7TXlpaWeZYdMWIEQ4cOZcuWLXh5efH666/TsGFDAOLi4mjXrl2ujYrk5GT++ecf2rRpo7e8TZs2HDlyRG9Z8+bNtd/v3r3L2bNnGThwIAEBAdry9PR0bGxsni5RIUSJIA0LIYQQopiytLSkRo0a+So7aNAgvL292bhxI1u2bCEkJITZs2fz4YcfYmFh8dziyZaSkgLAt99+S6tWrfTK5TUPRAhRssnkbSGEEKKEcHZ2ZsiQIaxdu5bRo0fz7bffAlnDpHbt2oVOp8uxjbW1NU5OTkRHR+stj46Opm7dunnuy97eHicnJ86dO0eNGjX0flxcXJ5vYkKIl4L0WAghhBAlQGBgIF26dKFWrVrcvHmTyMhI6tSpA8Dw4cNZsGABffr0Yfz48djY2LBv3z5atmyJq6srY8aMYcqUKVSvXp3GjRsTGhpKXFycduenvHzyySeMGDECGxsbfHx8SE1N5eDBg9y8eZNRo0a9iLSFEMWINCyEEEKIEiAjI4Nhw4bx119/YW1tjY+PD3PmzAGgfPnybN++nTFjxuDu7o6RkRGNGzfW5lWMGDGC27dvM3r0aK5du0bdunVZv3693h2hcjNo0CBKlSrFrFmzGDNmDJaWljRo0IDAwMDCTlcIUQzJXaGEEEIIIYQQBSZzLIQQQgghhBAFJg0LIYQQQgghRIFJw0IIIYQQQghRYNKwEEIIIYQQQhSYNCyEEEIIIYQQBSYNCyGEEEIIIUSBScNCCCGEEEIIUWDSsBBCCCGEEEIUmDQshBBCCCGEEAUmDQshhBBCCCFEgUnDQgghhBBCCFFg0rAQQgghhBBCFNj/A4ULMJv6DlI7AAAAAElFTkSuQmCC"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding Base Features\n",
        "\n",
        "from https://www.kaggle.com/code/trupologhelper/ps4e5-openfe-blending-explain#Creating-New-Features-%F0%9F%93%8A"
      ],
      "metadata": {
        "id": "3HW24rFQ_8KK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_FEATURES = test_final.columns\n",
        "initial_features = BASE_FEATURES\n",
        "initial_features"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-31T09:33:27.142377Z",
          "iopub.execute_input": "2024-05-31T09:33:27.142882Z",
          "iopub.status.idle": "2024-05-31T09:33:27.150662Z",
          "shell.execute_reply.started": "2024-05-31T09:33:27.142846Z",
          "shell.execute_reply": "2024-05-31T09:33:27.149838Z"
        },
        "trusted": true,
        "id": "v10RL0wc_8KN",
        "outputId": "8ec3c1d9-0810-446c-f0e5-67458a52da1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Index(['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement',\n       'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality',\n       'Siltation', 'AgriculturalPractices', 'Encroachments',\n       'IneffectiveDisasterPreparedness', 'DrainageSystems',\n       'CoastalVulnerability', 'Landslides', 'Watersheds',\n       'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss',\n       'InadequatePlanning', 'PoliticalFactors'],\n      dtype='object')"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for df in [train_final, test_final]:\n",
        "    print('comnputing f_sum')\n",
        "    df['fsum'] = df[initial_features].sum(axis=1) # for tree models\n",
        "    print('comnputing f_std')\n",
        "    df['f_std']  = df[initial_features].std(axis=1)\n",
        "    print('comnputing f_mean')\n",
        "    df['f_mean'] = df[initial_features].mean(axis=1)\n",
        "    print('comnputing f_max')\n",
        "    df['f_max']  = df[initial_features].max(axis=1)\n",
        "    print('comnputing f_min')\n",
        "    df['f_min']  = df[initial_features].min(axis=1)\n",
        "    print('comnputing f_mode')\n",
        "    df['f_mode'] = df[initial_features].mode(axis=1)[0]\n",
        "    print('comnputing f_median')\n",
        "    df['f_median'] = df[initial_features].median(axis=1)\n",
        "    print('comnputing f_25th')\n",
        "    df['f_25th'] = df[initial_features].quantile(0.25, axis=1)\n",
        "    print('comnputing f_75th')\n",
        "    df['f_75th'] = df[initial_features].quantile(0.75, axis=1)\n",
        "    print('comnputing f_skew')\n",
        "    df['f_skew'] = df[initial_features].skew(axis=1)\n",
        "    print('comnputing f_kurt')\n",
        "    df['f_kurt'] = df[initial_features].kurt(axis=1)\n",
        "    df['special1'] = df['fsum'].isin(np.arange(72, 76)) # for linear models\n",
        "    for i in range(10,100,10):\n",
        "        print(f'comnputing f_{i}th')\n",
        "        df[f'f_{i}th'] = df[initial_features].quantile(i/100, axis=1)\n",
        "    print('comnputing f_harmonic')\n",
        "    df['f_harmonic'] = len(initial_features) / df[initial_features].apply(lambda x: (1/x).mean(), axis=1)\n",
        "    print('comnputing f_geometric')\n",
        "    df['f_geometric'] = df[initial_features].apply(lambda x: x.prod()**(1/len(x)), axis=1)\n",
        "    print('comnputing f_zscore')\n",
        "    df['f_zscore'] = df[initial_features].apply(lambda x: (x - x.mean()) / x.std(), axis=1).mean(axis=1)\n",
        "    print('computing Coefficient of Variation ')\n",
        "    df['f_cv'] = df[initial_features].std(axis=1) / df[initial_features].mean(axis=1)\n",
        "    print('computing f_Quantile Coefficients of Skewness_75')\n",
        "    df['f_Quantile Coefficients of Skewness_75'] = (df[initial_features].quantile(0.75, axis=1) - df[initial_features].mean(axis=1)) / df[initial_features].std(axis=1)\n",
        "    print('computing f_Quantile Coefficients of Skewness_25')\n",
        "    df['f_Quantile Coefficients of Skewness_25'] = (df[initial_features].quantile(0.25, axis=1) - df[initial_features].mean(axis=1)) / df[initial_features].std(axis=1)\n",
        "    print('computing f_2ndMoment')\n",
        "    df['f_2ndMoment'] = df[initial_features].apply(lambda x: (x**2).mean(), axis=1)\n",
        "    print('computing f_3rdMoment')\n",
        "    df['f_3rdMoment'] = df[initial_features].apply(lambda x: (x**3).mean(), axis=1)\n",
        "    print('computing f_entropy')\n",
        "    df['f_entropy'] = df[initial_features].apply(lambda x: -1*(x*np.log(x)).sum(), axis=1)\n",
        "    #print('computing f_mad') probably has negative impact\n",
        "    #df['f_mad'] = df[initial_features].apply(lambda x: (x - x.median()).abs().median(), axis=1)\n",
        "    #print('computing f_iqr') probably has negative impact\n",
        "    #df['f_iqr'] = df[initial_features].quantile(0.75, axis=1) - df[initial_features].quantile(0.25, axis=1)"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2024-05-31T06:58:54.380625Z",
          "iopub.execute_input": "2024-05-31T06:58:54.381124Z",
          "iopub.status.idle": "2024-05-31T07:47:44.867837Z",
          "shell.execute_reply.started": "2024-05-31T06:58:54.381093Z",
          "shell.execute_reply": "2024-05-31T07:47:44.864836Z"
        },
        "trusted": true,
        "id": "VjTG3tHd_8KO",
        "outputId": "5470631f-b68e-4740-9c3d-fae9a7ee3113"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "comnputing f_sum\ncomnputing f_std\ncomnputing f_mean\ncomnputing f_max\ncomnputing f_min\ncomnputing f_mode\ncomnputing f_median\ncomnputing f_25th\ncomnputing f_75th\ncomnputing f_skew\ncomnputing f_kurt\ncomnputing f_10th\ncomnputing f_20th\ncomnputing f_30th\ncomnputing f_40th\ncomnputing f_50th\ncomnputing f_60th\ncomnputing f_70th\ncomnputing f_80th\ncomnputing f_90th\ncomnputing f_harmonic\ncomnputing f_geometric\ncomnputing f_zscore\ncomputing Coefficient of Variation \ncomputing f_Quantile Coefficients of Skewness_75\ncomputing f_Quantile Coefficients of Skewness_25\ncomputing f_2ndMoment\ncomputing f_3rdMoment\ncomputing f_entropy\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "comnputing f_sum\ncomnputing f_std\ncomnputing f_mean\ncomnputing f_max\ncomnputing f_min\ncomnputing f_mode\ncomnputing f_median\ncomnputing f_25th\ncomnputing f_75th\ncomnputing f_skew\ncomnputing f_kurt\ncomnputing f_10th\ncomnputing f_20th\ncomnputing f_30th\ncomnputing f_40th\ncomnputing f_50th\ncomnputing f_60th\ncomnputing f_70th\ncomnputing f_80th\ncomnputing f_90th\ncomnputing f_harmonic\ncomnputing f_geometric\ncomnputing f_zscore\ncomputing Coefficient of Variation \ncomputing f_Quantile Coefficients of Skewness_75\ncomputing f_Quantile Coefficients of Skewness_25\ncomputing f_2ndMoment\ncomputing f_3rdMoment\ncomputing f_entropy\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "CPU times: user 48min, sys: 50.8 s, total: 48min 51s\nWall time: 48min 50s\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_final.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-31T07:47:44.872497Z",
          "iopub.execute_input": "2024-05-31T07:47:44.873105Z",
          "iopub.status.idle": "2024-05-31T07:47:44.92776Z",
          "shell.execute_reply.started": "2024-05-31T07:47:44.873049Z",
          "shell.execute_reply": "2024-05-31T07:47:44.926005Z"
        },
        "trusted": true,
        "id": "pOHguGRO_8KR",
        "outputId": "c721b318-d445-46c1-c36a-bac6827081cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   MonsoonIntensity  TopographyDrainage  RiverManagement  Deforestation  \\\n0                 5                   8                5              8   \n1                 6                   7                4              4   \n2                 6                   5                6              7   \n3                 3                   4                6              5   \n4                 5                   3                2              6   \n\n   Urbanization  ClimateChange  DamsQuality  Siltation  AgriculturalPractices  \\\n0             6              4            4          3                      3   \n1             8              8            3          5                      4   \n2             3              7            1          5                      4   \n3             4              8            4          7                      6   \n4             4              4            3          3                      3   \n\n   Encroachments  ...  f_90th  f_harmonic  f_geometric      f_zscore  \\\n0              4  ...     7.1   82.151589     4.397569 -7.771561e-17   \n1              6  ...     8.0    0.000000     0.000000 -6.661338e-17   \n2              5  ...     7.0   76.242342     4.468658 -8.881784e-17   \n3              8  ...     7.1   92.766427     4.933055 -1.089406e-16   \n4              3  ...     6.0   58.394161     3.275062 -9.992007e-17   \n\n       f_cv  f_Quantile Coefficients of Skewness_75  \\\n0  0.372380                                0.314252   \n1  0.488606                                0.674955   \n2  0.390386                                0.672735   \n3  0.315686                                0.639633   \n4  0.416910                                0.932788   \n\n   f_Quantile Coefficients of Skewness_25  f_2ndMoment  f_3rdMoment  \\\n0                               -0.971324        25.00       147.50   \n1                               -0.740273        27.10       176.00   \n2                               -1.009102        28.05       171.45   \n3                               -0.731010        29.60       181.00   \n4                               -0.566336        15.10        70.50   \n\n    f_entropy  \n0 -151.546500  \n1 -157.930509  \n2 -166.426821  \n3 -176.528802  \n4  -98.348970  \n\n[5 rows x 51 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MonsoonIntensity</th>\n      <th>TopographyDrainage</th>\n      <th>RiverManagement</th>\n      <th>Deforestation</th>\n      <th>Urbanization</th>\n      <th>ClimateChange</th>\n      <th>DamsQuality</th>\n      <th>Siltation</th>\n      <th>AgriculturalPractices</th>\n      <th>Encroachments</th>\n      <th>...</th>\n      <th>f_90th</th>\n      <th>f_harmonic</th>\n      <th>f_geometric</th>\n      <th>f_zscore</th>\n      <th>f_cv</th>\n      <th>f_Quantile Coefficients of Skewness_75</th>\n      <th>f_Quantile Coefficients of Skewness_25</th>\n      <th>f_2ndMoment</th>\n      <th>f_3rdMoment</th>\n      <th>f_entropy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>8</td>\n      <td>5</td>\n      <td>8</td>\n      <td>6</td>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>3</td>\n      <td>4</td>\n      <td>...</td>\n      <td>7.1</td>\n      <td>82.151589</td>\n      <td>4.397569</td>\n      <td>-7.771561e-17</td>\n      <td>0.372380</td>\n      <td>0.314252</td>\n      <td>-0.971324</td>\n      <td>25.00</td>\n      <td>147.50</td>\n      <td>-151.546500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6</td>\n      <td>7</td>\n      <td>4</td>\n      <td>4</td>\n      <td>8</td>\n      <td>8</td>\n      <td>3</td>\n      <td>5</td>\n      <td>4</td>\n      <td>6</td>\n      <td>...</td>\n      <td>8.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-6.661338e-17</td>\n      <td>0.488606</td>\n      <td>0.674955</td>\n      <td>-0.740273</td>\n      <td>27.10</td>\n      <td>176.00</td>\n      <td>-157.930509</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>5</td>\n      <td>6</td>\n      <td>7</td>\n      <td>3</td>\n      <td>7</td>\n      <td>1</td>\n      <td>5</td>\n      <td>4</td>\n      <td>5</td>\n      <td>...</td>\n      <td>7.0</td>\n      <td>76.242342</td>\n      <td>4.468658</td>\n      <td>-8.881784e-17</td>\n      <td>0.390386</td>\n      <td>0.672735</td>\n      <td>-1.009102</td>\n      <td>28.05</td>\n      <td>171.45</td>\n      <td>-166.426821</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>4</td>\n      <td>6</td>\n      <td>5</td>\n      <td>4</td>\n      <td>8</td>\n      <td>4</td>\n      <td>7</td>\n      <td>6</td>\n      <td>8</td>\n      <td>...</td>\n      <td>7.1</td>\n      <td>92.766427</td>\n      <td>4.933055</td>\n      <td>-1.089406e-16</td>\n      <td>0.315686</td>\n      <td>0.639633</td>\n      <td>-0.731010</td>\n      <td>29.60</td>\n      <td>181.00</td>\n      <td>-176.528802</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>3</td>\n      <td>2</td>\n      <td>6</td>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>6.0</td>\n      <td>58.394161</td>\n      <td>3.275062</td>\n      <td>-9.992007e-17</td>\n      <td>0.416910</td>\n      <td>0.932788</td>\n      <td>-0.566336</td>\n      <td>15.10</td>\n      <td>70.50</td>\n      <td>-98.348970</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows  51 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape,train_final.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-31T07:47:44.929253Z",
          "iopub.execute_input": "2024-05-31T07:47:44.929661Z",
          "iopub.status.idle": "2024-05-31T07:47:44.93876Z",
          "shell.execute_reply.started": "2024-05-31T07:47:44.929624Z",
          "shell.execute_reply": "2024-05-31T07:47:44.937369Z"
        },
        "trusted": true,
        "id": "-JAiL4NE_8KS",
        "outputId": "a43254b8-5255-4fdf-d734-5f370ba38b6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "((1117957, 21), (1167957, 51))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "subset with new base features"
      ],
      "metadata": {
        "id": "TNnUsubA_8KT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#using subset\n",
        "splits = RandomSplitter(valid_pct=0.2)(range_of(train_subset))\n",
        "to = TabularPandas(train_subset, procs=[Categorify, FillMissing,Normalize],\n",
        "                   cat_names = cat_names,\n",
        "                   cont_names = cont_names,\n",
        "                   y_names='FloodProbability',\n",
        "                   y_block=RegressionBlock(),\n",
        "                   splits=splits)\n",
        "X_train, y_train = to.train.xs, to.train.ys.values.ravel()\n",
        "X_test, y_test = to.valid.xs, to.valid.ys.values.ravel()\n",
        "dls = to.dataloaders(bs=64)\n",
        "test_dl = dls.test_dl(test_subset)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-30T16:08:44.472901Z",
          "iopub.execute_input": "2024-05-30T16:08:44.473429Z",
          "iopub.status.idle": "2024-05-30T16:08:45.076312Z",
          "shell.execute_reply.started": "2024-05-30T16:08:44.473357Z",
          "shell.execute_reply": "2024-05-30T16:08:45.075329Z"
        },
        "trusted": true,
        "id": "uv5dXn42_8KU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "previous lgb subset without base features resulted in a score of 0.8352025054299641, using base features slighty improves the score to 0.8366867366706527"
      ],
      "metadata": {
        "id": "M8-BLZro_8KV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "lgb_model_3 = lgb.LGBMRegressor(boosting_type='gbdt', n_estimators=2000, learning_rate=0.012,num_leaves=250, subsample_for_bin=165700, min_child_samples=114, reg_alpha=2.075e-06, reg_lambda=3.839e-07, colsample_bytree= 0.9634,subsample=0.9592, max_depth= 10,random_state=0,verbosity=-1)\n",
        "lgb_model_3 = lgb_model_3.fit(X_train, y_train)\n",
        "\n",
        "#test set preds\n",
        "lgb_preds_3 = tensor(lgb_model_3.predict(test_dl.xs))\n",
        "\n",
        "#validation set preds\n",
        "lgb_preds_x_3 = tensor(lgb_model_3.predict(X_test))\n",
        "\n",
        "lgb_score_3 = r2_score(y_test,lgb_preds_x_3)\n",
        "lgb_score_3"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-30T16:08:55.261342Z",
          "iopub.execute_input": "2024-05-30T16:08:55.261812Z",
          "iopub.status.idle": "2024-05-30T16:10:40.059189Z",
          "shell.execute_reply.started": "2024-05-30T16:08:55.261776Z",
          "shell.execute_reply": "2024-05-30T16:10:40.058059Z"
        },
        "trusted": true,
        "id": "C9AN_kxj_8KV",
        "outputId": "078fd9eb-ef48-4065-9cbd-0a5efe79b76d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "CPU times: user 3min 26s, sys: 1.42 s, total: 3min 28s\nWall time: 1min 44s\n",
          "output_type": "stream"
        },
        {
          "execution_count": 55,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.8366867366706527"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Full dataset with base features"
      ],
      "metadata": {
        "id": "exjKdqWc_8KX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cont_names,cat_names = cont_cat_split(train_final, dep_var='FloodProbability')\n",
        "splits = RandomSplitter(valid_pct=0.2)(range_of(train_final))\n",
        "to = TabularPandas(train_final, procs=[Categorify, FillMissing,Normalize],\n",
        "                   cat_names = cat_names,\n",
        "                   cont_names = cont_names,\n",
        "                   y_names='FloodProbability',\n",
        "                   y_block=RegressionBlock(),\n",
        "                   splits=splits)\n",
        "X_train, y_train = to.train.xs, to.train.ys.values.ravel()\n",
        "X_test, y_test = to.valid.xs, to.valid.ys.values.ravel()\n",
        "dls = to.dataloaders(bs=64)\n",
        "#test_dl = dls.test_dl(test)\n",
        "#dl = learn1.dls.test_dl(test_final)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-31T07:47:51.915238Z",
          "iopub.execute_input": "2024-05-31T07:47:51.915764Z",
          "iopub.status.idle": "2024-05-31T07:47:57.562903Z",
          "shell.execute_reply.started": "2024-05-31T07:47:51.915704Z",
          "shell.execute_reply": "2024-05-31T07:47:57.561538Z"
        },
        "trusted": true,
        "id": "N92asSF6_8KY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dl = dls.test_dl(test_final)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-31T07:47:57.5646Z",
          "iopub.execute_input": "2024-05-31T07:47:57.564981Z",
          "iopub.status.idle": "2024-05-31T07:47:58.470498Z",
          "shell.execute_reply.started": "2024-05-31T07:47:57.56495Z",
          "shell.execute_reply": "2024-05-31T07:47:58.469131Z"
        },
        "trusted": true,
        "id": "mG5MoItj_8KZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "cat_model = CatBoostRegressor(n_estimators=8000,random_state=0,learning_rate=0.011277016304363601, depth=8, subsample=0.8675506657380021, colsample_bylevel=0.7183884158632279, min_data_in_leaf=98)\n",
        "cat_model = cat_model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False)\n",
        "\n",
        "#test set preds\n",
        "cat_preds = tensor(cat_model.predict(test_dl.xs))\n",
        "\n",
        "#validation set preds\n",
        "cat_preds_x = tensor(cat_model.predict(X_test))\n",
        "\n",
        "r2_score(y_test,cat_preds_x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-31T07:47:58.47193Z",
          "iopub.execute_input": "2024-05-31T07:47:58.472396Z",
          "iopub.status.idle": "2024-05-31T08:26:38.541822Z",
          "shell.execute_reply.started": "2024-05-31T07:47:58.472357Z",
          "shell.execute_reply": "2024-05-31T08:26:38.540537Z"
        },
        "trusted": true,
        "id": "7EgbncH4_8Ka",
        "outputId": "ea37a306-e105-465b-eceb-fb18ec85fc4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "CPU times: user 2h 16min 39s, sys: 3min 20s, total: 2h 20min\nWall time: 38min 40s\n",
          "output_type": "stream"
        },
        {
          "execution_count": 19,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.8720194395025203"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "lgb_model_3 = lgb.LGBMRegressor(boosting_type='gbdt', n_estimators=2000, learning_rate=0.012,num_leaves=250, subsample_for_bin=165700, min_child_samples=114, reg_alpha=2.075e-06, reg_lambda=3.839e-07, colsample_bytree= 0.9634,subsample=0.9592, max_depth= 10,random_state=0,verbosity=-1)\n",
        "lgb_model_3 = lgb_model_3.fit(X_train, y_train)\n",
        "\n",
        "#test set preds\n",
        "lgb_preds_3 = tensor(lgb_model_3.predict(test_dl.xs))\n",
        "\n",
        "#validation set preds\n",
        "lgb_preds_x_3 = tensor(lgb_model_3.predict(X_test))\n",
        "\n",
        "lgb_score_3 = r2_score(y_test,lgb_preds_x_3)\n",
        "lgb_score_3"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-31T08:26:38.543669Z",
          "iopub.execute_input": "2024-05-31T08:26:38.544659Z",
          "iopub.status.idle": "2024-05-31T08:40:41.329188Z",
          "shell.execute_reply.started": "2024-05-31T08:26:38.544616Z",
          "shell.execute_reply": "2024-05-31T08:40:41.327644Z"
        },
        "trusted": true,
        "id": "KhDVr3vh_8Ka",
        "outputId": "c07ba6ec-901e-4ec4-e08d-ab23ecdeeec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "CPU times: user 27min 52s, sys: 3.01 s, total: 27min 55s\nWall time: 14min 2s\n",
          "output_type": "stream"
        },
        {
          "execution_count": 20,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.871929835997473"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "xgb_model = xgb.XGBRegressor(n_estimators=8000,max_depth=10,learning_rate=0.01,random_state=0)\n",
        "xgb_model = xgb_model.fit(X_train, y_train)\n",
        "\n",
        "xgb_preds = tensor(xgb_model.predict(test_dl.xs))\n",
        "\n",
        "xgb_preds_x = tensor(xgb_model.predict(X_test))\n",
        "\n",
        "r2_score(y_test,xgb_preds_x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-31T08:40:41.334285Z",
          "iopub.execute_input": "2024-05-31T08:40:41.335117Z"
        },
        "trusted": true,
        "id": "WwOvd5tn_8Kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = tabular_learner(dls, metrics=R2Score())\n",
        "learn.lr_find(suggest_funcs=(slide,valley))"
      ],
      "metadata": {
        "trusted": true,
        "id": "9XIe1LLS_8Kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dl = learn1.dls.test_dl(test_final)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-31T09:31:19.773724Z",
          "iopub.execute_input": "2024-05-31T09:31:19.774143Z",
          "iopub.status.idle": "2024-05-31T09:31:19.80304Z",
          "shell.execute_reply.started": "2024-05-31T09:31:19.774102Z",
          "shell.execute_reply": "2024-05-31T09:31:19.801515Z"
        },
        "trusted": true,
        "id": "HetN2rYr_8Kd",
        "outputId": "a4c02a00-72df-458f-da89-8412a1801ddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dl \u001b[38;5;241m=\u001b[39m \u001b[43mlearn1\u001b[49m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mtest_dl(test_final)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'learn1' is not defined"
          ],
          "ename": "NameError",
          "evalue": "name 'learn1' is not defined",
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "learn.fit_one_cycle(12,0.012)"
      ],
      "metadata": {
        "trusted": true,
        "id": "-MpHrnaK_8Ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "nn_preds = learn.get_preds(dl=dl)\n",
        "nn_preds_x = learn.get_preds()[0]\n",
        "a_preds, _ = learn.get_preds(dl=dl)\n",
        "nn_preds_y = a_preds.squeeze(1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "6hesqqiT_8Kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset no original training subset with new openFE features\n",
        "r2_score(y_test,nn_preds_x)"
      ],
      "metadata": {
        "trusted": true,
        "id": "SR_k8G6i_8Kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv(path/'sample_submission.csv')\n",
        "submit['FloodProbability'] = cat_preds_x\n",
        "submit.to_csv('submission.csv', index=False)\n",
        "sub = pd.read_csv('submission.csv')"
      ],
      "metadata": {
        "id": "xjJh5QT0_8Kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7uXrq_W__8Kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1O78Stub_8Kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_model = CatBoostRegressor(iterations=1500, depth=8, learning_rate= 0.012, random_strength=8)\n",
        "cat_model = cat_model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False)\n",
        "\n",
        "#test set preds\n",
        "#cat_preds = tensor(cat_model.predict(test_dl.xs))\n",
        "\n",
        "#validation set preds\n",
        "cat_preds_x = tensor(cat_model.predict(X_test))\n",
        "\n",
        "r2_score(y_test,cat_preds_x)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Y1_4y3CQ_8Kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_preds_x = tensor(cat_model.predict(X_test))\n",
        "\n",
        "r2_score(y_test,cat_preds_x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-29T16:16:43.391053Z",
          "iopub.execute_input": "2024-05-29T16:16:43.391661Z",
          "iopub.status.idle": "2024-05-29T16:16:43.830053Z",
          "shell.execute_reply.started": "2024-05-29T16:16:43.391621Z",
          "shell.execute_reply": "2024-05-29T16:16:43.8289Z"
        },
        "trusted": true,
        "id": "OpcC5zm__8Kh",
        "outputId": "68c9a17b-317c-40e1-ba77-0f4cd11a9924"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 29,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.9958581143631213"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv(path/'sample_submission.csv')\n",
        "submit['FloodProbability'] = cat_preds_x\n",
        "submit.to_csv('submission.csv', index=False)\n",
        "sub = pd.read_csv('submission.csv')"
      ],
      "metadata": {
        "trusted": true,
        "id": "wYzTD5Jg_8Kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introducing Open FE\n",
        "\n",
        "So i experiment with adding new features using openFE, An auto feature generation framework"
      ],
      "metadata": {
        "id": "wOUmjAaG_8Ko"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Excluding original dataset"
      ],
      "metadata": {
        "id": "66XIwhmD_8Kp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ofe = OpenFE()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-29T07:39:42.270674Z",
          "iopub.execute_input": "2024-05-29T07:39:42.271406Z",
          "iopub.status.idle": "2024-05-29T07:39:42.278628Z",
          "shell.execute_reply.started": "2024-05-29T07:39:42.271347Z",
          "shell.execute_reply": "2024-05-29T07:39:42.277365Z"
        },
        "trusted": true,
        "id": "yqeH4rW8_8Kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set n_jobs to be the actual cpu core count\n",
        "CPU_COUNT = os.cpu_count()\n",
        "n_jobs = CPU_COUNT\n",
        "n_jobs"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-29T07:39:42.623089Z",
          "iopub.execute_input": "2024-05-29T07:39:42.623464Z",
          "iopub.status.idle": "2024-05-29T07:39:42.63128Z",
          "shell.execute_reply.started": "2024-05-29T07:39:42.623435Z",
          "shell.execute_reply": "2024-05-29T07:39:42.629988Z"
        },
        "trusted": true,
        "id": "b5Dvdrby_8Kr",
        "outputId": "1e42f7a4-b147-4432-e6b8-ab04bcb592a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 21,
          "output_type": "execute_result",
          "data": {
            "text/plain": "4"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_names='FloodProbability'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-29T07:39:43.225841Z",
          "iopub.execute_input": "2024-05-29T07:39:43.227004Z",
          "iopub.status.idle": "2024-05-29T07:39:43.232221Z",
          "shell.execute_reply.started": "2024-05-29T07:39:43.226943Z",
          "shell.execute_reply": "2024-05-29T07:39:43.231092Z"
        },
        "trusted": true,
        "id": "q4Av9qzQ_8Ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#features = ofe.fit(data=train_subset.drop('FloodProbability',axis=1), label=train_subset['FloodProbability'], n_jobs=n_jobs)  # generate new features\n",
        "#train_x, test_x = transform(train_z, test_subset, features, n_jobs=n_jobs) # transform the train and test data according to generated features."
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2024-05-29T03:29:14.242271Z",
          "iopub.execute_input": "2024-05-29T03:29:14.242805Z",
          "iopub.status.idle": "2024-05-29T03:29:14.248577Z",
          "shell.execute_reply.started": "2024-05-29T03:29:14.242764Z",
          "shell.execute_reply": "2024-05-29T03:29:14.247297Z"
        },
        "trusted": true,
        "id": "qcd5osw7_8Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concating the original dataframe before running the OpenFE feature generation tool seems to result in a NameError.\n",
        "This needs further investigation."
      ],
      "metadata": {
        "id": "z6MKesCJ_8Ku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\"n_estimators\": 1000, \"importance_type\": \"gain\", \"num_leaves\": 64,\"seed\": 1, \"n_jobs\": n_jobs}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-29T07:39:49.060232Z",
          "iopub.execute_input": "2024-05-29T07:39:49.060674Z",
          "iopub.status.idle": "2024-05-29T07:39:49.065897Z",
          "shell.execute_reply.started": "2024-05-29T07:39:49.060642Z",
          "shell.execute_reply": "2024-05-29T07:39:49.064533Z"
        },
        "trusted": true,
        "id": "EUd4vYUW_8Kv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from openfe import OpenFE, get_candidate_features, transform, tree_to_formula\n",
        "\n",
        "candidate_features_list = get_candidate_features(numerical_features=list(test_df.columns))\n",
        "features = ofe.fit(data=train_df.drop(y_names,axis=1), label=train_df[y_names],\n",
        "                     candidate_features_list=candidate_features_list, metric='rmse', task='regression', stage2_params=params,\n",
        "                     min_candidate_features=5000,\n",
        "                     n_jobs=n_jobs, n_data_blocks=2, feature_boosting=True)\n"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2024-05-29T07:39:54.538764Z",
          "iopub.execute_input": "2024-05-29T07:39:54.539323Z",
          "iopub.status.idle": "2024-05-29T08:16:41.723378Z",
          "shell.execute_reply.started": "2024-05-29T07:39:54.539274Z",
          "shell.execute_reply": "2024-05-29T08:16:41.721865Z"
        },
        "trusted": true,
        "id": "GOFRUgQj_8Kw",
        "outputId": "9a062b86-7215-4060-953c-d4b780cddb9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.225395 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 347\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 20\n[LightGBM] [Info] Start training from score 0.504471\nTraining until validation scores don't improve for 200 rounds\nEarly stopping, best iteration is:\n[3117]\tvalid_0's rmse: 0.0203707\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.130934 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 348\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 20\n[LightGBM] [Info] Start training from score 0.504463\nTraining until validation scores don't improve for 200 rounds\nEarly stopping, best iteration is:\n[3334]\tvalid_0's rmse: 0.0203727\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.129069 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 346\n[LightGBM] [Info] Number of data points in the train set: 894366, number of used features: 20\n[LightGBM] [Info] Start training from score 0.504470\nTraining until validation scores don't improve for 200 rounds\nEarly stopping, best iteration is:\n[4049]\tvalid_0's rmse: 0.0204355\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.127713 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 347\n[LightGBM] [Info] Number of data points in the train set: 894366, number of used features: 20\n[LightGBM] [Info] Start training from score 0.504528\nTraining until validation scores don't improve for 200 rounds\nEarly stopping, best iteration is:\n[3474]\tvalid_0's rmse: 0.0203541\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.126439 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 348\n[LightGBM] [Info] Number of data points in the train set: 894366, number of used features: 20\n[LightGBM] [Info] Start training from score 0.504469\nTraining until validation scores don't improve for 200 rounds\nEarly stopping, best iteration is:\n[2928]\tvalid_0's rmse: 0.0204223\nThe number of candidate features is 1300\nStart stage I selection.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  0%|          | 0/16 [00:00<?, ?it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011376 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013700 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014088 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013762 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013916 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013637 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006119 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013518 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013795 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014232 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 120[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013476 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014284 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 30\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039156 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013532 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014180 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012871 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013190 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014028 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023405 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 19\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013762 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013942 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013654 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013103 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014677 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014122 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014735 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013466 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013242 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012109 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Total Bins 124\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015660 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013579 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013263 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014372 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 123\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015637 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n[LightGBM] [Info] Total Bins 0\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 0\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012929 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013537 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 77[LightGBM] [Info] Total Bins 19\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013887 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012868 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013868 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18[LightGBM] [Info] Total Bins 18\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013922 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013485 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014305 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014517 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013833 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013027 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014550 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013759 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015392 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 77[LightGBM] [Info] Total Bins 14\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014172 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013952 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013904 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013345 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 76\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015545 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013729 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013904 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014051 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014774 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013724 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014514 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014171 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013603 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013344 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 27[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023824 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014145 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014439 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013275 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013226 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014148 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 125\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013736 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012994 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013536 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013360 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012974 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 19\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013740 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014008 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014012 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015358 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013113 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012696 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013294 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013978 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 0\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 0\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012772 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013819 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016284 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013218 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013050 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014087 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014652 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015094 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012658 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 27\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012966 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015465 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 116\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013492 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013465 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013291 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014345 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015414 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013426 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013092 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014439 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014947 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013002 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013704 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015603 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013189 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012754 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 78[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016398 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013864 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014435 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013334 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Total Bins 117[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012774 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012978 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019736 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 115\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013061 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 115\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013226 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014209 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012930 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013690 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014640 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013582 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012768 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 25[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006463 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012857 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012915 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014041 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014162 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 28\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014414 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006905 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013220 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014029 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013042 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013002 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013386 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013738 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013148 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013531 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n[LightGBM] [Info] Total Bins 0\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 0[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015094 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013568 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013563 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015043 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 30\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014311 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 18\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016190 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013712 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014551 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013084 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014398 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012421 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013669 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014262 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011999 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013652 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013227 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017321 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013314 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013061 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014540 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015088 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018124 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013217 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013496 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013450 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012697 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016274 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013213 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014220 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013798 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013635 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 123\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015931 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014558 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013754 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014115 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Total Bins 0\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 0\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012960 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016096 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013085 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014045 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014541 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014059 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 0\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 0\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014962 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014324 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013414 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013203 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015156 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 29\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013520 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013429 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006988 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015906 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012622 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013018 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013263 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014866 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013618 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012578 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012899 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013868 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012795 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014977 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015078 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015902 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 19\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013144 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014414 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013563 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013623 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014558 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013076 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013026 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 19\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013532 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014320 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013264 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 123\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012962 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012853 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012754 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015220 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013519 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013428 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014152 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014112 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Total Bins 29\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013636 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013589 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013063 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014344 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014975 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014977 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014943 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013064 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014592 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014129 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013068 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014305 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014049 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013048 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013309 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013364 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013012 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013261 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013374 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012873 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014632 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014857 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014174 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n[LightGBM] [Info] Total Bins 0\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 0\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013047 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013905 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012685 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014953 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014089 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013291 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 76[LightGBM] [Info] Total Bins 28\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013288 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013367 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013386 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013218 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012709 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013816 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 79\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n[LightGBM] [Info] Total Bins 0\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 0\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013225 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006429 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013559 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013808 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014403 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014214 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013657 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012716 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012892 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Total Bins 0\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 0\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013315 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013621 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013840 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 123\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013418 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013326 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013161 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014924 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013474 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013550 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  6%|         | 1/16 [00:47<11:46, 47.09s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013822 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013458 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Total Bins 0\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 0\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023607 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015698 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Total Bins 18[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013239 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012208 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013076 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014615 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014966 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013113 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 123\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015937 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012993 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018581 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014437 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013257 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014940 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014818 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023405 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016197 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013642 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015958 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 12%|        | 2/16 [00:52<05:15, 22.55s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014422 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013452 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013529 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023610 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014406 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013081 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013772 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 79\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013329 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014216 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012808 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013433 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014937 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014242 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013693 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 79\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013403 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014075 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013200 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 123\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013274 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013332 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013026 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012712 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Total Bins 120[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Total Bins 0\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 0\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013530 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012933 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014323 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013764 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012892 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014315 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013651 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013813 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013738 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013070 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013260 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014469 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Total Bins 18[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014153 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015114 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013439 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013594 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013970 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013257 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014170 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018946 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013120 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 115\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013190 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014631 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018793 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013317 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013381 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 19%|        | 3/16 [00:59<03:22, 15.60s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014736 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013525 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013810 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012813 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024785 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 30\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013558 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024059 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022760 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013599 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012811 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 73\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013127 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012576 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013127 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014620 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014070 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014363 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013108 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014893 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016363 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013856 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014518 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013612 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016600 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015170 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013898 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014768 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011873 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 119[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027493 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013667 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015264 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016371 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013768 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013098 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014925 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Total Bins 0\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 0\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013736 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014378 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013390 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 25%|       | 4/16 [01:05<02:19, 11.62s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013527 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013991 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 72\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013400 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013667 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022000 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013435 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023982 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013329 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013275 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013926 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013188 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013505 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018952 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013796 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013628 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014100 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 30\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013418 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012877 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013898 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 30\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012996 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014334 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013040 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013384 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Total Bins 26[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013335 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013253 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013295 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 19\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013043 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013346 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012571 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014725 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013322 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 124\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013507 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013141 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 123\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013319 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013241 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013186 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013519 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013664 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013569 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013914 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014565 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013231 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013338 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 123\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012855 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014470 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014003 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013965 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015391 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014174 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014590 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013670 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012888 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014656 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014486 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013024 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013808 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014456 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014359 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013628 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013511 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013832 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014212 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013808 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 124\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013563 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017648 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Total Bins 117\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014796 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013050 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014776 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014162 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013324 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013770 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 117\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012912 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013887 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013702 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Total Bins 26[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014033 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016259 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013485 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014123 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 19\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013926 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014386 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013192 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013319 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 79\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012886 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013526 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013887 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015040 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014346 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017959 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Total Bins 18\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013555 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 28[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013079 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013195 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 19\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012698 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023156 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023820 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 124\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012585 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017689 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013058 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013558 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014175 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012866 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013705 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012924 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013918 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012935 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014149 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Total Bins 74\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015146 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014122 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013814 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013655 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013823 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013612 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013679 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014051 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013455 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013585 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013944 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013730 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013968 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013075 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013406 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Total Bins 115\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013494 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013327 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013659 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013866 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013707 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015128 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Total Bins 0\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 0\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013484 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Info] Total Bins 76\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012865 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014028 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013947 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014893 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015526 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013827 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014769 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013599 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013256 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014869 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013957 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013886 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015050 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013941 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014412 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013761 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014900 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012672 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014058 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012877 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012916 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013326 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014860 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 30\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013067 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013539 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013789 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013997 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010885 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026501 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014722 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015872 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013984 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016552 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014771 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016314 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013899 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 31%|      | 5/16 [01:36<03:25, 18.72s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015837 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014270 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013948 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013377 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013239 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012968 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027667 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015102 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013513 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005835 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012969 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013832 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014081 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013829 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013958 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013022 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013252 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012772 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014277 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014905 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014390 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 30\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017295 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13[LightGBM] [Info] Total Bins 0\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 0\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013794 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014735 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015048 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012046 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014143 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014256 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014678 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013362 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013278 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013895 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013231 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014200 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 30\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014901 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013586 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014312 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013965 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014336 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013776 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 19\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013330 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012518 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019514 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012968 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013357 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014370 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014025 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013311 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014816 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015701 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014500 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015038 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Total Bins 77\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014102 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013949 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014052 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013860 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014291 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013772 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 12[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014094 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014109 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015064 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037725 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016957 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023979 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014166 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 73\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019424 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024190 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015233 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 79\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014519 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013979 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014609 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009094 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023846 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015905 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Total Bins 28\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052083 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033430 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031792 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031536 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029565 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035107 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053923 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 30\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 38%|      | 6/16 [02:01<03:27, 20.76s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036624 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029872 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040789 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027801 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 19\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016879 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024011 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030093 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013718 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031543 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014562 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070235 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 19\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010628 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010747 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014012 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015691 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 74\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014289 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013457 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014380 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013433 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013858 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013176 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012925 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013141 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014908 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013985 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013927 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 123\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013463 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012984 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013666 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013280 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012944 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013079 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013405 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 124\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013531 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013072 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014362 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012996 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015052 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013692 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 44%|     | 7/16 [02:14<02:43, 18.14s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013651 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013737 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023134 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 30\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022426 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 73\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015925 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014040 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013568 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014436 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 71\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013617 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014020 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014911 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014294 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015014 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014241 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013687 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 123\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012737 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014046 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014367 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014334 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 28\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014627 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n[LightGBM] [Info] Total Bins 0\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 0\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015986 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013373 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013077 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013369 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013497 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013827 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016041 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013799 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013066 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 79\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015146 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013207 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012608 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014067 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015027 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007186 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014765 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013358 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013217 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013472 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014471 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012698 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021288 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013562 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013489 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022557 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022446 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014410 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025464 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012970 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013050 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 27\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022218 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013009 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013574 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013599 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014153 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014068 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012975 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014513 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013455 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019192 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013462 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013733 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013631 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014473 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013597 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013905 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014474 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013102 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013099 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013339 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015022 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014235 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 30\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015274 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014283 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014076 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013014 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013425 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012738 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013967 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015582 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014220 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015691 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013117 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013919 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014152 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012997 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013062 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013493 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016126 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014803 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014080 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015423 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 30\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014023 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 19\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014513 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013847 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014214 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015117 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015213 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015100 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014411 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013046 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014584 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013947 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 19\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014085 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013994 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015211 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012913 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014551 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014203 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014175 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015862 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013823 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013488 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014181 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013905 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018288 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014711 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014388 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013991 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013903 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014500 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013600 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012685 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014753 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014284 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013321 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013780 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013360 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014573 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012619 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013716 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013649 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013137 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Total Bins 13[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014221 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 76\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013458 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011648 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 123\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015266 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014668 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012993 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 19\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013075 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 19\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021023 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013767 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n[LightGBM] [Info] Total Bins 0\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 0\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013832 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013143 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013027 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015147 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Total Bins 0\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 0\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013172 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013128 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Total Bins 18[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014097 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n\n[LightGBM] [Info] Total Bins 0\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 0\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014871 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013367 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011212 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014604 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012874 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021193 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014328 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012668 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016267 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013559 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 123\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013061 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 50%|     | 8/16 [02:51<03:14, 24.30s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015849 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014295 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014768 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012931 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013859 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013769 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012911 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033157 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012934 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013340 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012937 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013530 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013191 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015340 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015146 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012951 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 18\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013868 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013113 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015258 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013244 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006407 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013279 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014574 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013792 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012972 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013359 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016653 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013718 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 19\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013608 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015327 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013022 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013100 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011560 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013577 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 56%|    | 9/16 [02:56<02:08, 18.33s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014366 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013010 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013712 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014591 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014776 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026420 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015275 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013031 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013382 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013771 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013669 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 123\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013401 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013574 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015225 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 0\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 0\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013086 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013363 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014113 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013390 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014446 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013798 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014405 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014038 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014548 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015099 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015158 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014352 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 30\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013859 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014453 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015474 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 116\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012968 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014998 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016258 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012935 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014609 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015283 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014584 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013847 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015518 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014598 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 79\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014904 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013304 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014277 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013020 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014165 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014068 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013920 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013281 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015391 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012926 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013229 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017346 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013166 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 62%|   | 10/16 [03:08<01:37, 16.23s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012934 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 18[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013423 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013914 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013382 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015466 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013889 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012819 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 18\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013643 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014299 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013365 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013417 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013480 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014987 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015449 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013550 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023048 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013392 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013571 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013003 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013446 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013194 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 120[LightGBM] [Info] Total Bins 74\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014038 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014595 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014162 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013944 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016532 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013479 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014563 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013835 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015184 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020784 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020116 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021235 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020374 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023891 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021550 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018719 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024952 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023036 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020383 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020282 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021404 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013188 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014062 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014200 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013007 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013620 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013128 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013957 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012982 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013781 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013337 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018204 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013856 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 73\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013165 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017524 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014463 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014273 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014905 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012940 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013782 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013293 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013575 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014798 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014437 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014872 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015923 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013782 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014673 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014615 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013107 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013427 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013308 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014334 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013432 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Total Bins 76\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013555 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013661 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012971 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012987 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014004 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014493 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013648 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013548 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013135 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014457 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015863 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013089 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015047 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 119[LightGBM] [Info] Total Bins 30\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015752 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013024 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013091 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013829 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013500 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014451 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012809 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014589 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 69%|   | 11/16 [03:23<01:20, 16.01s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014727 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013147 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012845 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014346 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023804 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007398 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013554 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016683 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014105 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 30\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013291 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012956 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013316 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013051 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012853 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013215 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012350 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012938 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013156 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014098 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012859 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013512 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 19\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013526 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013227 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013344 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018407 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 125\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013630 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013792 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012951 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013514 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012992 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014580 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014666 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015064 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014008 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013720 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013576 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014185 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014512 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014139 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028227 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013491 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014499 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015457 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012561 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 18\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012985 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013809 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013744 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 116\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012566 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024472 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015798 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013166 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012564 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013603 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013309 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014234 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 115\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013395 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012874 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013344 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013532 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Total Bins 76\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014075 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013594 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013533 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013691 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014942 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013165 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013847 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014173 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013570 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013521 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013652 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 123\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013156 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015663 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 18[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015069 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015481 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012907 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014246 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015040 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013040 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014646 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022694 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015032 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017152 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015921 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013477 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013960 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015005 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014222 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015242 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013837 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014734 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015562 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014699 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015127 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013802 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014440 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014691 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013766 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013737 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014189 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014096 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014226 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014632 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013819 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014799 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014330 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 75%|  | 12/16 [03:47<01:13, 18.31s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014176 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014407 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015010 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014399 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014115 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013174 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013255 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014682 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013539 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013624 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013315 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013848 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 119\n\n[LightGBM] [Info] Total Bins 18[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015369 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014333 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013608 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015773 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n[LightGBM] [Info] Total Bins 0[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 0\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013196 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013797 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 18\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014448 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013535 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013379 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013820 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012988 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015307 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 19\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013828 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013851 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014637 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021255 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013339 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013146 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016006 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013632 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013020 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014545 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012772 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014583 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013418 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013285 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014622 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012917 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015269 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013098 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014776 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013262 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014434 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017044 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016175 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013224 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013898 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013111 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 19\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012887 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013243 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017321 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013900 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013967 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015953 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012777 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013460 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013481 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013214 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014271 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 81%| | 13/16 [03:56<00:47, 15.67s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012596 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014045 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014702 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009478 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013676 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011209 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015004 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013013 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015198 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011333 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009897 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009583 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013008 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014570 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009857 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012982 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013198 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013729 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009620 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013051 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014556 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013493 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009947 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011792 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014518 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014607 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012719 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010446 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013218 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012096 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009649 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009910 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010263 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014019 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012875 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012217 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009741 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013696 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011291 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009496 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 19\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010807 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013871 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013265 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011277 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 88%| | 14/16 [04:02<00:25, 12.74s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009459 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011289 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009482 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011062 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013122 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012960 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012332 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009590 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017005 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011121 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009513 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009420 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010038 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009608 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 124\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009538 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010401 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012036 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009662 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011002 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009452 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009611 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010041 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009915 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009546 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009705 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009640 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n[LightGBM] [Info] Total Bins 0\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 0\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011282 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009558 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009404 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009449 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009829 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009527 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 123\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009528 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009702 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009761 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010978 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009653 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009363 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011231 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009607 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011366 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009963 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009729 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010093 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009523 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011121 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009442 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011377 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009473 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009585 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009527 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009874 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009579 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009714 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009593 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009535 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009604 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009561 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009821 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009559 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009755 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009554 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009922 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010025 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 94%|| 15/16 [04:14<00:12, 12.48s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009418 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010144 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009695 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009535 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009561 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009504 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009795 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 447182, number of used features: 1\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|| 16/16 [04:19<00:00, 16.23s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "133 same features have been deleted.\nMeet early-stopping in successive feature-wise halving.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  0%|          | 0/16 [00:00<?, ?it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030502 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026601 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028067 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029141 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028047 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Total Bins 76\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027994 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025568 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029842 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 116\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027713 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026663 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025974 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029495 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027661 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026590 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026112 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026669 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026884 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029556 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026366 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027023 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029161 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026750 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028497 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 73\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026446 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Total Bins 76\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026652 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025278 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026360 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026451 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Total Bins 18[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027173 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026216 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027236 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082512 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046420 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012271 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030372 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 28\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026090 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026925 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030889 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027260 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032886 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026766 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026152 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026923 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029648 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025815 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028065 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028984 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025337 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027111 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026754 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028695 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030178 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027535 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026978 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026027 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026690 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029129 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026536 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027809 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027409 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027272 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027139 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026252 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027605 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026568 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028518 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 28\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029811 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028395 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 29\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027694 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031082 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026199 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 77\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026403 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027967 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027323 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028685 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025277 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026037 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028040 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027519 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025378 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026057 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026894 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027049 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028413 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026301 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025567 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027169 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071636 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050564 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Total Bins 18\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052040 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046067 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044608 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045945 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045384 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037723 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040734 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035526 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039850 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038172 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039042 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036458 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 116\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040616 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 19\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042499 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044328 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041858 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047982 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039679 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042000 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 19\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041397 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 73\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038679 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040623 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038248 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038939 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042064 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044867 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058813 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017958 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031277 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038607 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 123\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040806 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027387 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019608 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 28[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025228 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019458 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025792 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025658 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029654 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028878 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027020 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 116\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025152 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025429 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027525 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023123 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026621 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027187 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028886 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028296 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026627 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027757 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031365 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028109 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026999 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025875 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026825 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026261 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027567 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027572 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027658 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025218 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031938 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026229 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029163 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030719 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030478 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030846 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027141 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029222 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028913 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028890 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027356 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027188 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026356 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026495 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027050 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 124\n[LightGBM] [Info] Total Bins 76[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028081 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026614 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027612 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026256 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027972 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025439 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026006 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033458 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 28\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025640 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029140 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026574 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029953 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030036 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026296 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028433 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026851 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027331 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027451 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028009 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026470 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025393 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027556 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Total Bins 77\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026094 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026355 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026337 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Total Bins 77[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025650 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018762 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025785 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 29\n\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033464 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030415 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026653 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025678 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028386 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026078 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026344 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027158 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035479 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026953 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025390 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029014 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026688 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023506 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040823 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 27\n\n[LightGBM] [Info] Total Bins 77[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026203 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026630 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046558 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 76\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028619 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026421 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026536 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025894 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 79[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026368 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 119\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027236 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028124 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 30\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026222 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027127 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039899 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027175 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027688 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033019 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037617 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026614 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028924 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019687 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 28[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019517 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027612 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056757 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049340 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027419 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 19\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028708 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 29\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026618 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030303 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028463 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020124 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026804 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030281 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039182 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056010 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028702 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027769 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049082 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020093 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048589 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027646 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026782 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043887 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026751 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037163 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019384 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027983 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027611 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060519 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032969 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026760 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 79\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027997 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028370 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036296 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030373 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027588 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  6%|         | 1/16 [01:39<24:54, 99.62s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042839 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030966 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046917 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026312 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025811 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043182 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 12%|        | 2/16 [01:43<10:07, 43.41s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027121 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025862 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034607 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025478 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028065 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029386 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027378 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028676 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029090 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 19%|        | 3/16 [01:49<05:40, 26.19s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025714 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019337 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029967 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027459 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026781 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027152 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041400 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056390 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057513 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028138 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012536 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027987 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019423 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020019 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036827 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029484 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028021 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018593 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019251 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 18[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049792 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027326 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031236 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028257 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027782 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029423 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027265 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053428 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027350 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027918 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019443 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026942 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028445 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030345 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030308 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027043 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027869 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 73\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026684 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027047 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026419 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019320 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 76\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019938 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 76[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027580 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Total Bins 17[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030196 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n\n[LightGBM] [Info] Total Bins 27[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056196 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031289 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028318 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028978 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031169 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029502 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 25%|       | 4/16 [02:11<04:55, 24.67s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020215 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028913 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 18[LightGBM] [Info] Total Bins 116\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057592 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046078 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 29[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027307 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032806 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028412 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027005 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031437 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046588 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057360 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027259 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029264 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025938 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027354 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028128 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026935 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 18\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029737 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027257 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030742 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030922 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 30\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029949 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031152 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059687 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026799 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025979 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013596 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029438 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027869 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027489 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026024 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 76\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068294 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030329 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051676 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027495 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027566 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039357 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028083 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014305 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031286 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027624 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053613 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019883 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 117[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038301 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027598 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026029 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048208 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056982 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026881 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030017 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057793 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045966 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036826 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Total Bins 79\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026754 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027741 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029051 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031927 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027033 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029789 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026157 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028234 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016301 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032386 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Total Bins 118\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028304 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026591 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028610 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Total Bins 28[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034513 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033605 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031248 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019521 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065431 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026724 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026609 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Info] Total Bins 18\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028725 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026902 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026304 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037598 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029460 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025902 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012490 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039215 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 29[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025680 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029612 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028397 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 124[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028367 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036525 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027767 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Total Bins 14\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029116 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029396 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035051 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026095 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043728 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119[LightGBM] [Info] Total Bins 28\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027350 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025790 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027011 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028082 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Total Bins 77\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026700 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028499 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027130 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027342 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029495 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027687 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047598 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 115[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046047 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029731 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031313 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027278 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030670 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027865 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035401 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029016 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030391 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 30[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026831 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068480 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027108 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028138 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027297 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036049 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031392 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027610 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029770 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029181 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028836 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 29[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026505 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028276 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054299 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028720 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028614 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027272 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039302 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026630 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028320 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.102095 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.096671 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 30\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038450 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055635 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041674 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 116\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044639 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045084 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026502 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046323 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041060 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018772 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027559 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026388 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027496 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029268 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025799 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028194 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032009 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028383 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028230 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029394 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030937 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030543 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027194 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037521 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030574 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037391 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026233 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029534 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028801 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020749 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038110 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 76[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028730 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026442 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026493 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027616 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028283 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026375 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027760 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025491 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036819 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029725 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Total Bins 30\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029459 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027976 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026981 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026833 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046724 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027566 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027347 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019394 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029264 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029301 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028705 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027487 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046270 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 76\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031683 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026859 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029877 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027135 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037128 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028786 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 30\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027497 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026458 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019449 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028046 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 77\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026767 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027840 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028078 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025899 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 119\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028354 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026910 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029087 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061667 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 30\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028651 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030076 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056186 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051486 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026641 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026964 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026297 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 31%|      | 5/16 [03:22<07:34, 41.33s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046479 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026891 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058273 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036559 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028828 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043704 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019282 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025925 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037760 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027895 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037019 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 114\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027457 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036275 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026608 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 38%|      | 6/16 [03:27<04:49, 28.95s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027373 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026990 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024820 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068459 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028639 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026211 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026456 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026020 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028114 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027096 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 116\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052184 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039331 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026880 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052507 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027418 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026719 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014381 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027448 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027987 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029157 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027495 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037964 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027117 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029608 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049257 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026231 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055725 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 116\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041128 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027745 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027592 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026093 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 73[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026814 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 27[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028678 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030837 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032165 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 28[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 30\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 44%|     | 7/16 [03:38<03:28, 23.18s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026871 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028295 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039254 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056672 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056342 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048943 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031892 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027900 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029895 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026081 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028792 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026276 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028941 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031239 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026780 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060832 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033800 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019500 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048327 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029038 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026751 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027584 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026716 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013582 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030477 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046499 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028950 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Total Bins 119\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030531 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061098 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025917 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 30\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027090 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046568 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026214 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 125\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029735 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026216 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027947 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 125\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027756 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029522 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027470 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027930 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026814 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027129 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 18\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027182 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 114\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026666 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028892 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026793 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026973 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057083 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Info] Total Bins 75[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030783 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 30\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014535 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027164 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026731 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026969 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028052 seconds.\nYou can set `force_col_wise=true` to remove the overhead.",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 50%|     | 8/16 [03:57<02:52, 21.60s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027702 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024897 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025804 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019959 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037498 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053550 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030451 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048259 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024777 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028106 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026818 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 77[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031310 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028724 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059412 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034489 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037964 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027483 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026149 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028296 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029633 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033276 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027782 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026226 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 119[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032859 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Total Bins 28\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029612 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020023 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028208 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030026 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 18[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027934 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028281 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060892 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047936 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028656 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021977 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026374 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026265 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027846 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025572 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031180 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033515 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 29\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Total Bins 117\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026603 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028612 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029473 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026065 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018085 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026077 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042553 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26[LightGBM] [Info] Total Bins 27\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026714 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027050 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019265 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027385 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026720 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026699 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028301 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060888 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025912 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026862 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029201 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026184 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028450 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028765 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030863 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046841 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 126\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034794 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027819 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027092 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029439 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028367 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028832 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028937 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027263 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049105 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026364 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027269 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029221 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028675 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028306 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013439 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032264 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030043 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052907 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029065 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048866 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027036 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036184 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056449 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029244 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026900 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028376 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066414 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027354 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027432 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028070 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055520 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027181 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014372 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\n[LightGBM] [Info] Total Bins 124\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026609 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026763 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031491 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026867 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026516 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026625 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026440 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040762 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059032 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020046 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019138 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085118 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056549 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026323 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015793 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 116\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025880 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027092 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026416 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026913 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028104 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020027 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030063 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026221 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045538 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 19\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027316 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049259 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013122 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 116[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026886 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026676 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028931 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027065 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055865 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 25[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029543 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Total Bins 18\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029590 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026946 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026858 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020053 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030996 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026009 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019319 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 76[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027030 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027050 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026976 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014094 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029401 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029791 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032033 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019509 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037245 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028661 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030607 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030004 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029448 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059538 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027356 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045148 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 75\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057442 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026805 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040724 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050352 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030878 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027723 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039191 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030687 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058343 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019327 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026968 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028753 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 56%|    | 9/16 [04:57<03:55, 33.63s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026465 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028540 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027057 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029033 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026804 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028392 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027555 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028591 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019964 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030936 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 62%|   | 10/16 [05:03<02:31, 25.18s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019872 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026519 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 77\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035959 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057990 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026082 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046773 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032357 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Total Bins 27\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028267 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026115 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026790 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026981 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033471 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033333 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 115\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057378 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027446 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 116\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029956 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027504 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033058 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026433 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026315 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026201 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030060 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 17\n\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057860 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022383 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 73\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053076 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026938 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026288 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051096 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028493 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026967 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027113 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26[LightGBM] [Info] Total Bins 118\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037433 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028927 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014316 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027510 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026673 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029760 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028400 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055735 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 79[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026747 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Total Bins 77[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028591 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027122 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031308 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027593 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026987 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029962 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028355 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027686 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028684 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030750 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 73\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053744 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055937 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014340 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027322 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046619 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 116\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028579 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028697 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029283 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030327 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026769 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030034 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027171 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026127 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026426 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029517 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 30\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058198 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033962 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029863 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049317 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027436 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038579 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 19\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025310 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 123\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026827 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026288 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 19\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027179 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028371 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027822 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031469 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026704 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027209 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027619 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027844 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026063 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027021 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027170 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028211 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029703 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 29[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027201 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053691 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029017 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027104 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026707 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033002 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027930 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027231 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 75\n\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026948 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026466 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030788 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029856 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 30\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026474 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026947 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 18[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042101 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 29[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026563 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031604 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 28[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026606 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 69%|   | 11/16 [05:36<02:17, 27.56s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038747 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019224 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 119[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047446 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 127\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056645 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028333 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067962 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027762 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032711 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027522 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027963 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047555 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Total Bins 0\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 0\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029454 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 77[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046396 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027133 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040050 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Total Bins 17[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035223 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 18[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027440 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033012 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052386 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 76[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029585 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Total Bins 26\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027071 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026402 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 120\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028163 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027483 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 118\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028171 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019908 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029569 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048193 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026058 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046805 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043564 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026051 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Total Bins 122[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026344 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026582 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028918 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031075 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047667 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 13\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027720 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026178 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037718 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027505 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026150 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029102 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 75%|  | 12/16 [05:51<01:35, 23.93s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031567 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055936 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029730 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027293 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026071 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027472 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028458 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027938 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030495 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029910 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026615 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025830 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028027 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019271 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027779 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028166 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026231 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036891 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031574 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026718 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029052 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028936 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026031 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028022 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026239 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028148 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028026 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056348 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035126 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027602 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028026 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025881 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039560 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033265 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020052 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033250 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038488 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026937 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028643 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 28[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027033 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030214 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027335 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Total Bins 117\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026834 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027083 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026224 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 19[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027870 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029880 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029710 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031939 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026307 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 116\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027407 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028163 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025513 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028696 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030960 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028214 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 30\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026289 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058753 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025540 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030060 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025833 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056742 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026909 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029308 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028442 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 30\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028522 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019269 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 28[LightGBM] [Info] Total Bins 77\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028054 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033050 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028965 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045969 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 30[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028863 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035006 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027376 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029221 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029571 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029612 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060077 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027276 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 12\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027246 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020061 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031671 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027702 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026497 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056284 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030264 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 121\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033407 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019228 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029628 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026096 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026777 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027901 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029614 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027076 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027620 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030367 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027566 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049027 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027935 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057818 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026909 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027088 seconds.\nYou can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030595 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Info] Total Bins 76\n\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027015 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026263 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028676 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059764 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027663 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026780 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019236 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027516 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046659 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028318 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028655 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028139 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027312 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019370 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 81%| | 13/16 [06:33<01:27, 29.25s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026293 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028278 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 88%| | 14/16 [06:34<00:41, 20.74s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027997 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027983 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027030 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 19\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019379 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029422 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029177 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021649 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018790 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019186 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029741 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 30\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019126 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026956 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026576 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028970 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027280 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030185 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026346 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025976 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027097 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033494 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027724 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022223 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027437 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022632 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026945 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019162 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024601 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026957 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019285 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022654 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026982 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022109 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029261 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018897 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026210 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026558 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 116\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022143 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026425 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028237 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019300 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 76\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031298 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025817 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029615 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025824 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026447 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018944 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019084 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 122\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029700 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019081 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 75\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027698 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028729 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026189 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022187 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019136 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026877 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021963 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 30\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027397 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019255 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 74\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047224 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 120\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033096 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022230 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026529 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031024 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019222 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 78\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 94%|| 15/16 [07:04<00:23, 23.63s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018905 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 19\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019901 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018871 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 17\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018941 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 26\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019939 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018886 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 25\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021930 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022455 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 27\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018860 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025875 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022452 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 117\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020021 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019918 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020380 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 77\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019002 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 119\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018756 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 18\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019409 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 118\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019895 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 14\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019868 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021969 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 28\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 1\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|| 16/16 [07:31<00:00, 28.21s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "The number of remaining candidate features is 451\nStart stage II selection.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|| 16/16 [00:58<00:00,  3.68s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Finish data processing.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 8.733446 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 16443\n[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 470\nCPU times: user 1h 22min 53s, sys: 1min 29s, total: 1h 24min 22s\nWall time: 36min 47s\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_new, test_new = transform(train_df.drop(y_names,axis=1), test_df, features[:300], n_jobs=n_jobs)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-29T08:16:41.725915Z",
          "iopub.execute_input": "2024-05-29T08:16:41.726404Z",
          "iopub.status.idle": "2024-05-29T08:17:14.055704Z",
          "shell.execute_reply.started": "2024-05-29T08:16:41.726362Z",
          "shell.execute_reply": "2024-05-29T08:17:14.053949Z"
        },
        "trusted": true,
        "id": "2rAZZQ0R_8Kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_new, test_new = transform(train_subset.drop(y_names,axis=1), test_subset, features1[:300], n_jobs=n_jobs)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-29T08:17:14.05778Z",
          "iopub.execute_input": "2024-05-29T08:17:14.058244Z",
          "iopub.status.idle": "2024-05-29T08:17:14.065346Z",
          "shell.execute_reply.started": "2024-05-29T08:17:14.058205Z",
          "shell.execute_reply": "2024-05-29T08:17:14.064117Z"
        },
        "trusted": true,
        "id": "cmzVPEzD_8Ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge train_new with train_df to add the 'FloodProbability' column\n",
        "merged_train_new = pd.merge(train_new, train_df[['FloodProbability']], left_index=True, right_index=True)\n",
        "merged_train_new"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-29T08:17:14.068357Z",
          "iopub.execute_input": "2024-05-29T08:17:14.06938Z",
          "iopub.status.idle": "2024-05-29T08:17:15.721255Z",
          "shell.execute_reply.started": "2024-05-29T08:17:14.069331Z",
          "shell.execute_reply": "2024-05-29T08:17:15.720044Z"
        },
        "trusted": true,
        "id": "bsK2BfQk_8Kz",
        "outputId": "f7172020-019f-42a7-b82a-59e84f3ec52a"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 27,
          "output_type": "execute_result",
          "data": {
            "text/plain": "              MonsoonIntensity  TopographyDrainage  RiverManagement  \\\nopenfe_index                                                          \n0                            5                   8                5   \n1                            6                   7                4   \n2                            6                   5                6   \n3                            3                   4                6   \n4                            5                   3                2   \n...                        ...                 ...              ...   \n1117952                      3                   3                4   \n1117953                      2                   2                4   \n1117954                      7                   3                9   \n1117955                      7                   3                3   \n1117956                      4                   5                6   \n\n              Deforestation  Urbanization  ClimateChange  DamsQuality  \\\nopenfe_index                                                            \n0                         8             6              4            4   \n1                         4             8              8            3   \n2                         7             3              7            1   \n3                         5             4              8            4   \n4                         6             4              4            3   \n...                     ...           ...            ...          ...   \n1117952                  10             4              5            5   \n1117953                   3             9              5            8   \n1117954                   4             6              5            9   \n1117955                   7             5              2            3   \n1117956                   9             5              5            2   \n\n              Siltation  AgriculturalPractices  Encroachments  ...  \\\nopenfe_index                                                   ...   \n0                     3                      3              4  ...   \n1                     5                      4              6  ...   \n2                     5                      4              5  ...   \n3                     7                      6              8  ...   \n4                     3                      3              3  ...   \n...                 ...                    ...            ...  ...   \n1117952               7                     10              4  ...   \n1117953               1                      3              5  ...   \n1117954               1                      3              4  ...   \n1117955               4                      6              4  ...   \n1117956               8                      4              5  ...   \n\n              autoFE_f_291  autoFE_f_292  autoFE_f_293  autoFE_f_294  \\\nopenfe_index                                                           \n0                     35.0           1.0          13.0          15.0   \n1                     28.0           1.0          14.0           9.0   \n2                     21.0          -4.0          12.0           6.0   \n3                     14.0           2.0           6.0          25.0   \n4                      6.0           2.0           5.0          10.0   \n...                    ...           ...           ...           ...   \n1117952               42.0          -3.0          10.0          16.0   \n1117953               36.0           0.0          11.0          45.0   \n1117954               10.0           1.0           8.0          20.0   \n1117955               36.0          -1.0           9.0          28.0   \n1117956               28.0           1.0           9.0          56.0   \n\n              autoFE_f_295  autoFE_f_296  autoFE_f_297  autoFE_f_298  \\\nopenfe_index                                                           \n0                     12.0           3.0           7.0          12.0   \n1                     10.0           4.0           5.0          18.0   \n2                      9.0           5.0           8.0          15.0   \n3                     10.0           5.0           7.0          40.0   \n4                      8.0           3.0           3.0          15.0   \n...                    ...           ...           ...           ...   \n1117952                9.0           7.0           7.0          16.0   \n1117953                6.0           1.0           4.0          25.0   \n1117954                9.0           1.0           5.0          16.0   \n1117955               13.0           4.0           6.0          16.0   \n1117956               11.0           8.0           8.0          40.0   \n\n              autoFE_f_299  FloodProbability  \nopenfe_index                                  \n0                 0.714286             0.445  \n1                 1.333333             0.450  \n2                 0.750000             0.530  \n3                 1.000000             0.535  \n4                 2.000000             0.415  \n...                    ...               ...  \n1117952           4.000000             0.495  \n1117953           1.000000             0.480  \n1117954           1.800000             0.485  \n1117955           0.500000             0.495  \n1117956           1.000000             0.560  \n\n[1117957 rows x 321 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MonsoonIntensity</th>\n      <th>TopographyDrainage</th>\n      <th>RiverManagement</th>\n      <th>Deforestation</th>\n      <th>Urbanization</th>\n      <th>ClimateChange</th>\n      <th>DamsQuality</th>\n      <th>Siltation</th>\n      <th>AgriculturalPractices</th>\n      <th>Encroachments</th>\n      <th>...</th>\n      <th>autoFE_f_291</th>\n      <th>autoFE_f_292</th>\n      <th>autoFE_f_293</th>\n      <th>autoFE_f_294</th>\n      <th>autoFE_f_295</th>\n      <th>autoFE_f_296</th>\n      <th>autoFE_f_297</th>\n      <th>autoFE_f_298</th>\n      <th>autoFE_f_299</th>\n      <th>FloodProbability</th>\n    </tr>\n    <tr>\n      <th>openfe_index</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>8</td>\n      <td>5</td>\n      <td>8</td>\n      <td>6</td>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>3</td>\n      <td>4</td>\n      <td>...</td>\n      <td>35.0</td>\n      <td>1.0</td>\n      <td>13.0</td>\n      <td>15.0</td>\n      <td>12.0</td>\n      <td>3.0</td>\n      <td>7.0</td>\n      <td>12.0</td>\n      <td>0.714286</td>\n      <td>0.445</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6</td>\n      <td>7</td>\n      <td>4</td>\n      <td>4</td>\n      <td>8</td>\n      <td>8</td>\n      <td>3</td>\n      <td>5</td>\n      <td>4</td>\n      <td>6</td>\n      <td>...</td>\n      <td>28.0</td>\n      <td>1.0</td>\n      <td>14.0</td>\n      <td>9.0</td>\n      <td>10.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>18.0</td>\n      <td>1.333333</td>\n      <td>0.450</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>5</td>\n      <td>6</td>\n      <td>7</td>\n      <td>3</td>\n      <td>7</td>\n      <td>1</td>\n      <td>5</td>\n      <td>4</td>\n      <td>5</td>\n      <td>...</td>\n      <td>21.0</td>\n      <td>-4.0</td>\n      <td>12.0</td>\n      <td>6.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>8.0</td>\n      <td>15.0</td>\n      <td>0.750000</td>\n      <td>0.530</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>4</td>\n      <td>6</td>\n      <td>5</td>\n      <td>4</td>\n      <td>8</td>\n      <td>4</td>\n      <td>7</td>\n      <td>6</td>\n      <td>8</td>\n      <td>...</td>\n      <td>14.0</td>\n      <td>2.0</td>\n      <td>6.0</td>\n      <td>25.0</td>\n      <td>10.0</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>40.0</td>\n      <td>1.000000</td>\n      <td>0.535</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>3</td>\n      <td>2</td>\n      <td>6</td>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>10.0</td>\n      <td>8.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>15.0</td>\n      <td>2.000000</td>\n      <td>0.415</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1117952</th>\n      <td>3</td>\n      <td>3</td>\n      <td>4</td>\n      <td>10</td>\n      <td>4</td>\n      <td>5</td>\n      <td>5</td>\n      <td>7</td>\n      <td>10</td>\n      <td>4</td>\n      <td>...</td>\n      <td>42.0</td>\n      <td>-3.0</td>\n      <td>10.0</td>\n      <td>16.0</td>\n      <td>9.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>16.0</td>\n      <td>4.000000</td>\n      <td>0.495</td>\n    </tr>\n    <tr>\n      <th>1117953</th>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>3</td>\n      <td>9</td>\n      <td>5</td>\n      <td>8</td>\n      <td>1</td>\n      <td>3</td>\n      <td>5</td>\n      <td>...</td>\n      <td>36.0</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>45.0</td>\n      <td>6.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>25.0</td>\n      <td>1.000000</td>\n      <td>0.480</td>\n    </tr>\n    <tr>\n      <th>1117954</th>\n      <td>7</td>\n      <td>3</td>\n      <td>9</td>\n      <td>4</td>\n      <td>6</td>\n      <td>5</td>\n      <td>9</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>...</td>\n      <td>10.0</td>\n      <td>1.0</td>\n      <td>8.0</td>\n      <td>20.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>16.0</td>\n      <td>1.800000</td>\n      <td>0.485</td>\n    </tr>\n    <tr>\n      <th>1117955</th>\n      <td>7</td>\n      <td>3</td>\n      <td>3</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>6</td>\n      <td>4</td>\n      <td>...</td>\n      <td>36.0</td>\n      <td>-1.0</td>\n      <td>9.0</td>\n      <td>28.0</td>\n      <td>13.0</td>\n      <td>4.0</td>\n      <td>6.0</td>\n      <td>16.0</td>\n      <td>0.500000</td>\n      <td>0.495</td>\n    </tr>\n    <tr>\n      <th>1117956</th>\n      <td>4</td>\n      <td>5</td>\n      <td>6</td>\n      <td>9</td>\n      <td>5</td>\n      <td>5</td>\n      <td>2</td>\n      <td>8</td>\n      <td>4</td>\n      <td>5</td>\n      <td>...</td>\n      <td>28.0</td>\n      <td>1.0</td>\n      <td>9.0</td>\n      <td>56.0</td>\n      <td>11.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>40.0</td>\n      <td>1.000000</td>\n      <td>0.560</td>\n    </tr>\n  </tbody>\n</table>\n<p>1117957 rows  321 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cont_names,cat_names = cont_cat_split(merged_train_new, dep_var='FloodProbability')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-29T08:17:15.72254Z",
          "iopub.execute_input": "2024-05-29T08:17:15.722875Z",
          "iopub.status.idle": "2024-05-29T08:17:15.870269Z",
          "shell.execute_reply.started": "2024-05-29T08:17:15.722845Z",
          "shell.execute_reply": "2024-05-29T08:17:15.869111Z"
        },
        "trusted": true,
        "id": "U928mKuS_8K0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splits = RandomSplitter(valid_pct=0.2)(range_of(merged_train_new))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-29T08:17:15.871569Z",
          "iopub.execute_input": "2024-05-29T08:17:15.871922Z",
          "iopub.status.idle": "2024-05-29T08:17:16.10722Z",
          "shell.execute_reply.started": "2024-05-29T08:17:15.871883Z",
          "shell.execute_reply": "2024-05-29T08:17:16.105966Z"
        },
        "trusted": true,
        "id": "peTtA3Co_8K1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to = TabularPandas(merged_train_new, procs=[Categorify, FillMissing,Normalize],\n",
        "                   cat_names = cat_names,\n",
        "                   cont_names = cont_names,\n",
        "                   y_names='FloodProbability',\n",
        "                   y_block=RegressionBlock(),\n",
        "                   splits=splits)"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2024-05-29T08:17:16.109096Z",
          "iopub.execute_input": "2024-05-29T08:17:16.10946Z",
          "iopub.status.idle": "2024-05-29T08:17:40.793492Z",
          "shell.execute_reply.started": "2024-05-29T08:17:16.109431Z",
          "shell.execute_reply": "2024-05-29T08:17:40.792286Z"
        },
        "trusted": true,
        "id": "QXmfNgme_8K2",
        "outputId": "7508047e-fb84-4d4e-9291-bcd95ad821dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:314: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  to.loc[:,n+'_na'] = missing[n]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = to.train.xs, to.train.ys.values.ravel()\n",
        "X_test, y_test = to.valid.xs, to.valid.ys.values.ravel()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-29T08:17:40.795423Z",
          "iopub.execute_input": "2024-05-29T08:17:40.795884Z",
          "iopub.status.idle": "2024-05-29T08:17:43.556616Z",
          "shell.execute_reply.started": "2024-05-29T08:17:40.795842Z",
          "shell.execute_reply": "2024-05-29T08:17:43.555455Z"
        },
        "trusted": true,
        "id": "Lerc94Ua_8K3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dls = to.dataloaders(bs=64)\n",
        "test_dl = dls.test_dl(test_new)"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2024-05-29T08:17:43.558469Z",
          "iopub.execute_input": "2024-05-29T08:17:43.55942Z",
          "iopub.status.idle": "2024-05-29T08:17:50.058628Z",
          "shell.execute_reply.started": "2024-05-29T08:17:43.55937Z",
          "shell.execute_reply": "2024-05-29T08:17:50.057343Z"
        },
        "trusted": true,
        "id": "cjPGIb-z_8K4",
        "outputId": "e61c9f60-7b00-4962-9644-9e7f1afa8c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  to[n].fillna(self.na_dict[n], inplace=True)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'df' is your DataFrame\n",
        "#merged_train_new.to_csv('merged_train_new.csv', index=False, encoding='utf-8')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-29T08:17:50.063524Z",
          "iopub.execute_input": "2024-05-29T08:17:50.063899Z",
          "iopub.status.idle": "2024-05-29T08:17:50.068926Z",
          "shell.execute_reply.started": "2024-05-29T08:17:50.063869Z",
          "shell.execute_reply": "2024-05-29T08:17:50.067376Z"
        },
        "trusted": true,
        "id": "RTLzXvF2_8K5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#merged_train_new.to_pickle('merged_train_new.pkl')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-29T08:17:50.070978Z",
          "iopub.execute_input": "2024-05-29T08:17:50.071508Z",
          "iopub.status.idle": "2024-05-29T08:17:50.081127Z",
          "shell.execute_reply.started": "2024-05-29T08:17:50.071464Z",
          "shell.execute_reply": "2024-05-29T08:17:50.079985Z"
        },
        "trusted": true,
        "id": "WpST-bsm_8K6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FileLink('merged_train_new.csv')\n",
        "#FileLink('merged_train_new.pkl')"
      ],
      "metadata": {
        "trusted": true,
        "id": "QZbdDTza_8K6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest with openFE features\n",
        "\n",
        "We initially use a random forest as a baseline since it is a really simple model that doesnt break easily with small changes in the hyperparameters etc.\n",
        "\n",
        "We can also easily use this for explanability with features such as feature importance."
      ],
      "metadata": {
        "id": "cL6tI3CU_8K8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "rf = RandomForestRegressor(50, min_samples_leaf=3)\n",
        "rf_model = rf.fit(X_train, y_train);\n",
        "\n",
        "rf_preds = tensor(rf_model.predict(test_dl.xs))\n",
        "\n",
        "rf_preds_x = tensor(rf_model.predict(X_test))\n",
        "\n",
        "#mse = mean_absolute_error(y_test, rf_preds_x)\n",
        "#rmse = np.sqrt(mse)\n",
        "\n",
        "r2_score(y_test,rf_preds_x)"
      ],
      "metadata": {
        "trusted": true,
        "id": "UjzXxgfX_8K8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(dict(cols=X_train.columns, imp=rf.feature_importances_)).plot('cols', 'imp', 'barh');"
      ],
      "metadata": {
        "id": "c5FCoOVq_8K9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network with openFE features"
      ],
      "metadata": {
        "id": "UgFHxrCO_8K9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = tabular_learner(dls, metrics=R2Score())\n",
        "learn.lr_find(suggest_funcs=(slide,valley))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-29T10:58:21.016587Z",
          "iopub.execute_input": "2024-05-29T10:58:21.018033Z",
          "iopub.status.idle": "2024-05-29T10:58:21.059368Z",
          "shell.execute_reply.started": "2024-05-29T10:58:21.017986Z",
          "shell.execute_reply": "2024-05-29T10:58:21.057872Z"
        },
        "trusted": true,
        "id": "bBKduamm_8LO",
        "outputId": "6403a200-81b2-414f-b5de-80487a8f4b9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m learn \u001b[38;5;241m=\u001b[39m \u001b[43mtabular_learner\u001b[49m(dls, metrics\u001b[38;5;241m=\u001b[39mR2Score())\n\u001b[1;32m      2\u001b[0m learn\u001b[38;5;241m.\u001b[39mlr_find(suggest_funcs\u001b[38;5;241m=\u001b[39m(slide,valley))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tabular_learner' is not defined"
          ],
          "ename": "NameError",
          "evalue": "name 'tabular_learner' is not defined",
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "learn.fit_one_cycle(12,0.012)"
      ],
      "metadata": {
        "trusted": true,
        "id": "dVVcSf-x_8LP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dl = learn.dls.test_dl(test_new)\n"
      ],
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "id": "pm40ASEk_8LR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "nn_preds = learn.get_preds(dl=dl)\n",
        "nn_preds_x = learn.get_preds()[0]\n",
        "a_preds, _ = learn.get_preds(dl=dl)\n",
        "nn_preds_y = a_preds.squeeze(1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "OeLNDbwp_8LS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.export('models/fp_model.pkl')"
      ],
      "metadata": {
        "trusted": true,
        "id": "KlNtVPpe_8LT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#learn.load('fp_model.pkl')"
      ],
      "metadata": {
        "trusted": true,
        "id": "1TlvN39n_8LU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset no original training subset with new openFE features\n",
        "r2_score(y_test,nn_preds_x)"
      ],
      "metadata": {
        "trusted": true,
        "id": "juWivotI_8LV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset no original training subset with new openFE features\n",
        "r2_score(y_test,nn_preds_x)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZQ_-XbtH_8LW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network Ensemble"
      ],
      "metadata": {
        "id": "75E_pjgO_8LW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ensemble():\n",
        "    learn = tabular_learner(dls, metrics=RocAucMulti())\n",
        "    with learn.no_bar(),learn.no_logging(): learn.fit(6, 0.02)\n",
        "    return learn.get_preds(dl=dl)[0]"
      ],
      "metadata": {
        "trusted": true,
        "id": "Gsi88cA5_8LX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learns = [ensemble() for _ in range(5)]"
      ],
      "metadata": {
        "trusted": true,
        "id": "wK8O6o3L_8LX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ens_preds = torch.stack(learns).mean(0)"
      ],
      "metadata": {
        "trusted": true,
        "id": "xUlI9CSG_8LY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_preds_x.shape,ens_preds.shape"
      ],
      "metadata": {
        "trusted": true,
        "id": "bbGl6BUp_8LZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(y_test,nn_preds_x)"
      ],
      "metadata": {
        "trusted": true,
        "id": "akcVt1Od_8LZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_preds = nn_preds[0]"
      ],
      "metadata": {
        "trusted": true,
        "id": "U_6Z8qnF_8La"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['FloodProbability'] = target_preds"
      ],
      "metadata": {
        "trusted": true,
        "id": "Y_hOZQRf_8La"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_csv('submission.csv', columns=['FloodProbability'], index=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "zdr1ZYj3_8Lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv('submission.csv')\n",
        "submission.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "5iqvRPLv_8Lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm submission.csv"
      ],
      "metadata": {
        "trusted": true,
        "id": "LxMooaAj_8Ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['FloodProbability'] = target_preds\n",
        "test_df.to_csv('submission.csv', columns=['FloodProbability'], index=True)\n",
        "\n",
        "submission = pd.read_csv('submission.csv')\n",
        "submission.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "FwUDs3as_8Lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dl"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-29T05:05:27.684835Z",
          "iopub.execute_input": "2024-05-29T05:05:27.68836Z",
          "iopub.status.idle": "2024-05-29T05:05:27.712192Z",
          "shell.execute_reply.started": "2024-05-29T05:05:27.688215Z",
          "shell.execute_reply": "2024-05-29T05:05:27.708516Z"
        },
        "trusted": true,
        "id": "hkB5gcy-_8Lg",
        "outputId": "284759e2-2072-4c0a-cb4a-6bcd87f43ff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 31,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<fastai.tabular.core.TabDataLoader at 0x7d90b4d36560>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CatBoost with openFE features"
      ],
      "metadata": {
        "id": "7xlzrwIO_8Lh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_model = CatBoostRegressor(iterations=1500, depth=8, learning_rate= 0.012, random_strength=8)\n",
        "cat_model = cat_model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False)\n",
        "\n",
        "#test set preds\n",
        "cat_preds = tensor(cat_model.predict(test_dl.xs))\n",
        "\n",
        "#validation set preds\n",
        "cat_preds_x = tensor(cat_model.predict(X_test))\n",
        "\n",
        "r2_score(y_test,cat_preds_x)"
      ],
      "metadata": {
        "trusted": true,
        "id": "upZM2JxX_8Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LightGBM with openFE features"
      ],
      "metadata": {
        "id": "9I_5QOFX_8Li"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_model = lgb.LGBMRegressor(num_leaves=435, learning_rate=0.0137267854143469, n_estimators=380, max_depth=1, boosting_type='gbdt',min_child_samples=171, random_state=27,subsample_for_bin=161411, reg_alpha=4.885489650124004, reg_lambda=0.3204538963056391, colsample_bytree =  0.8025591720341736, subsample= 0.8291001995890841)\n",
        "lgb_model = lgb_model.fit(X_train, y_train)\n",
        "\n",
        "#test set preds\n",
        "lgb_preds = tensor(lgb_model.predict(test_dl.xs))\n",
        "\n",
        "#validation set preds\n",
        "lgb_preds_x = tensor(lgb_model.predict(X_test))\n",
        "\n",
        "lgb_score = r2_score(y_test,lgb_preds_x)\n",
        "lgb_score"
      ],
      "metadata": {
        "trusted": true,
        "id": "mk25Eyfo_8Li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost with openFE features"
      ],
      "metadata": {
        "id": "a2pHBsh7_8Lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = xgb.XGBRegressor(n_estimators = 196, max_depth=5, learning_rate=0.1461774202844157, subsample= 0.6649609199174655)\n",
        "xgb_model = xgb_model.fit(X_train, y_train)\n",
        "\n",
        "xgb_preds = tensor(xgb_model.predict(test_dl.xs))\n",
        "\n",
        "xgb_preds_x = tensor(xgb_model.predict(X_test))\n",
        "\n",
        "r2_score(y_test,xgb_preds_x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-29T09:50:33.859939Z",
          "iopub.status.idle": "2024-05-29T09:50:33.860537Z",
          "shell.execute_reply.started": "2024-05-29T09:50:33.860258Z",
          "shell.execute_reply": "2024-05-29T09:50:33.860282Z"
        },
        "trusted": true,
        "id": "LAbOJ9ko_8Ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_importance(xgb_model)"
      ],
      "metadata": {
        "id": "gVmTxMxX_8Ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Importance"
      ],
      "metadata": {
        "id": "mF15vvLq_8Lm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_importance(xgb_model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-29T09:50:33.862539Z",
          "iopub.status.idle": "2024-05-29T09:50:33.863101Z",
          "shell.execute_reply.started": "2024-05-29T09:50:33.862804Z",
          "shell.execute_reply": "2024-05-29T09:50:33.862828Z"
        },
        "trusted": true,
        "id": "6pcRMjjL_8Ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(dict(cols=X_train.columns, imp=rf.feature_importances_)).plot('cols', 'imp', 'barh');"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-29T09:50:33.865063Z",
          "iopub.status.idle": "2024-05-29T09:50:33.865637Z",
          "shell.execute_reply.started": "2024-05-29T09:50:33.865347Z",
          "shell.execute_reply": "2024-05-29T09:50:33.865371Z"
        },
        "trusted": true,
        "id": "hqnpbmr3_8Lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rJQpQpiK_8Lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drop features"
      ],
      "metadata": {
        "id": "ODebvofz_8Lq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PyjliH17_8Lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimize Params with Optuna"
      ],
      "metadata": {
        "id": "DHVy6Uyc_8Lr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CatBoost - Optuna"
      ],
      "metadata": {
        "id": "1h9jNeEr_8Ls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_catboost(trial):\n",
        "    params = {\n",
        "        \"iterations\": 200,\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
        "        \"depth\": trial.suggest_int(\"depth\", 1, 10),\n",
        "        \"random_strength\": trial.suggest_int(\"random_strength\", 1, 10),\n",
        "    }\n",
        "    model = CatBoostRegressor(**params, silent=True)\n",
        "    model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False)\n",
        "    cat_predictions = model.predict(X_test)\n",
        "    r2score = r2_score(y_test, cat_predictions)\n",
        "    return r2score\n",
        "\n",
        "\n",
        "study_catboost = optuna.create_study(direction='minimize')\n",
        "study_catboost.optimize(objective_catboost, n_trials=200)\n",
        "print(study_catboost.best_params)"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "trusted": true,
        "id": "onS8PNgM_8Lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LightGBM - Optuna"
      ],
      "metadata": {
        "id": "Uf44GnOI_8Lx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "def objective_lgbm(trial):\n",
        "    params = {\n",
        "            'num_leaves': trial.suggest_int('num_leaves', 100, 500),\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0, log=True),\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 300, 1200),\n",
        "            'subsample_for_bin': trial.suggest_int('subsample_for_bin', 20000, 300000),\n",
        "            'min_child_samples': trial.suggest_int('min_child_samples', 20, 500),\n",
        "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-9, 10.0, log=True),\n",
        "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-9, 10.0, log=True),\n",
        "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n",
        "            'subsample': trial.suggest_float('subsample', 0.25, 1.0),\n",
        "            'max_depth': trial.suggest_int('max_depth', 1, 15)\n",
        "            }\n",
        "\n",
        "    model = lgb.LGBMRegressor(**params,verbose=False)\n",
        "    model.fit(X_train, y_train)\n",
        "    lgb_predictions = model.predict(X_test)\n",
        "    r2score = r2_score(y_test, lgb_predictions)\n",
        "    return r2score\n",
        "\n",
        "\n",
        "study_lgbm = optuna.create_study(direction='minimize')\n",
        "study_lgbm.optimize(objective_lgbm, n_trials=100)\n",
        "print(study_lgbm.best_params)"
      ],
      "metadata": {
        "trusted": true,
        "id": "iVb8I-lX_8MB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost - Optuna"
      ],
      "metadata": {
        "id": "65t5DCXG_8MC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_xgboost(trial):\n",
        "    params = {\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 200),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 10),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.1, 1.0),\n",
        "    }\n",
        "    model = xgb.XGBRegressor(**params)\n",
        "    model.fit(X_train, y_train)\n",
        "    xgb_predictions = model.predict(X_test)\n",
        "    rmse = mean_squared_error(y_test, xgb_predictions, squared=False)\n",
        "    return rmse\n",
        "\n",
        "study_xgboost = optuna.create_study(direction='minimize')\n",
        "study_xgboost.optimize(objective_xgboost, n_trials=150)\n",
        "print(study_xgboost.best_params)"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "trusted": true,
        "id": "eSk442mS_8MC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models with optuna optimized hyperparameters"
      ],
      "metadata": {
        "id": "E1X2eiJx_8MD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CatBoost with optuna params"
      ],
      "metadata": {
        "id": "XWwSd_xy_8ME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(study_catboost.best_params)"
      ],
      "metadata": {
        "trusted": true,
        "id": "5otM4P4U_8MF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#with optuna params\n",
        "cat_model = CatBoostRegressor(iterations=1441, depth=1, learning_rate= 0.01000456241465664, random_strength=10)\n",
        "cat_model = cat_model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False)\n",
        "\n",
        "#test set preds\n",
        "cat_preds = tensor(cat_model.predict(test_dl.xs))\n",
        "\n",
        "#validation set preds\n",
        "cat_preds_x = tensor(cat_model.predict(X_test))\n",
        "\n",
        "r2_score(y_test,cat_preds_x)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ofNq3NH8_8NF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LightGBM with optuna params"
      ],
      "metadata": {
        "id": "sqHrJRaj_8NI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(study_lgbm.best_params)"
      ],
      "metadata": {
        "trusted": true,
        "id": "CaphLMEm_8NK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_model = lgb.LGBMRegressor(num_leaves=435, learning_rate=0.0137267854143469, n_estimators=380, max_depth=1, boosting_type='gbdt',min_child_samples=171, random_state=27,subsample_for_bin=161411, reg_alpha=4.885489650124004, reg_lambda=0.3204538963056391, colsample_bytree =  0.8025591720341736, subsample= 0.8291001995890841)\n",
        "lgb_model = lgb_model.fit(X_train, y_train)\n",
        "\n",
        "#test set preds\n",
        "lgb_preds = tensor(lgb_model.predict(test_dl.xs))\n",
        "\n",
        "#validation set preds\n",
        "lgb_preds_x = tensor(lgb_model.predict(X_test))\n",
        "\n",
        "lgb_score = r2_score(y_test,lgb_preds_x)\n",
        "lgb_score"
      ],
      "metadata": {
        "trusted": true,
        "id": "G0m_tvkg_8NP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost with optuna params"
      ],
      "metadata": {
        "id": "msVaVJd0_8NQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = xgb.XGBRegressor(n_estimators = 196, max_depth=5, learning_rate=0.1461774202844157, subsample= 0.6649609199174655)\n",
        "xgb_model = xgb_model.fit(X_train, y_train)\n",
        "\n",
        "xgb_preds = tensor(xgb_model.predict(test_dl.xs))\n",
        "\n",
        "xgb_preds_x = tensor(xgb_model.predict(X_test))\n",
        "\n",
        "r2_score(y_test,xgb_preds_x)"
      ],
      "metadata": {
        "trusted": true,
        "id": "PIY8sIYN_8NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# General Ensemble"
      ],
      "metadata": {
        "id": "iU4_G2bl_8NW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn_preds_m = nn_preds_x.squeeze()"
      ],
      "metadata": {
        "trusted": true,
        "id": "AUbNsxyK_8NX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for r2_Score testing\n",
        "general_preds = (lgb_preds_x + xgb_preds_x + cat_preds_x + nn_preds_m)/4\n",
        "general_preds"
      ],
      "metadata": {
        "trusted": true,
        "id": "2Sa-I7JT_8Na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for r2_Score testing\n",
        "general_preds = ( cat_preds_x + nn_preds_m)/2\n",
        "general_preds"
      ],
      "metadata": {
        "trusted": true,
        "id": "TWuGhgUU_8Nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(y_test,general_preds)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Br9Pw-lB_8Nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(y_test,general_preds)"
      ],
      "metadata": {
        "trusted": true,
        "id": "mxpNHETg_8Nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "trusted": true,
        "id": "hczTlmdw_8Ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "general_preds.shape"
      ],
      "metadata": {
        "trusted": true,
        "id": "JZ69XnxB_8Ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#use for submission\n",
        "general_preds = (cat_preds + nn_preds_y)/2\n",
        "general_preds"
      ],
      "metadata": {
        "trusted": true,
        "id": "cdP7NaAB_8Nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scoring"
      ],
      "metadata": {
        "id": "0a4R7qAY_8Nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv(path/'sample_submission.csv')\n",
        "submit['FloodProbability'] = general_preds\n",
        "submit.to_csv('submission.csv', index=False)\n",
        "sub = pd.read_csv('submission.csv')"
      ],
      "metadata": {
        "trusted": true,
        "id": "2blKaEie_8Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "trusted": true,
        "id": "K_-76GAd_8Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm submission.csv"
      ],
      "metadata": {
        "trusted": true,
        "id": "IY8In8Ze_8Nk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}